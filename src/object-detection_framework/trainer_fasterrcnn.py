import torch
import torch.optim as optim
from torch.utils.data import DataLoader
import os
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
from torchvision import transforms as T
from torchvision.transforms import v2
import re  # ì •ê·œ í‘œí˜„ì‹ ëª¨ë“ˆ ì¶”ê°€
import wandb


import models
from dataset import CustomCocoDataset, custom_collate_fn
from models import get_model, CustomFasterRCNN
from utils import visualize_prediction, get_id2name_dict
from metrics import evaluate_with_metrics, plot_evaluation_results
# , log_metrics_to_wandb

plt.rcParams['font.family'] = 'Malgun Gothic'  # Windowsì˜ ê²½ìš°
# plt.rcParams['font.family'] = 'AppleGothic' # Macì˜ ê²½ìš°
# plt.rcParams['font.family'] = 'NanumGothic' # Linuxì˜ ê²½ìš°
plt.rcParams['axes.unicode_minus'] = False


def get_transforms(train=True):
    """ë°ì´í„° ì¦ê°•ì„ ìœ„í•œ transform ì •ì˜"""
    if train:
        transforms = v2.Compose([
            v2.ToImage(),
            v2.ToDtype(torch.float32, scale=True),
            v2.RandomHorizontalFlip(p=0.5),
            v2.RandomPhotometricDistort(p=0.5),
        ])
    else:
        transforms = v2.Compose([
            v2.ToImage(),
            v2.ToDtype(torch.float32, scale=True),
        ])
    return transforms


def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):
    """í•œ ì—í­ í•™ìŠµ í•¨ìˆ˜"""
    model.train()
    running_loss = 0.0

    for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=f"Epoch {epoch}", leave=False)):
        # print(images, targets)
        images = [image.to(device) for image in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        # Forward pass
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())

        # Backward pass
        optimizer.zero_grad()
        losses.backward()
        optimizer.step()

        running_loss += losses.item()

        if batch_idx % print_freq == 0:
            print(f"Batch {batch_idx}/{len(data_loader)}, Loss: {losses.item():.4f}")

    avg_loss = running_loss / len(data_loader)
    print(f"Epoch {epoch} - Average Loss: {avg_loss:.4f}")
    return avg_loss


# def evaluate(model, data_loader, device):
#     """ê²€ì¦ í•¨ìˆ˜"""
#     model.eval()
#     total_loss = 0.0
#
#     with torch.no_grad():
#         for images, targets in tqdm(data_loader, desc="Evaluating"):
#             images = [image.to(device) for image in images]
#             targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
#
#             # í‰ê°€ ëª¨ë“œì—ì„œëŠ” targetsë¥¼ ì „ë‹¬í•˜ì§€ ì•ŠìŒ
#             model.train()  # loss ê³„ì‚°ì„ ìœ„í•´ ì¼ì‹œì ìœ¼ë¡œ train ëª¨ë“œ
#             loss_dict = model(images, targets)
#             losses = sum(loss for loss in loss_dict.values())
#             total_loss += losses.item()
#             model.eval()  # ë‹¤ì‹œ eval ëª¨ë“œë¡œ
#
#     avg_loss = total_loss / len(data_loader)
#     print(f"Validation Loss: {avg_loss:.4f}")
#     return avg_loss


def save_checkpoint(model, optimizer, scheduler, epoch, loss, filepath):
    """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'loss': loss,
    }, filepath)
    print(f"Checkpoint saved: {filepath}")


def load_checkpoint(model, optimizer, scheduler, filepath):
    """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
    checkpoint = torch.load(filepath)
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
    epoch = checkpoint['epoch']
    loss = checkpoint['loss']
    print(f"Checkpoint loaded: {filepath}, Epoch: {epoch}, Loss: {loss:.4f}")
    return epoch, loss


def visualize_sample_predictions(model, dataset, device, class_names, num_samples=5):
    """ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
    model.eval()

    # ëœë¤í•˜ê²Œ ìƒ˜í”Œ ì„ íƒ
    import random
    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))

    with torch.no_grad():
        for idx in indices:
            image, target = dataset[idx]
            image_tensor = image.unsqueeze(0).to(device)

            prediction = model(image_tensor)[0]

            # CPUë¡œ ì´ë™
            prediction = {k: v.cpu() for k, v in prediction.items()}
            target = {k: v.cpu() for k, v in target.items()}

            visualize_prediction(image, prediction, class_names, target)


def main(args, model_name):
    print(f'ì‚¬ìš©ì¤‘ì¸ ëª¨ë¸ ëª… : {model_name}')
    print(f"Using device: {args.device}")

    # args.checkpoint_dir = os.path.join(args.checkpoint_dir, model_name)
    # # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±(ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš°)
    # os.makedirs(args.checkpoint_dir, exist_ok=True)

    ''' train1, train2 ìƒˆë¡œ í›ˆë ¨í• ë•Œë§ˆë‹¤ ìƒˆë¡œìš´ í´ë” ë§Œë“¤ì–´ì„œ ì €ì¥'''
    base_checkpoint_dir = os.path.join(args.checkpoint_dir, model_name)
    os.makedirs(base_checkpoint_dir, exist_ok=True)  # ìƒìœ„ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±

    if args.resume and args.checkpoint_path and os.path.exists(args.checkpoint_path):
        # í•™ìŠµ ì¬ê°œ ì‹œì—ëŠ” ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ê°€ ìˆëŠ” í´ë”ë¥¼ ì‚¬ìš©
        args.checkpoint_dir = os.path.dirname(args.checkpoint_path)
        print(f"í•™ìŠµ ì¬ê°œ: ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì‚¬ìš© - {args.checkpoint_dir}")
    else:
        # ìƒˆë¡­ê²Œ í•™ìŠµì„ ì‹œì‘í•  ë•Œë§Œ ê³ ìœ í•œ í´ë” ìƒì„±
        existing_runs = [d for d in os.listdir(base_checkpoint_dir) if re.match(r'^train\d+$', d)]

        if existing_runs:
            # ê¸°ì¡´ í´ë”ì—ì„œ ê°€ì¥ í° ìˆ«ì ì°¾ê¸°
            run_numbers = [int(re.match(r'^train(\d+)$', d).group(1)) for d in existing_runs]
            next_run_number = max(run_numbers) + 1
        else:
            # ê¸°ì¡´ í´ë”ê°€ ì—†ìœ¼ë©´ 1ë¶€í„° ì‹œì‘
            next_run_number = 1

        run_dir_name = f"train{next_run_number}"
        args.checkpoint_dir = os.path.join(base_checkpoint_dir, run_dir_name)
        os.makedirs(args.checkpoint_dir, exist_ok=True)
        print(f"ìƒˆë¡œìš´ í›ˆë ¨ ì‹œì‘: ê³ ìœ í•œ í´ë” ìƒì„± - {args.checkpoint_dir}")

    '''wandb ì—°ê²°'''
    if args.use_wandb:
        # wandb.init() í˜¸ì¶œ ì‹œ ì‹¤í–‰ ì´ë¦„ì„ `run_dir_name`ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í´ë”ëª…ê³¼ ì¼ì¹˜ì‹œí‚µë‹ˆë‹¤.
        # ê¸°ì¡´ í•™ìŠµì„ ì¬ê°œí•˜ëŠ” ê²½ìš°, ì´ë¦„ì€ ì´ë¯¸ ì €ì¥ëœ `run_dir_name`ì´ ë©ë‹ˆë‹¤.
        run_name = os.path.basename(args.checkpoint_dir)
        wandb.init(
            project=args.wandb_project,
            entity=args.wandb_entity,
            name=run_name,
            config=args
        )
        print("Wandbì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")


    # ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.train_annotation_path):
        raise FileNotFoundError(f"í›ˆë ¨ annotation íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.: {args.train_annotation_path}")
    if not os.path.exists(args.valid_annotation_path):
        raise FileNotFoundError(f"ê²€ì¦ annotation íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.: {args.valid_annotation_path}")

    # ë°ì´í„°ì…‹ ìƒì„± - í›ˆë ¨ìš©ê³¼ ê²€ì¦ìš©ì„ ë³„ë„ë¡œ ìƒì„±
    print("Loading datasets...")
    train_dataset = CustomCocoDataset(
        image_dir=args.train_image_dir,
        annotation_file=args.train_annotation_path,
        id2label_path=args.id2label_path,
        transforms=get_transforms(train=True),
        # transforms = get_transforms(train=True),
    )

    val_dataset = CustomCocoDataset(
        image_dir=args.valid_image_dir,
        annotation_file=args.valid_annotation_path,
        id2label_path=args.id2label_path,
        transforms=get_transforms(train=False)
    )

    # í´ë˜ìŠ¤ ìˆ˜ ì„¤ì • (í›ˆë ¨ ë°ì´í„°ì…‹ ê¸°ì¤€)
    args.num_classes = train_dataset.num_total_classes
    print(f"í´ë˜ìŠ¤ ìˆ˜(ë°°ê²½í¬í•¨): {args.num_classes}")
    # print(f"Class mapping: {train_dataset.sequential_label_to_original_name}")

    print(f"í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: {len(train_dataset)}")
    print(f"ê²€ì¦ ë°ì´í„°ì…‹ í¬ê¸°: {len(val_dataset)}")

    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        collate_fn=custom_collate_fn
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        collate_fn=custom_collate_fn
    )

    # ëª¨ë¸ ìƒì„±
    print("Creating model...")
    model = models.get_model(model_name, args.num_classes)
    model.to(args.device)

    # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = optim.SGD(
        params,
        lr=args.learning_rate,
        momentum=args.momentum,
        weight_decay=args.weight_decay
    )

    scheduler = optim.lr_scheduler.StepLR(
        optimizer,
        step_size=args.step_size,
        gamma=args.gamma
    )
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (ì¬ê°œ í•™ìŠµ)
    start_epoch = 0
    if args.resume and args.checkpoint_path and os.path.exists(args.checkpoint_path):
        start_epoch, _ = load_checkpoint(model, optimizer, scheduler, args.checkpoint_path)
        start_epoch += 1

    class_names = ['background'] + list(train_dataset.id2label.values())
    best_map = 0.0
    train_losses = []
    val_losses = []

    for epoch in range(start_epoch, args.num_epochs):
        # í•™ìŠµ
        train_loss = train_one_epoch(
            model, optimizer, train_loader, args.device, epoch, args.print_freq
        )
        train_losses.append(train_loss)

        # ìƒì„¸ í‰ê°€ ì—¬ë¶€ ê²°ì • (ì„¤ì • ì—í¬í¬ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ì—í¬í¬)
        compute_detailed = (epoch + 1) % args.eval_freq == 0 or epoch == args.num_epochs - 1

        # ê²€ì¦ (ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©)
        val_loss, detailed_results = evaluate_with_metrics(
            model, val_loader, args.device, class_names,
            confidence_threshold=args.confidence_threshold,
            compute_detailed_metrics=compute_detailed
        )
        val_losses.append(val_loss)

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if detailed_results:
            current_map = detailed_results['mAP']['mAP@0.5:0.95']
            if current_map > best_map:
                best_map = current_map
                best_model_path = os.path.join(args.checkpoint_dir, f"best_model_map_{current_map:.4f}.pth")
                torch.save(model.state_dict(), best_model_path)
                print(f"ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! mAP@0.5:0.95: {current_map:.4f}")

            # í‰ê°€ ê²°ê³¼ ì‹œê°í™” ì €ì¥
            if hasattr(args, 'save_metric_plots') and args.save_metric_plots:
                plot_path = os.path.join(args.checkpoint_dir, f'metrics_epoch_{epoch + 1}.png')
                plot_evaluation_results(detailed_results, save_path=plot_path)
            log_dict = {
                "epoch": epoch + 1,
                "train_loss": train_loss,
                "val_loss": val_loss,
                "lr": scheduler.get_last_lr()[0],
            }

            if detailed_results:
                log_dict.update({
                    "mAP@0.5:0.95": detailed_results['mAP']['mAP@0.5:0.95'],
                    # "mAP@0.5": detailed_results['mAP']['mAP@0.5'],
                    # "mAP@0.75": detailed_results['mAP']['mAP@0.75'],
                })
            if args.use_wandb:
                wandb.log(log_dict)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()

        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if (epoch + 1) % args.save_freq == 0:
            checkpoint_path = os.path.join(
                args.checkpoint_dir, f"checkpoint_epoch_{epoch + 1}.pth"
            )
            save_checkpoint(model, optimizer, scheduler, epoch, val_loss, checkpoint_path)



        print(f"Epoch {epoch + 1}/{args.num_epochs} completed\n")
        if detailed_results:
            print(f"Current mAP@0.5:0.95: {detailed_results['mAP']['mAP@0.5:0.95']:.4f}, Best: {best_map:.4f}")
        # ì´ë¯¸ì§€ ì‹œê°í™”
    if args.visualize_predictions:
        visualize_sample_predictions(
            model, val_dataset, args.device, class_names, args.vis_num_samples)
'''val_lossë§Œ ê³„ì‚°í•˜ëŠ” trainê³¼ì •'''
    # # í•™ìŠµ ë£¨í”„
    # train_losses = []
    # val_losses = []
    #
    # print("Starting training...")
    # for epoch in range(start_epoch, args.num_epochs):
    #     # í•™ìŠµ
    #     train_loss = train_one_epoch(
    #         model, optimizer, train_loader, args.device, epoch, args.print_freq
    #     )
    #     train_losses.append(train_loss)
    #
    #     # ê²€ì¦
    #     val_loss = evaluate(model, val_loader, args.device)
    #     val_losses.append(val_loss)
    #
    #     # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
    #     scheduler.step()
    #
    #     # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    #     if (epoch + 1) % args.save_freq == 0:
    #         checkpoint_path = os.path.join(
    #             args.checkpoint_dir, f"checkpoint_epoch_{epoch + 1}.pth"
    #         )
    #         save_checkpoint(model, optimizer, scheduler, epoch, val_loss, checkpoint_path)
    #
    #     print(f"Epoch {epoch + 1}/{args.num_epochs} completed\n")
    #
    # # ìµœì¢… ëª¨ë¸ ì €ì¥
    # final_model_path = os.path.join(args.checkpoint_dir, "final_model.pth")
    # torch.save(model.state_dict(), final_model_path)
    # print(f"Final model saved: {final_model_path}")
    #
    # # í•™ìŠµ ê³¡ì„  ì‹œê°í™”
    # plt.figure(figsize=(12, 5))
    #
    # plt.subplot(1, 2, 1)
    # plt.plot(train_losses, label='Train Loss')
    # plt.plot(val_losses, label='Validation Loss')
    # plt.title('Training and Validation Loss')
    # plt.xlabel('Epoch')
    # plt.ylabel('Loss')
    # plt.legend()
    # plt.grid(True)
    #
    # plt.tight_layout()
    # plt.savefig(os.path.join(args.checkpoint_dir, 'training_curves.png'))
    # plt.show()
    #
    # # ìƒ˜í”Œ ì˜ˆì¸¡ ì‹œê°í™”
    # if args.visualize_predictions:
    #     class_names = ['background'] + [name for name in train_dataset.sequential_label_to_original_name.values()]
    #     visualize_sample_predictions(
    #         model, val_dataset, args.device, class_names, args.vis_num_samples
    #     )
    #
    # print("Training completed!")


if __name__ == "__main__":
    class Args_rcnn:
        def __init__(self):
            # Data paths - ìƒˆë¡œìš´ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
            self.train_image_dir = "./data/images/train"  # í›ˆë ¨ ì´ë¯¸ì§€ í´ë”
            self.valid_image_dir = "./data/images/val"  # ê²€ì¦ ì´ë¯¸ì§€ í´ë”
            self.train_annotation_path = "./data/labels/train/train.json"  # í›ˆë ¨ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼
            self.valid_annotation_path = "./data/labels/val/valid.json"  # ê²€ì¦ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼
            self.checkpoint_dir = "./checkpoints/CustomFasterRCNN"  # checkpoint ëª¨ë¸ ê²½ë¡œ

            # Training parameters
            self.batch_size = 4  # ë°°ì¹˜ í¬ê¸°
            self.num_epochs = 11  # ì—í¬í¬ ìˆ˜
            self.learning_rate = 0.005  # í•™ìŠµë¥ 
            self.weight_decay = 0.0005  # í•™ìŠµë¥  ë³€í™”
            self.momentum = 0.9  # ëª¨ë©˜í…€
            self.step_size = 3
            self.gamma = 0.1

            # Model parameters
            self.num_classes = None  # datasetì—ì„œ ìë™ìœ¼ë¡œ ê²°ì •, ì†ìˆ˜ ê²°ì •í•  ë•Œë§Œ ì…ë ¥
            self.model_name = 'customfasterrcnn'  # ['Yolov#', 'CustomFasterRCNN', ]

            # Training settings
            self.device = "cuda" if torch.cuda.is_available() else "cpu"  # ë””ë°”ì´ìŠ¤ ì„¤ì •
            self.num_workers = 4  # Dataloaderì˜ num_worker ìˆ˜ ì„¤ì •
            self.print_freq = 10  # ì–¼ë§ˆë§ˆë‹¤ loss í”„ë¦°íŠ¸ í•  ê²ƒì¸ì§€
            self.save_freq = 1  # ì²´í¬í¬ì¸íŠ¸ë¥¼ ëª‡ epochë§ˆë‹¤ ì €ì¥í•  ê²ƒì¸ì§€

            # Resume training
            # ì¤‘ê°„ì— í•™ìŠµ ë©ˆì¶”ê³  ë‹¤ì‹œ ì‹œì‘í• ë•Œ, checkpoint ë¶ˆëŸ¬ì˜¤ëŠ” ì„¤ì •
            # self.resume = False                                                                   # FalseëŠ” ì•ˆë¶ˆëŸ¬ì˜´ - ì²˜ìŒë¶€í„° í•™ìŠµí•¨(ëŒ€ì‹  ì´ì „ì— í•™ìŠµí•´ì„œ checkpointìˆìœ¼ë©´, ë®ì–´ì”€.
            # self.checkpoint_path = None
            self.resume = True  # TrueëŠ” ë¶ˆëŸ¬ì˜´
            self.checkpoint_path = "./checkpoints/CustomFasterRCNN/checkpoint_epoch_10.pth"  # ë¶ˆëŸ¬ì˜¬ checkpoint ê²½ë¡œ

            # Validation - ì´ì œ ë³„ë„ íŒŒì¼ë¡œ ì œê³µë˜ë¯€ë¡œ í•„ìš”ì—†ìŒ
            # self.val_split = 0.2

            # Visualization
            self.visualize_predictions = True  # validation ì´ë¯¸ì§€ ë³´ì—¬ ì£¼ëŠ”ê°€
            self.vis_num_samples = 5  # ì´ë¯¸ì§€ ê°¯ìˆ˜

            # WandB settings
            self.use_wandb = True  # wandb ì—°ê²°
            self.wandb_project = "object-detection"
            self.wandb_entity = 'AI-team4'
            self.wandb_run_name = None  # Noneìœ¼ë¡œ ì„¤ì •ë˜ë©´ ì•„ë¬´ë ‡ê²Œë‚˜ ìë™ìœ¼ë¡œ ì €ì¥ë¨

            # Evaluation settings
            self.eval_freq = 1  # ëª‡ epochë§ˆë‹¤ í‰ê°€í•˜ë‚˜
            self.confidence_threshold = 0.5  # classificationëœ ë°•ìŠ¤ë¥¼ ì œê±°í•˜ëŠ” ê¸°ì¤€
            self.nms_threshold = 0.5  # IoUë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°•ìŠ¤ë¥¼ ì œê±°í•˜ëŠ” ê¸°ì¤€
            self.save_metric_plots = True                                                       # ë©”íŠ¸ë¦­ ì‹œê°í™” ì €ì¥ ì—¬ë¶€


    args = Args_rcnn()
    main(args)