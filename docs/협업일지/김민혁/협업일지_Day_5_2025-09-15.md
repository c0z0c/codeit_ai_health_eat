---
layout: default
title: "협업일지 Day 5 (2025-09-15) - 코드잇 AI 4기 4팀 김민혁"
description: "협업일지 Day 5 (2025-09-15) - 코드잇 AI 4기 4팀 김민혁"
date: 2025-09-15
author: "김민혁"
cache-control: no-cache
expires: 0
pragma: no-cache
---

# 일일 협업일지 - Day 5 (2025-09-15)

## [1] 기본 정보
**날짜**: 2025-09-15  
**이름**: 김민혁 
**팀명**: 코드잇 AI 4기 4팀

---

## [2] 오늘 맡은 역할 및 구체적인 작업 내용
**답변**:  
Faster R-CNN 하이퍼파라미터 튜닝, YOLO vs Faster R-CNN 동일 조건 실험

데이터 확장 후 학습 중 GPU OOM 발생 → 즉시 대응
    AMP(autocast + GradScaler) 적용
    마이크로배치(gradient accumulation) 적용으로 유효 배치 크기 유지

성능 저하 우려로 해상도 축소/백본 축소 등은 보류하고,
클래스별 균등 증분 로더로 데이터 수를 “클래스당 N개씩 점증” 방식으로 제한하여 학습 재가동

최소 세팅에서 모델 학습 정상 진행까지 확인

---

## [3] 오늘 작업 완료도 체크 (하나만 체크)
- [ ] 0% (시작 못함)
- [ ] 25% (시작은 했지만 진척 없음)  
- [x] 50% (진행 중, 절반 이하)
- [ ] 75% (거의 완료됨)
- [ ] 100% (완료 및 점검까지 완료)

**간단한 근거**: 데이터 숫자를 늘려봤을때, OOM이 일어나서 이를 효과적으로 해결할 방법을 찾는데 시간을 보냈고 결국 AMP + 마이크로배치(gradient accumulation)만 적용 후 데이터량을 타협.

---

## [4] 오늘 협업 중 제안하거나 피드백한 내용이 있다면?
**답변**:  
제안한 내용 없음.
---

## [5] 오늘 분석/실험 중 얻은 인사이트나 발견한 문제점은?
**답변**:  
OOM 원인은 데이터 확대와 함께 입력 크기, RPN/ROI 후보 수, FPN 피처맵 누적이 결합된 결과로 추정.

AMP는 VRAM 사용량을 안정적으로 낮추면서도 성능 저하 위험이 적어 1순위 대응책으로 적합.

Gradient Accumulation은 step 당 메모리를 줄여 주지만, 스케줄러/정규화의 **“step 기준”**이 바뀌므로 로깅 시 유효 스텝을 명확히 기록 필요.

데이터는 클래스당 균등 증분으로 늘리는 방식이 초기 비교(YOLO vs Faster R-CNN)에서 편향 리스크를 낮추는 데 유효.
---

## [6] 일정 지연이나 협업 중 어려웠던 점이 있다면?
**답변**:  
OOM으로 실험 계획(동일 조건 비교/튜닝) 일정 일부 지연.

---

## [7] 오늘 발표 준비나 커뮤니케이션에서 기여한 부분은?
**답변**:  
금일 발표 기여 없음.

---

## [8] 내일 목표 / 할 일
**답변**:  
yolo모델의 성능 파악
Faster R-CNN 튜닝 스윗(LR/Warmup/Scheduler, RPN pre/post_nms_top_n, ROI batch_size_per_image)

---

## [9] 추가 기록 (선택사항)

### Kaggle 제출 (해당시)
| 시간 | 점수 | 변경사항 |
|------|------|----------|
|------|------|----------|

### 코드 기여
**작성 파일**: 
**주요 기능**: 

### 개인 성찰
**뿌듯한 점**: 
**어려운 점**: 
**내일 개선**: yolo모델의 성능 파악 및 Faster R-CNN 튜닝 스윗

---

**작성 시간**: 5분