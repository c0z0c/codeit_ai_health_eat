{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a25b40d-8bff-46ff-9e8f-006f42f4c22d",
   "metadata": {},
   "source": [
    "## Daily 협업일지 양식\n",
    "### 1. 오늘 날짜 / 이름 / 팀명\n",
    "- 날짜: 2025.09.09\n",
    "- 이름: 이건희\n",
    "- 팀명: codeit_AI_04기_04팀\n",
    "\n",
    "### 2. 오늘 맡은 역할 및 구체적인 작업 내용\n",
    "오늘 당신이 맡았던 역할은 무엇이었고, 어떤 작업을 수행했나요?\n",
    "(예: 모델 학습 파라미터 조정, 결측치 처리, 발표자료 구성 등)\n",
    "\n",
    "✍️ 답변:\n",
    "(예시) 데이터 전처리 파트 담당. 범주형 변수 인코딩 및 이상치 확인 코드 작성 후 팀에게 공유함.\n",
    "\n",
    "\n",
    "​\n",
    "### 3. 오늘 작업 완료도 체크 (하나만 체크)\n",
    "진척 상황을 정량적으로 표시하고, 간단한 근거도 작성하세요.\n",
    "\n",
    "- [ ] 🔴 0% (시작 못함)\n",
    "  \n",
    "- [ ] 🟠 25% (시작은 했지만 진척 없음)\n",
    "- [ ] 🟡 50% (진행 중, 절반 이하)\n",
    "- [ ] 🔵 75% (거의 완료됨)\n",
    "- [ ] 🟢 100% (완료 및 점검까지 완료)\n",
    "\n",
    "\n",
    "📌 간단한 근거:\n",
    "(예시) 75%: 주요 전처리 완료했지만 시각화 일부 남음\n",
    "\n",
    "\n",
    "​\n",
    "### 4. 오늘 협업 중 제안하거나 피드백한 내용이 있다면?\n",
    "오늘 회의나 메시지에서 당신이 제안하거나 팀에 피드백한 내용은 무엇인가요?\n",
    "\n",
    "✍️ 답변:\n",
    "(예시) 모델 학습 전에 EDA를 먼저 해야 한다는 의견 제안. 기존 모델 성능 비교표 작성 아이디어 냄.\n",
    "\n",
    "\n",
    "​\n",
    "### 5. 오늘 분석/실험 중 얻은 인사이트나 발견한 문제점은?\n",
    "EDA, 모델 실험 중 유의미한 점이나 오류가 있었다면 자유롭게 작성하세요.\n",
    "\n",
    "✍️ 답변:\n",
    "(예시) ‘duration’ 변수의 이상치가 모델 성능 저하에 영향을 주는 것으로 보임.\n",
    "\n",
    "\n",
    "​\n",
    "### 6. 일정 지연이나 협업 중 어려웠던 점이 있다면?\n",
    "자기 업무 외에도 전체 일정이나 팀 내 협업에서 생긴 문제를 공유해 주세요.\n",
    "\n",
    "✍️ 답변:\n",
    "(예시) 발표자료 수정 중 겹치는 작업이 발생해 버전 충돌 있었음 → 구글 슬라이드로 일원화함.\n",
    "\n",
    "\n",
    "​\n",
    "### 7. 오늘 발표 준비나 커뮤니케이션에서 기여한 부분은?\n",
    "슬라이드 제작, 발표 연습, 질문 정리 등 발표와 관련된 활동을 썼다면 기록하세요.\n",
    "\n",
    "✍️ 답변:\n",
    "(예시) 발표용 그래프 수정 및 정렬. 질문 예상 리스트 작성해서 팀 공유.\n",
    "\n",
    "\n",
    "​\n",
    "### 8. 내일 목표 / 할 일\n",
    "구체적인 개인 업무나 팀 목표 기반 계획을 간단히 적어주세요.\n",
    "\n",
    "✍️ 답변:\n",
    "(예시) 모델 성능 비교 실험 3개 수행 후 결과 요약, 발표자료 3p 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1508a2f-11db-4464-808b-f83be95dba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from PIL import Image\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d11db74-2742-41b3-a407-b8d04f1b6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('./data/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e78a5fe-da79-427c-b7cf-9e6f61a84372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/ai04-level1-project/train_images ./data/ai04-level1-project/train_annotations\n"
     ]
    }
   ],
   "source": [
    "path = './data/ai04-level1-project/'\n",
    "\n",
    "image_base_dir = os.path.join(path, os.listdir(path)[2])\n",
    "annotation_base_dir = os.path.join(path, os.listdir(path)[1])\n",
    "print(image_base_dir,annotation_base_dir)\n",
    "# test_images_dir = os.path.join(path, os.listdir(path)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "390558fd-e60b-4421-95c0-51fe7e10a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489\n"
     ]
    }
   ],
   "source": [
    "image_list = os.listdir(image_base_dir)\n",
    "\n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902d702-e117-4ebc-9487-66fc7015f3c9",
   "metadata": {},
   "source": [
    "### 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fc57f5f-e708-4e00-a29c-ac3222fe60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx,img_filename in enumerate(images_list):\n",
    "#     img_path = image_base_dir+'/' + img_filename\n",
    "#     # print(img_path)\n",
    "#     a = cv2.imread(img_path)\n",
    "#     if a is not None: # 이미지가 성공적으로 로드되었는지 다시 한번 확인\n",
    "#         cv2.imshow('Image Window', a) # 'Image Window'는 창의 이름, 'a'는 로드된 이미지 데이터\n",
    "#         cv2.waitKey(0) # 키 입력이 있을 때까지 창을 띄워둠 (0은 무한대)\n",
    "#         cv2.destroyAllWindows() # 열려있는 모든 OpenCV 창을 닫음\n",
    "#     else:\n",
    "#         print(\"이미지를 로드하지 못했습니다.\")\n",
    "#     if idx ==10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f21e4d0-bca7-45c5-aec5-9527a3f327a9",
   "metadata": {},
   "source": [
    "### Annotation를 이미지에 맞게 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43126ded-7195-4b10-8982-00a8a1e88c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-001900-010224-016551-031705_0_2_0_2_70_000_200.png\n",
      "K-001900-010224-016551-031705_0_2_0_2_75_000_200.png\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/ai04-level1-project/train_annotations\\\\K-001900-010224-016551-031705_json\\\\K-031705\\\\K-001900-010224-016551-031705_0_2_0_2_75_000_200.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx,image_filename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(image_list):\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(image_filename)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     anno = \u001b[43mbring_annotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_base_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_base_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# print(anno)\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m idx==\u001b[32m10\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mbring_annotation\u001b[39m\u001b[34m(image_base_dir, annotation_base_dir, image_filename)\u001b[39m\n\u001b[32m     17\u001b[39m anno_list= []\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m anno_path \u001b[38;5;129;01min\u001b[39;00m pill_annotation_path:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manno_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     20\u001b[39m         anno = json.load(f)\n\u001b[32m     21\u001b[39m     image_info = anno[\u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\new_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/ai04-level1-project/train_annotations\\\\K-001900-010224-016551-031705_json\\\\K-031705\\\\K-001900-010224-016551-031705_0_2_0_2_75_000_200.json'"
     ]
    }
   ],
   "source": [
    "def bring_annotation(image_base_dir, annotation_base_dir, image_filename:str):\n",
    "    '''\n",
    "    image_base_dir : 이미지의 base 폴더 경로 (./data/ai04-level1-project/train_images)\n",
    "    annotation_base_dir : 어노테이션 base 폴더 경로 (./data/ai04-level1-project/train_annotations)\n",
    "    image_filename : 이미지의 파일명( K-001900-010224-016551-031705_0_2_0_2_70_000_200.png )\n",
    "\n",
    "    이미지 파일명으로부터 annotation을 찾고, boundbox와 label을 찾아서 반환함    \n",
    "    '''\n",
    "    image_filename = os.path.splitext(image_filename)[0]\n",
    "    splited_filename = image_filename.split('_')\n",
    "    annotation_dir = os.path.join(annotation_base_dir,splited_filename[0]+'_json')\n",
    "    pill_dir = os.listdir(annotation_dir)\n",
    "    pill_annotation_base_dir = [os.path.join(annotation_dir, pill_name) for pill_name in pill_dir]\n",
    "    pill_annotation_path = [os.path.join(base_dir, image_filename) for base_dir in pill_annotation_base_dir]\n",
    "    pill_annotation_path = [path_item + '.json' for path_item in pill_annotation_path]\n",
    "    # print(pill_annotation_path)\n",
    "    anno_list= []\n",
    "    for anno_path in pill_annotation_path:\n",
    "        with open(anno_path, 'r',encoding='utf-8') as f:\n",
    "            anno = json.load(f)\n",
    "        image_info = anno['images'][0]\n",
    "        annotation_info = anno['annotations'][0]\n",
    "        category_info = anno['categories'][0] if anno['categories'] else {} \n",
    "        anno_list.append(anno)\n",
    "    return anno_list\n",
    "\n",
    "\n",
    "for idx,image_filename in enumerate(image_list):\n",
    "    print(image_filename)\n",
    "    anno = bring_annotation(image_base_dir, annotation_base_dir, image_filename)\n",
    "    # print(anno)\n",
    "    if idx==10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb2bf9-8cec-44bb-807c-cceb5f7e86b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
