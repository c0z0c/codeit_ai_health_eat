{"cells":[{"cell_type":"markdown","metadata":{"id":"G3tb146HKUGS"},"source":["# [초급 프로젝트] 4팀_김명환"]},{"cell_type":"markdown","metadata":{"id":"hmaVeBaGKUGW"},"source":["---\n","---"]},{"cell_type":"markdown","metadata":{"id":"KzN8SzLMKgH1"},"source":["# 프로그래밍"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47-Qf8TYKUGW"},"outputs":[],"source":["# 기본 라이브러리\n","\n","# --- Scikit-learn: 데이터 전처리, 모델, 평가 ---\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import (\n","    fetch_california_housing, load_iris, make_moons, make_circles,\n","    load_breast_cancer, load_wine\n",")\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","from sklearn.metrics import average_precision_score\n","\n","# --- 기타 라이브러리 ---\n","import cv2\n","from PIL import Image\n","from PIL import ImageFilter\n","from PIL import ImageDraw\n","import albumentations as A\n","import IPython.display\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","# --- PyTorch: 딥러닝 관련 ---\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Subset\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import v2\n","from torchvision.datasets import CocoDetection\n","from torchvision.transforms import functional as TF\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import Dataset\n","from collections import OrderedDict\n","from pycocotools.coco import COCO\n","from pycocotools import mask as coco_mask\n","\n","# --- 기타 ---\n","import re\n","import os\n","import sys\n","import copy\n","import json\n","import math\n","import random\n","import yaml\n","import shutil\n","import pandas as pd\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timezone, timedelta\n","import pytz\n","__kst = pytz.timezone('Asia/Seoul')\n","\n","# GPU 설정\n","__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","__device_cpu = torch.device('cpu')\n","\n","  # 재현 가능한 결과를 위해\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if __device == 'cuda':\n","    torch.cuda.manual_seed_all(42)\n","\n","print(f\"라이브러리 로드 완료 사용장치:{__device}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gDTmqQCCrBWm","outputId":"07c8b240-b50d-4bad-9d97-6725fcca10e4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757601321115,"user_tz":-540,"elapsed":42612,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["🌐 https://c0z0c.github.io/jupyter_hangul\n","ℹ️ NumPy 2.0.2 (v2.x+): 호환성 모드 적용됨\n","install fonts-nanum...\n","Mounted at /content/drive\n","✅ 설정 완료: 한글 폰트, plt 전역 등록, pandas 확장, 캐시 기능\n","pd commit 저장 경로 = /content/drive/MyDrive\n","🌐 https://c0z0c.github.io/jupyter_hangul\n","ℹ️ NumPy 2.0.2 (v2.x+): 호환성 모드 적용됨\n","Mounted at /content/drive\n","✅ 설정 완료: 한글 폰트, plt 전역 등록, pandas 확장, 캐시 기능\n","pd commit 저장 경로 = /content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'helper_c0z0c_dev' from '/content/helper_c0z0c_dev.py'>"]},"metadata":{},"execution_count":3}],"source":["from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n","import importlib\n","import helper_c0z0c_dev as helper\n","importlib.reload(helper)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17307,"status":"ok","timestamp":1757601340236,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"WE6336hF11C5","outputId":"b7e4e06b-7344-4798-f0b5-7724bfc124b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["utils_dir: /content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\n","sys.path: ['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmptfl_1mrc', '/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils']\n","🌐 https://c0z0c.github.io/jupyter_hangul\n","ℹ️ NumPy 2.0.2 (v2.x+): 호환성 모드 적용됨\n","Mounted at /content/drive\n","✅ 설정 완료: 한글 폰트, plt 전역 등록, pandas 확장, 캐시 기능\n","pd commit 저장 경로 = /content/drive/MyDrive\n","🌐 https://c0z0c.github.io/jupyter_hangul\n","ℹ️ NumPy 2.0.2 (v2.x+): 호환성 모드 적용됨\n","Mounted at /content/drive\n","✅ 설정 완료: 한글 폰트, plt 전역 등록, pandas 확장, 캐시 기능\n","pd commit 저장 경로 = /content/drive/MyDrive\n","helper.__file__: /content/helper_c0z0c_dev.py\n","health_ea_utils.__file__: /content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils/health_ea_utils.py\n"]}],"source":["import os, sys\n","from pathlib import Path\n","\n","utils_dir = None\n","if helper.is_colab:\n","    utils_dir = \"/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\"\n","else:\n","    utils_dir = os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive', \"codeit_ai_health_eat\", \"src\", \"python_modules\", \"utils\")\n","\n","print(\"utils_dir:\", utils_dir)\n","\n","sys.path.append(str(utils_dir))\n","print(\"sys.path:\", sys.path)\n","import importlib\n","import health_ea_utils as heu\n","importlib.reload(heu)\n","from health_ea_utils import *\n","\n","print(\"helper.__file__:\", helper.__file__)\n","print(\"health_ea_utils.__file__:\", heu.__file__)\n"]},{"cell_type":"markdown","metadata":{"id":"20rBdRxvKUGZ"},"source":["# 1. 학습용 데이타 다운로드 및 압축 풀기"]},{"cell_type":"code","source":["!pip install -q kaggle\n","print(\"로딩완료\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ch19qLmxNYIn","executionInfo":{"status":"ok","timestamp":1757601460269,"user_tz":-540,"elapsed":6278,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"0e02596a-cec0-4855-87bc-3751a426d244"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["로딩완료\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"DSwfz_YpqZ_W","outputId":"84bf9d9a-976e-4ea2-8644-bf3b10802a25","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757602136489,"user_tz":-540,"elapsed":216297,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle_config_dir: /content/drive/MyDrive/\n","kaggle_code_it_data: ~/.cache/dataset/kaggle_code_it_data\n","kaggle.json 복사 및 권한 설정 완료 (두 경로 모두)\n","Kaggle 데이터 다운로드 중...\n"]},{"output_type":"stream","name":"stderr","text":["압축 해제 중: ai04-level1-project.zip: 100%|██████████| 6858/6858 [00:11<00:00, 595.12file/s]\n"]},{"output_type":"stream","name":"stdout","text":["압축 해제 완료: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip\n","다운로드 완료 ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip\n"]}],"source":["# google drive root에 keggle.json 파일 필요합니다.\n","\n","#kaggle_code_it_data = \"~/.cache/kaggle_code_it_data\" if helper.is_colab else os.path.join(Path.cwd(),'dataset', 'kaggle_code_it_data')\n","kaggle_config_dir = \"/content/drive/MyDrive/\" if helper.is_colab else os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive')\n","print(\"kaggle_config_dir:\", kaggle_config_dir)\n","kaggle_code_it_data = os.path.join( '~/.cache/' if helper.is_colab else Path.cwd().drive + '\\\\','dataset', 'kaggle_code_it_data')\n","print(\"kaggle_code_it_data:\", kaggle_code_it_data)\n","\n","import sys\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","from tqdm import tqdm\n","\n","if helper.is_colab:\n","    os.makedirs('/root/.kaggle', exist_ok=True)\n","    os.makedirs('/root/.config/kaggle', exist_ok=True)\n","    !cp /content/drive/MyDrive/kaggle.json /root/.kaggle/kaggle.json\n","    !cp /content/drive/MyDrive/kaggle.json /root/.config/kaggle/kaggle.json\n","    !chmod 600 /root/.kaggle/kaggle.json\n","    !chmod 600 /root/.config/kaggle/kaggle.json\n","    print(\"kaggle.json 복사 및 권한 설정 완료 (두 경로 모두)\")\n","\n","def download_ai01_level1_project():\n","    os.environ['KAGGLE_CONFIG_DIR'] = kaggle_config_dir\n","    kaggle_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip')\n","    if not os.path.exists(kaggle_path):\n","        os.makedirs(kaggle_code_it_data, exist_ok=True)\n","        print(\"Kaggle 데이터 다운로드 중...\")\n","        api = KaggleApi()\n","        api.authenticate()\n","        # 전체 압축파일 다운로드 (프로그래스 바는 kaggle API에서 지원하지 않음)\n","        api.competition_download_files('ai04-level1-project', path=kaggle_code_it_data)\n","        return os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip')\n","        print(\"Kaggle 데이터 다운로드 완료\")\n","    else:\n","        return kaggle_path\n","        print(\"Kaggle 데이터 다운로드 완료\")\n","\n","kaggle_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip')\n","kaggle_unzip_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip.unzip')\n","if os.path.exists(kaggle_unzip_path) is False:\n","    kaggle_path = download_ai01_level1_project()\n","    heu.unzip([kaggle_path,])\n","    kaggle_unzip_path = f\"{kaggle_path}.unzip\"\n","    print(f\"다운로드 완료\", kaggle_unzip_path)\n","else:\n","    kaggle_unzip_path = f\"{kaggle_path}.unzip\"\n","    print(f\"이미 다운로드 받았습니다.\", kaggle_unzip_path)\n","\n","root_dir = os.path.join(kaggle_unzip_path)\n","kaggle_unzip_path_test_images = os.path.join(kaggle_unzip_path, 'test_images')\n","kaggle_unzip_path_train_images = os.path.join(kaggle_unzip_path, 'train_images')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-t1kwMyqZ_W"},"outputs":[],"source":["# heu.print_dir_tree(root=kaggle_unzip_path)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Qh4JvLIDKUGa","executionInfo":{"status":"ok","timestamp":1757602174568,"user_tz":-540,"elapsed":107,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def df_filename_list(root):\n","    \"\"\"\n","    root 하위의 모든 .json 파일에 대해\n","    - 파일명(확장자 없는)\n","    - json 파일 경로\n","    - png 파일 경로 (동일 경로, 동일 파일명, 확장자만 .png)\n","    를 DataFrame으로 반환\n","    \"\"\"\n","    import os\n","    import pandas as pd\n","\n","    records = []\n","    for dirpath, _, filenames in os.walk(root):\n","        for fname in filenames:\n","            drug_info={\n","                'filename': None,\n","                'ext': None,\n","                'file_name': None,\n","                'path': None,\n","                'label': None,\n","                'drug0': None,\n","                'drug1': None,\n","                'drug2': None,\n","                'drug3': None,\n","            }\n","\n","            filename, ext = os.path.splitext(fname)\n","            ext = ext.lower().replace('.', '')  # 확장자에서 . 제거\n","            drug_info.update({\n","                'filename': filename,\n","                'file_name': fname,\n","                'ext': ext,\n","                'path': os.path.join(dirpath, fname),\n","            })\n","            if filename.startswith('K-'):\n","                # 예시: K-001900-010224-016551-031705_0_2_0_2_70_000_200\n","                parts = filename.split('_')[0].split('-')\n","                if len(parts) >= 5:\n","                    drug_info.update({\n","                        'label': f'{filename.split(\"_\")[0]}',\n","                        'drug0': f'K-{parts[1]}',\n","                        'drug1': f'K-{parts[2]}',\n","                        'drug2': f'K-{parts[3]}',\n","                        'drug3': f'K-{parts[4]}',\n","                    })\n","            records.append(drug_info)\n","    return pd.DataFrame(records)\n","df_files = df_filename_list(kaggle_unzip_path)\n","df_files.sort_values(by='filename',inplace=True)\n","df_files_sort = df_files"]},{"cell_type":"markdown","metadata":{"id":"9ssg2kYkKUGb"},"source":["# 2. Yolo DataFrame"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"XqY1XACxKUGc","outputId":"917d1ede-0376-4ce1-cf20-465afd7388d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757602198448,"user_tz":-540,"elapsed":18262,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["JSON 정보 수집 중...\n"]},{"output_type":"stream","name":"stderr","text":["Processing Test files: 100%|██████████| 843/843 [00:00<00:00, 15300.46it/s]\n","Processing JSON files: 100%|██████████| 4526/4526 [00:14<00:00, 322.60it/s, K-003544-012247-016548-021026_0_2_0_2_75_000_200]"]},{"output_type":"stream","name":"stdout","text":["\n","=== 처리 결과 ===\n","전체 파일: 6858\n","성공 처리: 5369\n","오류 파일: 0\n","df_new shape: (5369, 24)\n","df_drug shape: (73, 19)\n","✅ 커밋 완료: 021da901baae | 2025-09-11 14:50:04 | df_codeit04_new\n","✅ 커밋 완료: 81ede6b27b2e | 2025-09-11 14:50:04 | df_codeit04_drug\n","df_codeit04_new, df_codeit04_drug 저장\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# json 파일을 DataFrame로 로드\n","df = df_files.copy()\n","def json_to_df(json_path):\n","    \"\"\"\n","    json_path의 json 파일을 pandas DataFrame으로 변환\n","    - images, annotations, categories를 각각 DataFrame으로 반환\n","    \"\"\"\n","    with open(json_path, encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    df_images = pd.DataFrame(data.get('images', []))\n","    df_annotations = pd.DataFrame(data.get('annotations', []))\n","    df_categories = pd.DataFrame(data.get('categories', []))\n","\n","    return df_images, df_annotations, df_categories\n","\n","def bbox_to_yolo(bbox, img_width, img_height):\n","    # bbox: [x, y, w, h] (COCO)\n","    if not bbox or len(bbox) < 4:\n","        return None  # 오류시 None 반환\n","\n","    x, y, w, h = bbox[:4]\n","    x_center = (x + w / 2) / img_width\n","    y_center = (y + h / 2) / img_height\n","    w_norm = w / img_width\n","    h_norm = h / img_height\n","    return x_center, y_center, w_norm, h_norm\n","\n","def collect_json_info(df):\n","    \"\"\"\n","                                              filename  ext                                             file_name                                                                                                                                                                             path                         label  drug0  drug1  drug2  drug3\n","  962 K-001900-016548-019607-031705_0_2_0_2_75_000_200 json K-001900-016548-019607-031705_0_2_0_2_75_000_200.json d:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\train_annotations\\K-001900-016548-019607-031705_json\\K-016548\\K-001900-016548-019607-031705_0_2_0_2_75_000_200.json K-001900-016548-019607-031705 001900 016548 019607 031705\n"," 5406 K-001900-016548-019607-031705_0_2_0_2_75_000_200  png  K-001900-016548-019607-031705_0_2_0_2_75_000_200.png                                                   d:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\train_images\\K-001900-016548-019607-031705_0_2_0_2_75_000_200.png K-001900-016548-019607-031705 001900 016548 019607 031705\n","\n","    df['ext'] json을 순회하며 json_to_df로 정보를 읽고,\n","    df에 image, drug_N, width, height, bbox_x/y/w/h, yolo_x/y/w/h 컬럼을 추가.\n","    약 정보는 drug_N 기준으로 중복 없이 df_drug에 저장.\n","    bbox 오류가 있는 파일은 출력하고 제거.\n","    \"\"\"\n","    import pandas as pd\n","\n","    records = []\n","    drug_info = {}\n","    error_files = []  # 오류 파일 목록\n","\n","    # Test 분류\n","    df_test = df[(df['ext'] == 'png') & (df['path'].str.contains('test', case=False))].copy()\n","    pbar = tqdm(df_test.iterrows(), total=len(df_test), mininterval=3, desc=\"Processing Test files\")\n","    for idx, row in pbar:\n","        field = {\n","                **row,\n","                'imgfile': row['path'],\n","                'Train' : False,\n","                'Test' : True,\n","                'drug_N': None,\n","                'width': 0,\n","                'height': 0,\n","                'bbox_x': 0,\n","                'bbox_y': 0,\n","                'bbox_w': 0,\n","                'bbox_h': 0,\n","                'yolo_x': 0.0,\n","                'yolo_y': 0.0,\n","                'yolo_w': 0.0,\n","                'yolo_h': 0.0\n","            }\n","        filename_without_ext = os.path.splitext(os.path.basename(row['path']))[0]\n","        field['filename'] = filename_without_ext\n","        records.append(field)\n","\n","    # Train 분류\n","    df_json = df[df['ext'] == 'json'].copy()\n","    df_png = df[df['ext'] == 'png'].copy()\n","    pbar = tqdm(df_json.iterrows(), total=len(df_json), mininterval=3, desc=\"Processing JSON files\")\n","    for idx, row in pbar:\n","        field = {\n","                **row,\n","                'imgfile': None,\n","                'Train' : True,\n","                'Test' : False,\n","                'drug_N': None,\n","                'width': 0,\n","                'height': 0,\n","                'bbox_x': 0,\n","                'bbox_y': 0,\n","                'bbox_w': 0,\n","                'bbox_h': 0,\n","                'yolo_x': 0.0,\n","                'yolo_y': 0.0,\n","                'yolo_w': 0.0,\n","                'yolo_h': 0.0\n","            }\n","        filename = row['filename']\n","        json_path = row['path']\n","\n","        try:\n","            df_images, df_annotations, df_categories = json_to_df(json_path)\n","        except Exception as e:\n","            print(f\"JSON 파싱 오류 - 파일: {filename}, 오류: {e}\")\n","            error_files.append(filename)\n","            continue\n","\n","        if df_images.empty or df_annotations.empty:\n","            print(f\"데이터 부족 - 파일: {filename} (images: {len(df_images)}, annotations: {len(df_annotations)})\")\n","            error_files.append(filename)\n","            continue\n","\n","        img_row = df_images.iloc[0]\n","        ann_row = df_annotations.iloc[0]\n","        cat_row = df_categories.iloc[0] if not df_categories.empty else {}\n","\n","        png_match = df_png[df_png['file_name'] == img_row.get('file_name', None)]\n","        if png_match.empty:\n","            pbar.set_postfix_str(f\"이미지 파일 없음 - 파일: {filename}\")\n","            error_files.append(filename)\n","            continue\n","\n","        field['imgfile'] = png_match['path'].values[0]  # path가 여러 개면 첫 번째 값 사용\n","        filename_without_ext = os.path.splitext(os.path.basename(png_match['path'].iloc[0]))[0]\n","        field['filename'] = filename_without_ext\n","\n","        if pd.isna(field['imgfile']) | (field['imgfile'] is None):\n","            pbar.set_postfix_str(f\"이미지 파일명 누락 - 파일: {filename}\")\n","            error_files.append(filename)\n","            continue\n","\n","        # bbox 검증\n","        bbox = ann_row.get('bbox', [])\n","        if not bbox or len(bbox) < 4:\n","            print(f\"bbox 오류 - 파일: {filename}, bbox: {bbox}\")\n","            error_files.append(filename)\n","            continue\n","\n","        # YOLO bbox 계산\n","        yolo_result = bbox_to_yolo(bbox, img_row['width'], img_row['height'])\n","        if yolo_result is None:\n","            print(f\"YOLO 변환 오류 - 파일: {filename}\")\n","            error_files.append(filename)\n","            continue\n","\n","        x_center, y_center, w_norm, h_norm = yolo_result\n","\n","        # 기존 df row에 정보 추가\n","        field.update({\n","            'drug_N': img_row.get('drug_N'),\n","            'width': img_row.get('width'),\n","            'height': img_row.get('height'),\n","            'bbox_x': bbox[0],\n","            'bbox_y': bbox[1],\n","            'bbox_w': bbox[2],\n","            'bbox_h': bbox[3],\n","            'yolo_x': x_center,\n","            'yolo_y': y_center,\n","            'yolo_w': w_norm,\n","            'yolo_h': h_norm\n","        })\n","        records.append(field)\n","\n","        # 약 정보 dict (중복 제거)\n","        drug_N = img_row.get('drug_N')\n","        if drug_N and drug_N not in drug_info:\n","            drug_info[drug_N] = {\n","                'drug_N': drug_N,\n","                'drug_S': img_row.get('drug_S'),\n","                'dl_name': img_row.get('dl_name'),\n","                'dl_name_en': img_row.get('dl_name_en'),\n","                'img_key': img_row.get('img_key'),\n","                'dl_material': img_row.get('dl_material'),\n","                'dl_material_en': img_row.get('dl_material_en'),\n","                'dl_custom_shape': img_row.get('dl_custom_shape'),\n","                'dl_company': img_row.get('dl_company'),\n","                'dl_company_en': img_row.get('dl_company_en'),\n","                'di_class_no': img_row.get('di_class_no'),\n","                'di_etc_otc_code': img_row.get('di_etc_otc_code'),\n","                'di_edi_code': img_row.get('di_edi_code'),\n","                'chart': img_row.get('chart'),\n","                'drug_shape': img_row.get('drug_shape'),\n","                'form_code_name': img_row.get('form_code_name'),\n","                'supercategory': cat_row.get('supercategory', ''),\n","                'name': cat_row.get('name', '')\n","            }\n","        if idx % 100 == 0:\n","            pbar.set_postfix_str(filename)\n","\n","    print(f\"\\n=== 처리 결과 ===\")\n","    print(f\"전체 파일: {len(df)}\")\n","    print(f\"성공 처리: {len(records)}\")\n","    print(f\"오류 파일: {len(error_files)}\")\n","    if error_files:\n","        print(f\"오류 파일 목록 (처음 10개): {error_files[:10]}\")\n","\n","    df_new = pd.DataFrame(records)\n","    df_drug = pd.DataFrame(list(drug_info.values()))\n","\n","    train_df = df_new[df_new['Train'] == True]\n","    drug_classes = {drug_N: idx+1 for idx, drug_N in enumerate(sorted(train_df['drug_N'].unique()))}\n","\n","    df_new['class_id'] = train_df['drug_N'].map(drug_classes).fillna(0).astype(int)\n","    df_drug['class_id'] = df_drug['drug_N'].map(drug_classes).fillna(0).astype(int)\n","\n","    # df_drug = pd.DataFrame(list(drug_info.values()))\n","    # drug_classes = {drug_N: idx+1 for idx, drug_N in enumerate(sorted(df_new['drug_N'].unique()))}\n","    # df_new['class_id'] = df_new['drug_N'].map(drug_classes).fillna(0).astype(int)\n","    # df_drug['class_id'] = df_drug['drug_N'].map(drug_classes).fillna(0).astype(int)\n","\n","    return df_new, df_drug, drug_classes\n","\n","# os.path.join(kaggle_unzip_path, 'train_images')\n","def create_yolo_dataset(df_files, ignore=True):\n","    df = helper.pd_checkout(\"df_codeit04_new\", commit_dir=drive_root())\n","    df_drug = helper.pd_checkout(\"df_codeit04_drug\", commit_dir=drive_root())\n","    if df.empty or df_drug.empty or ignore:\n","        from datetime import datetime\n","        print(\"JSON 정보 수집 중...\")\n","        # 실행\n","        df, df_drug, _ = collect_json_info(df_files)\n","        print('df_new shape:', df.shape)\n","        print('df_drug shape:', df_drug.shape)\n","\n","        helper.pd_commit(df, \"df_codeit04_new\", commit_dir=drive_root())\n","        helper.pd_commit(df_drug, \"df_codeit04_drug\", commit_dir=drive_root())\n","\n","        print(\"df_codeit04_new, df_codeit04_drug 저장\")\n","    else:\n","        print(\"이미 df_codeit04_new, df_codeit04_drug가 존재함\")\n","\n","    df.sort_values(by='filename',inplace=True)\n","    df_drug.sort_values(by='drug_N',inplace=True)\n","    return df, df_drug\n","\n","df_train_test, df_drug = create_yolo_dataset(df_files = df_files, ignore=True)\n","drug_classes = dict(zip(df_drug['drug_N'], df_drug['class_id']))\n","drug_classes_idx = dict(zip(df_drug['class_id'], df_drug['drug_N']))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"jVOOXbUfKUGe","executionInfo":{"status":"ok","timestamp":1757602227246,"user_tz":-540,"elapsed":94,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# df를 class_id의 개수 별로 정렬하고\n","# Train = False이고 Test = False 이면 Validation 로 하자\n","# Test = True 이면 Test 로 하자\n","# Validation을 Train에서 램덤하게 0.3 정도 Train=False 로 하자\n","df = df_train_test.copy()\n","\n","# 1. class_id별로 정렬\n","df.sort_values('class_id', inplace=True)\n","\n","# 2. Validation 셋 지정 (Train=True & Test=False 중에서 class별로 30% 랜덤 선택)\n","for class_id in df['class_id'].unique():\n","    idxs = df[(df['class_id'] == class_id) & (df['Train'] == True) & (df['Test'] == False)].index\n","    n_val = max(1, int(len(idxs) * 0.3)) if len(idxs) > 0 else 0\n","    if n_val > 0:\n","        val_idxs = np.random.choice(idxs, n_val, replace=False)\n","        df.loc[val_idxs, 'Train'] = False  # Validation으로 변경\n","\n","# 3. set_type 컬럼 지정\n","df['set_type'] = np.where(df['Test'] == True, 'Test',\n","                  np.where(df['Train'] == True, 'Train', 'Validation'))\n","\n","df_train_val_test = df.copy()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"li81c7DVKUGg","outputId":"ed85d1fc-ee39-4d12-f442-ea9ee7acef17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757602233081,"user_tz":-540,"elapsed":2620,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Creating YOLO dataset: 100%|██████████| 5369/5369 [00:01<00:00, 3022.53it/s, K-003544-010221-016551-021026_0_2_0_2_90_000_200.png]\n"]},{"output_type":"stream","name":"stdout","text":["✅ 커밋 완료: 09b5fc2fcb89 | 2025-09-11 14:50:39 | df_codeit04_yolo\n"]}],"source":["def create_yolo_dataset(df, yolo_dataset_path):\n","    \"\"\"\n","                                              filename  ext                                             file_name                                                                                                                                                                             path                         label    drug0    drug1    drug2    drug3 Train  Test   drug_N width height bbox_x bbox_y bbox_w bbox_h yolo_x yolo_y yolo_w yolo_h class_id   set_type\n","  872 K-001900-016548-018110-027926_0_2_0_2_75_000_200 json K-001900-016548-018110-027926_0_2_0_2_75_000_200.json d:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\train_annotations\\K-001900-016548-018110-027926_json\\K-001900\\K-001900-016548-018110-027926_0_2_0_2_75_000_200.json K-001900-016548-018110-027926 K-001900 K-016548 K-018110 K-027926 False False K-001900   976   1280    142    241    200    127  0.248 0.2379 0.2049 0.0992        1 Validation\n","  870 K-001900-016548-018110-027926_0_2_0_2_70_000_200 json K-001900-016548-018110-027926_0_2_0_2_70_000_200.json d:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\train_annotations\\K-001900-016548-018110-027926_json\\K-001900\\K-001900-016548-018110-027926_0_2_0_2_70_000_200.json K-001900-016548-018110-027926 K-001900 K-016548 K-018110 K-027926 False False K-001900   976   1280    630    894    211    133 0.7536 0.7504 0.2162 0.1039        1 Validation\n","\n","dataset/\n","├── images/\n","│   ├── train/\n","│   │   ├── image1.jpg\n","│   │   ├── image2.jpg\n","│   │   └── ...\n","│   ├── val/\n","│   │   ├── val_image1.jpg\n","│   │   └── ...\n","│   └── test/ (선택적)\n","└── labels/\n","    ├── train/\n","    │   ├── image1.txt\n","    │   ├── image2.txt\n","    │   └── ...\n","    ├── val/\n","    │   ├── val_image1.txt\n","    │   └── ...\n","    └── test/ (선택적)\n","\n","    DataFrame df_convert_yolo를 만들고 df를 복사하고 to yolo_image_train, yolo_image_val, yolo_label_train, yolo_label_val를 만든다.\n","    df의 Train 컬럼을 참고 하면 된다.\n","    df_convert_yolo를 yolo_dataset_path에 저장한다. (원복등에 참고 할 수 있을 것이다.)\n","\n","    만들어진 df_convert_yolo 를 이용하여 images를 yolo_image_train, yolo_image_val에 이동시킨다.\n","    전체적인 데이타 용량이 큼으로 파일을 이동시키는 방식으로 한다.\n","\n","    \"\"\"\n","\n","    images_train_dir = os.path.join(yolo_dataset_path, 'images', 'train')\n","    images_val_dir = os.path.join(yolo_dataset_path, 'images', 'val')\n","    images_test_dir = os.path.join(yolo_dataset_path, 'images', 'test')\n","    labels_train_dir = os.path.join(yolo_dataset_path, 'labels', 'train')\n","    labels_val_dir = os.path.join(yolo_dataset_path, 'labels', 'val')\n","    labels_test_dir = os.path.join(yolo_dataset_path, 'labels', 'test')\n","\n","    df.sort_values('filename', inplace=True)\n","    df = df.reset_index(drop=True)\n","\n","    pbar = tqdm(df.iterrows(), total=len(df), mininterval=3, desc=\"Creating YOLO dataset\")\n","    for idx, row in pbar:\n","        set_type = row.get('set_type', 'Unknown')\n","        img_dst, label_dst = None, None\n","\n","        filename = row['filename']\n","        label_name = row['label']\n","        # 파일명에 _순서 붙이기\n","        base_img_name = f\"{filename}.png\"\n","        base_label_name = f\"{filename}.txt\"\n","\n","        if set_type == 'Train':\n","            img_dst = os.path.join(images_train_dir, base_img_name)\n","            label_dst = os.path.join(labels_train_dir, base_label_name)\n","        elif set_type == 'Validation':\n","            img_dst = os.path.join(images_val_dir, base_img_name)\n","            label_dst = os.path.join(labels_val_dir, base_label_name)\n","        elif set_type == 'Test':\n","            img_dst = os.path.join(images_test_dir, base_img_name)\n","            label_dst = os.path.join(labels_test_dir, base_label_name)\n","        else:\n","            continue\n","\n","        df.loc[idx, 'yolo_image'] = img_dst\n","        df.loc[idx, 'yolo_label'] = label_dst\n","\n","        if idx % 100 == 0:\n","            pbar.set_postfix_str(base_img_name)\n","\n","    return df\n","\n","def create_yolo_df(yolo_path, ignore=True):\n","    df = df_train_val_test.copy()\n","    df_yolo = helper.pd_checkout(\"df_codeit04_yolo\", commit_dir=drive_root())\n","    if df_yolo.empty | ignore:\n","        df_yolo = create_yolo_dataset(df, yolo_path)\n","        helper.pd_commit(df_yolo, \"df_codeit04_yolo\", commit_dir=drive_root())\n","    else:\n","        print(\"df_yolo 로드됨\")\n","    return df_yolo, yolo_path\n","\n","yolo_path  = os.path.join(root_dir, \"yolo\")\n","df_yolo, yolo_path = create_yolo_df(yolo_path, ignore=True)"]},{"cell_type":"markdown","metadata":{"id":"J1JkMr2VKUGg"},"source":["# 3. Image to Yolo File\n","- resize Iamge 640 x 480"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"yaLn4RYXKUGg","executionInfo":{"status":"ok","timestamp":1757602237157,"user_tz":-540,"elapsed":121,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","from sklearn.cluster import KMeans\n","\n","def create_rounded_mask(width, height, radius):\n","    \"\"\"OpenCV를 사용한 둥근 네모 마스크 생성\"\"\"\n","    mask = np.zeros((height, width), dtype=np.uint8)\n","\n","    if radius <= 0:\n","        mask[:, :] = 255\n","        return mask\n","\n","    # 반지름이 너무 크면 조정\n","    radius = min(radius, min(width, height) // 2)\n","\n","    # 둥근 사각형 그리기\n","    # 중앙 사각형들\n","    cv2.rectangle(mask, (radius, 0), (width - radius, height), 255, -1)\n","    cv2.rectangle(mask, (0, radius), (width, height - radius), 255, -1)\n","\n","    # 네 모서리에 원 그리기\n","    cv2.circle(mask, (radius, radius), radius, 255, -1)  # 좌상단\n","    cv2.circle(mask, (width - radius, radius), radius, 255, -1)  # 우상단\n","    cv2.circle(mask, (radius, height - radius), radius, 255, -1)  # 좌하단\n","    cv2.circle(mask, (width - radius, height - radius), radius, 255, -1)  # 우하단\n","\n","    return mask\n","\n","def get_combined_rect_with_margin(bboxes, img_shape, margin=20):\n","    \"\"\"\n","    여러 객체의 bbox를 합친 전체 rect를 계산하고 마진을 추가\n","\n","    Args:\n","        bboxes: 객체들의 bbox 리스트 [(x, y, w, h), ...]\n","        img_shape: 이미지 크기 (height, width)\n","        margin: 추가할 마진 크기\n","\n","    Returns:\n","        combined_rect: (x, y, w, h) 형태의 합쳐진 rect\n","    \"\"\"\n","    if not bboxes:\n","        return None\n","\n","    h, w = img_shape[:2]\n","\n","    # 모든 bbox의 최소/최대 좌표 계산\n","    min_x = min(bbox[0] for bbox in bboxes)\n","    min_y = min(bbox[1] for bbox in bboxes)\n","    max_x = max(bbox[0] + bbox[2] for bbox in bboxes)\n","    max_y = max(bbox[1] + bbox[3] for bbox in bboxes)\n","\n","    # 마진 추가\n","    min_x = max(0, min_x - margin)\n","    min_y = max(0, min_y - margin)\n","    max_x = min(w, max_x + margin)\n","    max_y = min(h, max_y + margin)\n","\n","    return (min_x, min_y, max_x - min_x, max_y - min_y)\n","\n","def extract_background_color_advanced(img, combined_rect, corner_radius=20, sample_size=1000):\n","    \"\"\"\n","    둥근 모서리로 잘라낸 객체 영역을 제외한 배경에서 평균 색상 추출\n","\n","    Args:\n","        img: 원본 이미지\n","        combined_rect: 객체들의 합쳐진 rect (x, y, w, h)\n","        corner_radius: 둥근 모서리 반지름\n","        sample_size: 배경색 추출을 위한 샘플 픽셀 수\n","\n","    Returns:\n","        bg_color: 배경색 (B, G, R)\n","    \"\"\"\n","    h, w = img.shape[:2]\n","\n","    # 전체 마스크 (배경 = 255, 객체 = 0)\n","    mask = np.ones((h, w), dtype=np.uint8) * 255\n","\n","    if combined_rect is not None:\n","        x, y, rect_w, rect_h = map(int, combined_rect)\n","\n","        # 둥근 모서리 마스크 생성\n","        rounded_mask = create_rounded_mask(rect_w, rect_h, corner_radius)\n","\n","        # 객체 영역에 둥근 마스크 적용 (해당 영역을 0으로 설정)\n","        if (x + rect_w <= w and y + rect_h <= h and\n","            x >= 0 and y >= 0 and rect_w > 0 and rect_h > 0):\n","            # 둥근 마스크를 이용해 객체 영역 제거\n","            mask[y:y+rect_h, x:x+rect_w] = rounded_mask\n","\n","    # 배경 영역 픽셀 추출\n","    background_pixels = img[mask == 255]\n","\n","    if len(background_pixels) == 0:\n","        # 배경이 없으면 ImageNet 평균값 사용\n","        return np.array([123, 117, 104], dtype=np.uint8)\n","\n","    # 너무 많은 픽셀이 있으면 랜덤 샘플링\n","    if len(background_pixels) > sample_size:\n","        indices = np.random.choice(len(background_pixels), sample_size, replace=False)\n","        background_pixels = background_pixels[indices]\n","\n","    # K-means를 사용해 주요 색상 추출\n","    try:\n","        kmeans = KMeans(n_clusters=min(3, len(background_pixels)), random_state=42, n_init=10)\n","        kmeans.fit(background_pixels)\n","\n","        # 가장 많은 픽셀을 가진 클러스터의 중심색을 배경색으로 선택\n","        labels = kmeans.labels_\n","        cluster_counts = np.bincount(labels)\n","        dominant_cluster = np.argmax(cluster_counts)\n","        bg_color = kmeans.cluster_centers_[dominant_cluster].astype(np.uint8)\n","\n","    except:\n","        # K-means 실패시 평균값 사용\n","        bg_color = np.mean(background_pixels, axis=0).astype(np.uint8)\n","\n","    return bg_color\n","\n","def create_cleaned_image_with_rounded_crop(img, combined_rect, bg_color, corner_radius=20):\n","    \"\"\"\n","    둥근 모서리로 잘라낸 객체 영역을 제외하고 배경색으로 채운 이미지 생성\n","\n","    Args:\n","        img: 원본 이미지\n","        combined_rect: 객체들의 합쳐진 rect (x, y, w, h)\n","        bg_color: 배경색\n","        corner_radius: 둥근 모서리 반지름\n","\n","    Returns:\n","        cleaned_img: 정리된 이미지\n","    \"\"\"\n","    h, w = img.shape[:2]\n","    cleaned_img = np.full_like(img, bg_color)\n","\n","    if combined_rect is not None:\n","        x, y, rect_w, rect_h = map(int, combined_rect)\n","\n","        # 안전 체크\n","        if (x + rect_w <= w and y + rect_h <= h and\n","            x >= 0 and y >= 0 and rect_w > 0 and rect_h > 0):\n","\n","            # 둥근 모서리 마스크 생성\n","            rounded_mask = create_rounded_mask(rect_w, rect_h, corner_radius)\n","\n","            # 객체 영역만 복사 (둥근 모서리 적용)\n","            roi = img[y:y+rect_h, x:x+rect_w]\n","\n","            # 마스크가 255인 부분만 복사\n","            mask_3ch = cv2.cvtColor(rounded_mask, cv2.COLOR_GRAY2BGR) / 255.0\n","\n","            cleaned_roi = (roi * mask_3ch +\n","                          bg_color.reshape(1, 1, 3) * (1 - mask_3ch)).astype(np.uint8)\n","\n","            cleaned_img[y:y+rect_h, x:x+rect_w] = cleaned_roi\n","\n","    return cleaned_img\n","\n","def resize_with_aspect_ratio_and_bg_advanced(img, target_size=(640, 480), bg_color=None):\n","    \"\"\"\n","    비율을 유지하며 리사이즈하고, 배경색으로 패딩 추가\n","    \"\"\"\n","    if bg_color is None:\n","        bg_color = [0, 0, 0]\n","\n","    h, w = img.shape[:2]\n","    target_w, target_h = target_size\n","\n","    # 스케일 계산 (비율 유지)\n","    scale = min(target_w / w, target_h / h)\n","    new_w, new_h = int(w * scale), int(h * scale)\n","\n","    # 리사이즈\n","    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n","\n","    # 배경색으로 패딩된 캔버스 생성\n","    result = np.full((target_h, target_w, 3), bg_color, dtype=np.uint8)\n","\n","    # 중앙에 배치\n","    x_offset = (target_w - new_w) // 2\n","    y_offset = (target_h - new_h) // 2\n","    result[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n","\n","    return result\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"U380f5XQKUGk","executionInfo":{"status":"ok","timestamp":1757602243246,"user_tz":-540,"elapsed":11,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def create_individual_object_masks(img, bboxes, corner_radius=20):\n","    \"\"\"\n","    각 객체별로 개별 마스크를 생성\n","\n","    Args:\n","        img: 원본 이미지\n","        bboxes: 객체들의 bbox 리스트 [(x, y, w, h), ...]\n","        corner_radius: 둥근 모서리 반지름\n","\n","    Returns:\n","        object_masks: 각 객체의 마스크 리스트\n","        combined_mask: 모든 객체를 합친 마스크\n","    \"\"\"\n","    h, w = img.shape[:2]\n","    object_masks = []\n","    combined_mask = np.zeros((h, w), dtype=np.uint8)\n","\n","    for bbox in bboxes:\n","        x, y, bbox_w, bbox_h = map(int, bbox)\n","\n","        # 안전 체크\n","        if (x + bbox_w <= w and y + bbox_h <= h and\n","            x >= 0 and y >= 0 and bbox_w > 0 and bbox_h > 0):\n","\n","            # 개별 객체 마스크 생성\n","            object_mask = np.zeros((h, w), dtype=np.uint8)\n","\n","            # 둥근 모서리 마스크 생성\n","            rounded_mask = create_rounded_mask(bbox_w, bbox_h, corner_radius)\n","\n","            # 해당 위치에 마스크 적용\n","            object_mask[y:y+bbox_h, x:x+bbox_w] = rounded_mask\n","\n","            object_masks.append(object_mask)\n","\n","            # 전체 마스크에 추가 (OR 연산)\n","            combined_mask = cv2.bitwise_or(combined_mask, object_mask)\n","\n","    return object_masks, combined_mask"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"wSwWCB9GKUGk","executionInfo":{"status":"ok","timestamp":1757602245179,"user_tz":-540,"elapsed":11,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["\n","def create_cleaned_image_with_individual_objects(img, bboxes, bg_color, corner_radius=20):\n","    \"\"\"\n","    개별 객체들만 유지하고 나머지는 배경색으로 채운 이미지 생성\n","\n","    Args:\n","        img: 원본 이미지\n","        bboxes: 라벨링된 객체들의 bbox 리스트 [(x, y, w, h), ...]\n","        bg_color: 배경색\n","        corner_radius: 둥근 모서리 반지름\n","\n","    Returns:\n","        cleaned_img: 정리된 이미지 (라벨링된 객체만 유지)\n","    \"\"\"\n","    h, w = img.shape[:2]\n","\n","    # 배경색으로 채운 캔버스 생성\n","    cleaned_img = np.full_like(img, bg_color)\n","\n","    if not bboxes:\n","        return cleaned_img\n","\n","    # 각 객체별 마스크 생성\n","    object_masks, combined_mask = create_individual_object_masks(img, bboxes, corner_radius)\n","\n","    # 각 객체를 개별적으로 복사\n","    for bbox, object_mask in zip(bboxes, object_masks):\n","        x, y, bbox_w, bbox_h = map(int, bbox)\n","\n","        # 안전 체크\n","        if (x + bbox_w <= w and y + bbox_h <= h and\n","            x >= 0 and y >= 0 and bbox_w > 0 and bbox_h > 0):\n","\n","            # 해당 영역의 마스크와 원본 이미지를 이용해 객체만 추출\n","            roi_mask = object_mask[y:y+bbox_h, x:x+bbox_w]\n","            roi_img = img[y:y+bbox_h, x:x+bbox_w]\n","            roi_bg = np.full_like(roi_img, bg_color)\n","\n","            # 마스크 적용 (객체 부분만 원본, 나머지는 배경색)\n","            mask_3ch = cv2.cvtColor(roi_mask, cv2.COLOR_GRAY2BGR) / 255.0\n","            blended_roi = (roi_img * mask_3ch + roi_bg * (1 - mask_3ch)).astype(np.uint8)\n","\n","            # 정리된 이미지에 복사\n","            cleaned_img[y:y+bbox_h, x:x+bbox_w] = blended_roi\n","\n","    return cleaned_img\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"lI53cXAEKUGl","executionInfo":{"status":"ok","timestamp":1757602246625,"user_tz":-540,"elapsed":21,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["\n","def extract_background_color_from_unlabeled_areas(img, bboxes, corner_radius=20, sample_size=1000):\n","    \"\"\"\n","    라벨링된 객체들을 제외한 영역에서 배경색 추출\n","\n","    Args:\n","        img: 원본 이미지\n","        bboxes: 라벨링된 객체들의 bbox 리스트\n","        corner_radius: 둥근 모서리 반지름\n","        sample_size: 배경색 추출을 위한 샘플 픽셀 수\n","\n","    Returns:\n","        bg_color: 배경색 (B, G, R)\n","    \"\"\"\n","    h, w = img.shape[:2]\n","\n","    if not bboxes:\n","        # bbox가 없으면 전체 이미지에서 평균 추출\n","        return np.mean(img.reshape(-1, 3), axis=0).astype(np.uint8)\n","\n","    # 라벨링된 객체들의 마스크 생성\n","    _, combined_mask = create_individual_object_masks(img, bboxes, corner_radius)\n","\n","    # 배경 마스크 (라벨링된 객체가 아닌 영역)\n","    background_mask = cv2.bitwise_not(combined_mask)\n","\n","    # 배경 영역 픽셀 추출\n","    background_pixels = img[background_mask == 255]\n","\n","    if len(background_pixels) == 0:\n","        # 배경이 없으면 ImageNet 평균값 사용\n","        return np.array([123, 117, 104], dtype=np.uint8)\n","\n","    # 너무 많은 픽셀이 있으면 랜덤 샘플링\n","    if len(background_pixels) > sample_size:\n","        indices = np.random.choice(len(background_pixels), sample_size, replace=False)\n","        background_pixels = background_pixels[indices]\n","\n","    # K-means를 사용해 주요 색상 추출\n","    try:\n","        kmeans = KMeans(n_clusters=min(3, len(background_pixels)), random_state=42, n_init=10)\n","        kmeans.fit(background_pixels)\n","\n","        # 가장 많은 픽셀을 가진 클러스터의 중심색을 배경색으로 선택\n","        labels = kmeans.labels_\n","        cluster_counts = np.bincount(labels)\n","        dominant_cluster = np.argmax(cluster_counts)\n","        bg_color = kmeans.cluster_centers_[dominant_cluster].astype(np.uint8)\n","\n","    except:\n","        # K-means 실패시 평균값 사용\n","        bg_color = np.mean(background_pixels, axis=0).astype(np.uint8)\n","\n","    return bg_color"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"KHPKMB_GKUGl","executionInfo":{"status":"ok","timestamp":1757602247789,"user_tz":-540,"elapsed":5,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def resize_with_aspect_ratio_simple(img, target_size):\n","    \"\"\"\n","    비율을 유지하며 이미지를 리사이즈하고 ImageNet 평균값으로 패딩\n","\n","    Args:\n","        img: 원본 이미지\n","        target_size: 목표 크기 (width, height)\n","\n","    Returns:\n","        resized_img: 리사이즈된 이미지\n","    \"\"\"\n","    target_w, target_h = target_size\n","    h, w = img.shape[:2]\n","\n","    # 비율 계산\n","    scale = min(target_w / w, target_h / h)\n","\n","    # 새로운 크기 계산\n","    new_w = int(w * scale)\n","    new_h = int(h * scale)\n","\n","    # 리사이즈\n","    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n","\n","    # ImageNet 평균값으로 배경 생성 (BGR 순서)\n","    imagenet_mean = [103.939, 116.779, 123.68]  # BGR 순서\n","    result = np.full((target_h, target_w, 3), imagenet_mean, dtype=np.uint8)\n","\n","    # 중앙 위치 계산\n","    start_x = (target_w - new_w) // 2\n","    start_y = (target_h - new_h) // 2\n","\n","    # 이미지 배치\n","    result[start_y:start_y + new_h, start_x:start_x + new_w] = resized\n","\n","    return result"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-0ApQERPKUGl","executionInfo":{"status":"ok","timestamp":1757602249434,"user_tz":-540,"elapsed":24,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def create_yolo_file(\n","    df_yolo,\n","    yolo_dataset_path,\n","    image_size=(640, 640),\n","    object_margin=30,\n","    corner_radius=20,\n","    ignore=True,\n","    no_label_erase=True,\n","):\n","    \"\"\"\n","    개선된 YOLO 데이터셋 생성 함수\n","\n","    Args:\n","        df_yolo: YOLO 데이터프레임\n","        yolo_dataset_path: 저장 경로\n","        image_size: 목표 이미지 크기\n","        object_margin: 객체 주변 마진\n","        corner_radius: 둥근 모서리 반지름\n","        ignore: 기존 파일 무시 여부\n","        no_label_erase: True이면 라벨링되지 않은 객체 제거, False이면 간단한 리사이즈만\n","    \"\"\"\n","    df_yolo = df_yolo.sort_values(\"imgfile\").reset_index(drop=True)\n","\n","    # 처리 모드 설정\n","    mode_desc = \"label-only\" if no_label_erase else \"simple resize\"\n","\n","    # 유니크한 filename 리스트 생성\n","    unique_filenames = df_yolo[\"filename\"].unique()\n","    pbar = tqdm(\n","        unique_filenames,\n","        total=len(unique_filenames),\n","        mininterval=3,\n","        desc=f\"Creating {mode_desc} YOLO dataset\",\n","    )\n","\n","    count = 0\n","    for filename in pbar:\n","        # 해당 filename의 모든 행들 가져오기\n","        filename_rows = df_yolo[df_yolo[\"filename\"] == filename]\n","        row = filename_rows.iloc[0]  # 첫 번째 행 사용 (같은 이미지이므로)\n","        src_img_path = row[\"imgfile\"]\n","        dest_img_path = row[\"yolo_image\"]\n","        set_type = row[\"set_type\"]\n","\n","        str_end = os.path.basename(dest_img_path)\n","\n","        org_image_size = (row[\"width\"], row[\"height\"])\n","        final_image_size = image_size\n","\n","        # 이미지 처리\n","        if not ignore and os.path.exists(dest_img_path):\n","            str_end += \" (이미 존재)\"\n","        else:\n","            try:\n","                dest_img_dir = os.path.dirname(dest_img_path)\n","                os.makedirs(dest_img_dir, exist_ok=True)\n","\n","                if os.path.exists(src_img_path):\n","                    # 원본 이미지 로드\n","                    img = cv2.imread(src_img_path)\n","                    if img is None:\n","                        print(f\"이미지 로드 실패: {src_img_path}\")\n","                        continue\n","\n","                    org_image_size = (img.shape[1], img.shape[0])  # (width, height)\n","\n","                    if set_type == \"Test\":\n","                        # Test 데이터: 간단한 리사이즈만 수행\n","                        final_img = resize_with_aspect_ratio_simple(img, image_size)\n","                    else:\n","                        # Train/Validation 데이터: 전체 전처리 수행\n","                        # filename_rows 같은 이미지의 모든 bbox 수집\n","                        bboxes = []\n","                        for _, same_row in filename_rows.iterrows():\n","                            if (\n","                                same_row[\"bbox_w\"] > 0\n","                                and same_row[\"bbox_h\"] > 0\n","                                and not pd.isna(same_row[\"bbox_x\"])\n","                            ):\n","                                bboxes.append(\n","                                    [\n","                                        same_row[\"bbox_x\"],\n","                                        same_row[\"bbox_y\"],\n","                                        same_row[\"bbox_w\"],\n","                                        same_row[\"bbox_h\"],\n","                                    ]\n","                                )\n","\n","                        if not no_label_erase:\n","                            # 간단한 리사이즈만 수행\n","                            final_img = resize_with_aspect_ratio_simple(img, image_size)\n","                        else:\n","                            # 라벨링되지 않은 영역에서 배경색 추출\n","                            bg_color = extract_background_color_from_unlabeled_areas(\n","                                img, bboxes, corner_radius\n","                            )\n","                            # 라벨링된 객체만 유지하고 나머지는 배경색으로 채움\n","                            cleaned_img = create_cleaned_image_with_individual_objects(\n","                                img, bboxes, bg_color, corner_radius\n","                            )\n","                            # 비율 유지 리사이즈 및 배경색 패딩\n","                            final_img = resize_with_aspect_ratio_and_bg_advanced(\n","                                cleaned_img, image_size, bg_color\n","                            )\n","\n","                    # 이미지 저장\n","                    cv2.imwrite(dest_img_path, final_img)\n","                    final_image_size = (final_img.shape[1], final_img.shape[0])  # (width, height)\n","                else:\n","                    print(f\"원본 이미지 파일 없음: {src_img_path}\")\n","                    continue\n","\n","            except Exception as e:\n","                print(f\"이미지 저장 오류: {dest_img_path}, {e}\")\n","\n","        # YOLO 라벨 파일 생성 (Test 데이터는 제외)\n","        if set_type != \"Test\":\n","            try:\n","                dest_label_path = row[\"yolo_label\"]\n","                if ignore or not os.path.exists(dest_label_path):\n","                    dest_label_dir = os.path.dirname(dest_label_path)\n","                    os.makedirs(dest_label_dir, exist_ok=True)\n","\n","                    with open(dest_label_path, \"w\", encoding=\"utf-8\") as f:\n","                        for _, label_row in filename_rows.iterrows():\n","                            # 원본 및 최종 이미지 사이즈\n","                            orig_w, orig_h = org_image_size  # (width, height)\n","                            tgt_w, tgt_h = final_image_size  # (width, height)\n","\n","                            # 기존 yolo_x, yolo_y, yolo_w, yolo_h (원본 이미지 기준)\n","                            x_center_orig = label_row[\"yolo_x\"] * orig_w\n","                            y_center_orig = label_row[\"yolo_y\"] * orig_h\n","                            w_orig = label_row[\"yolo_w\"] * orig_w\n","                            h_orig = label_row[\"yolo_h\"] * orig_h\n","\n","                            # 리사이즈 비율 및 패딩 계산\n","                            scale = min(tgt_w / orig_w, tgt_h / orig_h)\n","                            pad_x = (tgt_w - int(orig_w * scale)) // 2\n","                            pad_y = (tgt_h - int(orig_h * scale)) // 2\n","\n","                            # 리사이즈 및 패딩 적용\n","                            x_center_new = x_center_orig * scale + pad_x\n","                            y_center_new = y_center_orig * scale + pad_y\n","                            w_new = w_orig * scale\n","                            h_new = h_orig * scale\n","\n","                            # 최종 yolo 좌표 (변환된 이미지 기준)\n","                            x_center = x_center_new / tgt_w\n","                            y_center = y_center_new / tgt_h\n","                            w_norm = w_new / tgt_w\n","                            h_norm = h_new / tgt_h\n","\n","                            class_id = (\n","                                max(0, int(label_row[\"class_id\"]) - 1)\n","                                if label_row[\"class_id\"] > 0\n","                                else 0\n","                            )\n","                            f.write(\n","                                f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\"\n","                            )\n","\n","            except Exception as e:\n","                print(f\"라벨 저장 오류: {dest_label_path}, {e}\")\n","\n","        if count % 100 == 0:\n","            pbar.set_postfix_str(str_end)\n","        count += 1\n","\n","    # dataset.yaml 파일 생성\n","    df_drug_sort = df_drug.sort_values(by=\"class_id\")\n","    classnames = df_drug_sort[\"drug_N\"].tolist()\n","\n","    dataset_config = {\n","        \"path\": yolo_dataset_path,\n","        \"train\": \"images/train\",\n","        \"val\": \"images/val\",\n","        \"test\": \"images/test\",\n","        \"nc\": len(classnames),\n","        \"names\": classnames,\n","    }\n","\n","    yaml_path = os.path.join(yolo_dataset_path, \"dataset.yaml\")\n","\n","    print(yolo_dataset_path)\n","    print(yaml_path)\n","\n","    with open(yaml_path, \"w\") as f:\n","        yaml.dump(dataset_config, f, default_flow_style=False)\n","\n","    print(f\"\\n=== 처리 완료 ===\")\n","    print(f\"생성: {len(df_yolo)}\")\n","    print(f\"YAML 파일: {yaml_path}\")\n","\n","    return yaml_path\n","\n","\n","# # 1. 간단한 리사이즈만 (가장 빠름)\n","# yolo_path = os.path.join(root_dir, \"yolo_resize\")\n","# df_yolo, yolo_path = create_yolo_df(yolo_path, ignore=True)\n","# #df_yolo_test = df_yolo.iloc[2000:2100].copy()\n","# yaml_path = create_yolo_file(df_yolo_test, yolo_dataset_path=yolo_path)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"LNFgc1ahKUGl","outputId":"77a01267-de7e-4f3a-afc7-738afda6fbe5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757602385925,"user_tz":-540,"elapsed":130284,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Creating YOLO dataset: 100%|██████████| 5369/5369 [00:01<00:00, 2976.90it/s, K-003544-010221-016551-021026_0_2_0_2_90_000_200.png]\n"]},{"output_type":"stream","name":"stdout","text":["✅ 커밋 완료: b4dc3e242139 | 2025-09-11 14:51:03 | df_codeit04_yolo\n"]},{"output_type":"stream","name":"stderr","text":["Creating simple resize YOLO dataset: 100%|██████████| 2332/2332 [02:08<00:00, 18.16it/s, K-003544-010221-016548-029451_0_2_0_2_75_000_200.png]"]},{"output_type":"stream","name":"stdout","text":["~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_resize\n","~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_resize/dataset.yaml\n","\n","=== 처리 완료 ===\n","생성: 5369\n","YAML 파일: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_resize/dataset.yaml\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# # 실행\n","# 1. 간단한 리사이즈만 (가장 빠름)\n","yolo_path  = os.path.join(root_dir, \"yolo_resize\")\n","df_yolo, yolo_path = create_yolo_df(yolo_path, ignore=True)\n","yaml_path = create_yolo_file(df_yolo, yolo_path, no_label_erase=False, ignore=True)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"c464SJfYKUGl","outputId":"1813054a-4fa5-4ffc-de79-c321a004c851","colab":{"base_uri":"https://localhost:8080/","height":259,"referenced_widgets":["24816e0122cf4c058127b5a4e2cee908","d5676358062d41e39a3734d658d52a37","e0a75d1cd56e44788b3b4eb575d2ae2c","b098f041193a4882b2f8dad7815deb7d","d2a93d522b3f44c1a5bfaaab6b0e29ef","71d5cc6214c243d9ba22fd2982b157bf","d60d3d229d1f43de9808f6cf19d61d97","761c6eaa6d8b440a9225f6d6ed61117c","8a9be69c35014cbe85c96d4392265fc9","1e7961a59b744823b460a16a4d59193a","fd638b147d944be69005e5897720d3f4","fe8aeea207ed441d9aa2773db23c97d6","c419bc980fec415a944c6e6e2dd8ad98","d5086a914578434fb4a31403b5792a03","a8ebacd7e8e040328ff249ff891a601d","a42111a1c71c4cd28ec4394699586313","f83dd9a5bdd443f5b518d386a69eb075","e7e1efdc57684c219d9caf7b3f13c375","e71aa091bc7647c79b74ce754f3ad404","27add70b337647dca61c36c66fa8a943","1549aadb94ce422ebddabfde483ec2b4","fe60a5cc55d84ea0b86b03cf43e21caa"]},"executionInfo":{"status":"ok","timestamp":1757603842005,"user_tz":-540,"elapsed":287917,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Creating YOLO dataset:   0%|          | 0/5369 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24816e0122cf4c058127b5a4e2cee908"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 커밋 완료: 735a7cb92423 | 2025-09-11 15:12:42 | df_codeit04_yolo\n"]},{"output_type":"display_data","data":{"text/plain":["Creating label-only YOLO dataset:   0%|          | 0/2332 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8aeea207ed441d9aa2773db23c97d6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label\n","~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml\n","\n","=== 처리 완료 ===\n","생성: 5369\n","YAML 파일: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml\n"]}],"source":["# 2. 새로운 방식 (라벨링된 객체만 유지)\n","yolo_path  = os.path.join(root_dir, \"yolo_no_label\")\n","df_yolo, yolo_path = create_yolo_df(yolo_path, ignore=True)\n","yaml_path = create_yolo_file(df_yolo, yolo_path, no_label_erase=True, ignore=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkmRQLG9MlGp"},"outputs":[],"source":["raise ValueError(\"stop here\")"]},{"cell_type":"markdown","metadata":{"id":"Z4JFBb3HMlGp"},"source":["# 프로그래밍 Yolo"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWNUnPJkMlGp","executionInfo":{"status":"ok","timestamp":1757602426211,"user_tz":-540,"elapsed":26158,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"249c5bd5-9b8f-4ad4-8600-2a9b66552bec"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h로딩완료\n"]}],"source":["!pip install -q albumentations\n","!pip install -q ultralytics\n","!pip install -q roboflow\n","!pip install -q opencv-python\n","!pip install -q opencv-python-headless\n","print(\"로딩완료\")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orKJ7phmMlGp","executionInfo":{"status":"ok","timestamp":1757602434345,"user_tz":-540,"elapsed":5958,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"44eab525-a66e-496b-bafb-84457ec19d2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["🌐 https://c0z0c.github.io/jupyter_hangul\n","ℹ️ NumPy 2.0.2 (v2.x+): 호환성 모드 적용됨\n","Mounted at /content/drive\n","✅ 설정 완료: 한글 폰트, plt 전역 등록, pandas 확장, 캐시 기능\n","pd commit 저장 경로 = /content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'helper_c0z0c_dev' from '/content/helper_c0z0c_dev.py'>"]},"metadata":{},"execution_count":22}],"source":["from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n","import importlib\n","import helper_c0z0c_dev as helper\n","importlib.reload(helper)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adgC_6YVMlGp","executionInfo":{"status":"ok","timestamp":1757602438804,"user_tz":-540,"elapsed":10,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"79f51802-5cc8-46c7-b49c-e69011daea24"},"outputs":[{"output_type":"stream","name":"stdout","text":["라이브러리 로드 완료 사용장치:cuda\n"]}],"source":["# 기본 라이브러리\n","\n","# --- Scikit-learn: 데이터 전처리, 모델, 평가 ---\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import (\n","    fetch_california_housing, load_iris, make_moons, make_circles,\n","    load_breast_cancer, load_wine\n",")\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","from sklearn.metrics import average_precision_score\n","\n","# --- 기타 라이브러리 ---\n","from PIL import Image\n","from PIL import ImageFilter\n","from PIL import ImageDraw\n","import albumentations as A\n","import IPython.display\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","# --- PyTorch: 딥러닝 관련 ---\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import v2\n","from torchvision.datasets import CocoDetection\n","from torchvision.transforms import functional as TF\n","from torch.nn import CrossEntropyLoss\n","from collections import OrderedDict\n","\n","# --- 기타 ---\n","import re\n","import os\n","import sys\n","import copy\n","import json\n","import math\n","import random\n","import yaml\n","import shutil\n","import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timezone, timedelta\n","import pytz\n","__kst = pytz.timezone('Asia/Seoul')\n","\n","# GPU 설정\n","__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","__device_cpu = torch.device('cpu')\n","\n","  # 재현 가능한 결과를 위해\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if __device == 'cuda':\n","    torch.cuda.manual_seed_all(42)\n","\n","print(f\"라이브러리 로드 완료 사용장치:{__device}\")"]},{"cell_type":"markdown","metadata":{"id":"JfapF4EsMlGp"},"source":["### > 설정 < 플레그"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJ2Z8DJ5MlGq","executionInfo":{"status":"ok","timestamp":1757602445610,"user_tz":-540,"elapsed":8,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"4b8a413d-8878-45bd-9fa5-4b57c77bc4bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["이미지 원본크기:(640, 480) 모델입력크기:(640, 480) DEBUG_ON:False\n","평균 표준편차 {'mean_tensor': [0.485, 0.456, 0.406], 'std_tensor': [0.229, 0.224, 0.225], 'mean_rgb': [123, 116, 103], 'std_rgb': [58, 57, 57]}\n"]}],"source":["# 디버그 모드 (필요시 True로 변경)\n","DEBUG_ON = False\n","if not helper.is_colab:\n","    DEBUG_ON = True\n","\n","IMAGE_SIZE_ORG=(640,480)\n","IMAGE_SIZE=(640,480)\n","BATCH_SIZE=16\n","\n","__MEAN_TENSOR = [0.485, 0.456, 0.406]\n","__STD_TENSOR = [0.229, 0.224, 0.225]\n","__MEAN_RGB = [123, 116, 103]\n","__STD_RGB = [58, 57, 57]\n","\n","def mean_std(type=None, mean_tensor=None, std_tensor=None, mean_rgb=None, std_rgb=None):\n","    \"\"\"\n","    Mean (RGB): [0.485, 0.456, 0.406]\n","    Std (RGB):  [0.229, 0.224, 0.225]\n","    Mean (RGB, 0~255): [123, 116, 103]\n","    Std (RGB, 0~255):  [58, 57, 57]\n","    \"\"\"\n","    global __MEAN_TENSOR, __STD_TENSOR, __MEAN_RGB, __STD_RGB\n","    res_old = {\n","        \"mean_tensor\": __MEAN_TENSOR,\n","        \"std_tensor\": __STD_TENSOR,\n","        \"mean_rgb\": __MEAN_RGB,\n","        \"std_rgb\": __STD_RGB\n","    }\n","\n","    if mean_tensor is not None:\n","        __MEAN_TENSOR = mean_tensor\n","    if std_tensor is not None:\n","        __STD_TENSOR = std_tensor\n","    if mean_rgb is not None:\n","        __MEAN_RGB = mean_rgb\n","    if std_rgb is not None:\n","        __STD_RGB = std_rgb\n","\n","    res = {\n","        \"mean_tensor\": __MEAN_TENSOR,\n","        \"std_tensor\": __STD_TENSOR,\n","        \"mean_rgb\": __MEAN_RGB,\n","        \"std_rgb\": __STD_RGB\n","    }\n","\n","    if res_old != res:\n","        print(f\"변경사항 발견: { json.dumps(res_old, indent=2, ensure_ascii=False)} -> {json.dumps(res, indent=2, ensure_ascii=False)}\")\n","\n","    if type is None:\n","        return res\n","    return res.get(type, res)\n","\n","\n","print(f'이미지 원본크기:{IMAGE_SIZE_ORG} 모델입력크기:{IMAGE_SIZE} DEBUG_ON:{DEBUG_ON}')\n","print(f'평균 표준편차 {mean_std()}')"]},{"cell_type":"markdown","metadata":{"id":"S41xfQbvMlGq"},"source":["### 1.2. 유틸리티 함수"]},{"cell_type":"markdown","metadata":{"id":"tpJHEimnMlGq"},"source":["#### 1.2.1 기본 유틸리티 함수"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1gQK-nfMlGq","executionInfo":{"status":"ok","timestamp":1757602450481,"user_tz":-540,"elapsed":41,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"98468928-0a95-493a-8063-da0810663c47"},"outputs":[{"output_type":"stream","name":"stdout","text":["유틸리티 함수 로드 완료\n"]}],"source":["\n","def get_tqdm_kwargs_old():\n","    \"\"\"환경에 맞는 tqdm 설정 반환\"\"\"\n","    if helper.is_colab or 'ipykernel' in sys.modules:\n","        # Jupyter/Colab 환경\n","        # return {'disable': False, 'leave': True, 'position': 0, 'ncols': 60}  # 폭 60으로 지정\n","        return {'disable': False, 'leave': True, 'position': 0}\n","    else:\n","        # 일반 Python 환경\n","        #return {'disable': False, 'mininterval': 1, 'leave': True, 'ncols': 60}\n","        return {'disable': False, 'mininterval': 1, 'leave': True}\n","\n","def get_tqdm_kwargs():\n","    \"\"\"Widget 오류를 방지하는 안전한 tqdm 설정\"\"\"\n","    return {\n","        'disable': False,\n","        'leave': True,\n","        'file': sys.stdout,\n","        'ascii': True,  # ASCII 문자만 사용\n","        'dynamic_ncols': False,\n","#        'ncols': 80  # 고정 폭\n","    }\n","\n","def drive_root():\n","    root_path = os.path.join(\"D:\\\\\", \"GoogleDrive\")\n","    if helper.is_colab:\n","        root_path = os.path.join(\"/content/drive/MyDrive\")\n","    return root_path\n","\n","def get_path_modeling(add_path = None):\n","    modeling_path = \"modeling_yolo\"\n","    if DEBUG_ON:\n","        modeling_path = modeling_path +\"_debug\"\n","    path = os.path.join(drive_root(),modeling_path)\n","    if add_path is not None:\n","        path = os.path.join(path,add_path)\n","    return path\n","\n","def get_path_modeling_release(add_path = None):\n","    modeling_path = \"modeling_yolo\"\n","    path = os.path.join(drive_root(),modeling_path)\n","    if add_path is not None:\n","        path = os.path.join(path,add_path)\n","    return path\n","\n","def print_dir_tree(root, max_depth=2, list_count=3, indent=\"\"):\n","    import os\n","    if max_depth < 0:\n","        return\n","    try:\n","        items = os.listdir(root)\n","    except Exception as e:\n","        print(indent + f\"[Error] {e}\")\n","        return\n","\n","    img_count = len([f for f in os.listdir(root) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n","    for item in items:\n","        path = os.path.join(root, item)\n","        if os.path.isdir(path):\n","            print(indent + \"|-- \"+ item)\n","            # 이미지 파일 개수만 출력\n","            img_count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n","            if img_count > list_count:\n","                print(indent + \"   \"+ f\"[데이터파일: {img_count}개]\")\n","            print_dir_tree(root=path, max_depth=max_depth-1, list_count=list_count, indent=indent + \"   \")\n","        else:\n","            if list_count < img_count and item.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt')):\n","                continue\n","            print(indent + \"|-- \"+ item)\n","\n","def save_model_dict(model, path, pth_name, kwargs=None):\n","    \"\"\"모델 state_dict와 추가 정보를 저장\"\"\"\n","    def safe_makedirs(path):\n","        \"\"\"안전한 디렉토리 생성\"\"\"\n","        if os.path.exists(path) and not os.path.isdir(path):\n","            os.remove(path)  # 파일이면 삭제\n","        os.makedirs(path, exist_ok=True)\n","\n","    # 디렉토리 생성\n","    safe_makedirs(path)\n","\n","    # 모델 구조 정보 추출\n","    model_info = {\n","        'class_name': model.__class__.__name__,\n","        'init_args': {},\n","        'str': str(model),\n","        'repr': repr(model),\n","        'modules': [m.__class__.__name__ for m in model.modules()],\n","    }\n","\n","    # 생성자 인자 자동 추출(가능한 경우)\n","    if hasattr(model, '__dict__'):\n","        for key in ['in_ch', 'base_ch', 'num_classes', 'out_ch']:\n","            if hasattr(model, key):\n","                model_info['init_args'][key] = getattr(model, key)\n","\n","    # kwargs 처리\n","    extra_info = {}\n","    if kwargs is not None:\n","        if isinstance(kwargs, str):\n","            extra_info = json.loads(kwargs)\n","        elif isinstance(kwargs, dict):\n","            extra_info = kwargs\n","\n","    model_info.update(extra_info)\n","\n","    # 저장할 dict 구성\n","    save_dict = {\n","        'model_state': model.state_dict(),\n","        'class_name': model.__class__.__name__,\n","        'model_info': model_info,\n","    }\n","\n","    save_path = os.path.join(path, f\"{pth_name}.pth\")\n","    torch.save(save_dict, save_path)\n","    return save_path\n","\n","def load_model_dict(path, pth_name=None):\n","    \"\"\"\n","    save_model_dict로 저장한 모델을 불러오는 함수\n","    반환값: (model_state, model_info)\n","    \"\"\"\n","    import torch\n","    load_path = path\n","    if pth_name is not None:\n","        load_path = os.path.join(path, f\"{pth_name}.pth\")\n","    checkpoint = torch.load(load_path, map_location='cpu', weights_only=False)  # <-- 여기 추가\n","    model_state = checkpoint.get('model_state')\n","    model_info = checkpoint.get('model_info')\n","    model_info['file_name'] = os.path.basename(load_path)\n","    return model_state, model_info\n","\n","\n","def search_pth_files(base_path):\n","    \"\"\"\n","    입력된 경로의 하위 폴더들에서 pth 파일들을 검색\n","    \"\"\"\n","    pth_files = []\n","\n","    if not os.path.exists(base_path):\n","        print(f\"경로가 존재하지 않습니다: {base_path}\")\n","        return pth_files\n","\n","    print(f\"pth 파일 검색 시작: {base_path}\")\n","\n","    # 하위 폴더들을 순회하며 pth 파일 검색\n","    for root, dirs, files in os.walk(base_path):\n","        for file in files:\n","            if file.endswith('.pth'):\n","                pth_path = os.path.join(root, file)\n","                pth_files.append(pth_path)\n","\n","    # 결과 정리 및 출력\n","    if pth_files:\n","        print(f\"\\n발견된 pth 파일들 ({len(pth_files)}개):\")\n","        for i, pth_file in enumerate(pth_files, 1):\n","            # 상대 경로로 표시 (base_path 기준)\n","            rel_path = os.path.relpath(pth_file, base_path)\n","            print(f\" {i:2d}. {rel_path}\")\n","    else:\n","        print(\"pth 파일을 찾을 수 없습니다.\")\n","\n","    return pth_files\n","\n","def print_json_tree(data, indent=\"\", max_depth=4, _depth=0, list_count=2, print_value=True):\n","    \"\"\"\n","    JSON 객체를 지정한 단계(max_depth)까지 트리 형태로 출력\n","    - list 타입은 3개 이상일 때 개수만 출력\n","    - 하위 노드가 값일 경우 key(type) 형태로 출력\n","    - print_value=True일 때 key(type): 값 형태로 출력\n","    \"\"\"\n","    if _depth > max_depth:\n","        return\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            if isinstance(value, (dict, list)):\n","                print(f\"{indent}|-- {key}\")\n","                print_json_tree(value, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n","            else:\n","                if print_value:\n","                    print(f\"{indent}|-- {key}({type(value).__name__}): {value if len(str(value)) < 100 else f'{str(value)[:30]}...'}\")\n","                else:\n","                    print(f\"{indent}|-- {key}({type(value).__name__})\")\n","    elif isinstance(data, list):\n","        if len(data) > list_count:\n","            print(f\"{indent}|-- [list] ({len(data)} items)\")\n","        else:\n","            for i, item in enumerate(data):\n","                if isinstance(item, (dict, list)):\n","                    print(f\"{indent}|-- [{i}]\")\n","                    print_json_tree(item, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n","                else:\n","                    if print_value:\n","                        print(f\"{indent}|-- [{i}]({type(item).__name__}): {item if len(str(item)) < 100 else f'{str(item)[:30]}...'}\")\n","                    else:\n","                        print(f\"{indent}|-- [{i}]({type(item).__name__})\")\n","    else:\n","        if print_value:\n","            print(f\"{indent}{type(data).__name__}: {data if len(str(data)) < 100 else f'{str(data)[:30]}...'}\")\n","        else:\n","            print(f\"{indent}{type(data).__name__}\")\n","\n","def print_git_tree(data, indent=\"\", max_depth=3, _depth=0):\n","    \"\"\"\n","    PyTorch tensor/딕셔너리/리스트를 git tree 스타일로 출력\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","\n","    if _depth > max_depth:\n","        return\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            print(f\"{indent}├─ {key} [{type(value).__name__}]\")\n","            print_git_tree(value, indent + \"│  \", max_depth, _depth + 1)\n","    elif isinstance(data, (list, tuple)):\n","        for i, item in enumerate(data):\n","            print(f\"{indent}├─ [{i}] [{type(item).__name__}]\")\n","            print_git_tree(item, indent + \"│  \", max_depth, _depth + 1)\n","    elif torch.is_tensor(data):\n","        shape = tuple(data.shape)\n","        dtype = str(data.dtype)\n","        preview = str(data)\n","        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n","        print(f\"{indent}└─ Tensor shape={shape} dtype={dtype} preview={preview_str}\")\n","    elif isinstance(data, np.ndarray):\n","        shape = data.shape\n","        dtype = data.dtype\n","        preview = str(data)\n","        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n","        print(f\"{indent}└─ ndarray shape={shape} dtype={dtype} preview={preview_str}\")\n","    else:\n","        val_str = str(data)\n","        print(f\"{indent}└─ {type(data).__name__}: {val_str[:80]}{'...' if len(val_str)>80 else ''}\")\n","\n","\n","print(\"유틸리티 함수 로드 완료\")"]},{"cell_type":"markdown","metadata":{"id":"MSpb1Pp8MlGq"},"source":["## 2. 데이터 로드"]},{"cell_type":"markdown","metadata":{"id":"Ephz8BXVMlGq"},"source":["### 2.1. 데이터 다운로드"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjxsUVjUMlGq","executionInfo":{"status":"ok","timestamp":1757605349523,"user_tz":-540,"elapsed":443,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"0842dab0-0eda-4659-e1b5-b938ce20d643"},"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle_config_dir: /content/drive/MyDrive/\n","kaggle_code_it_data: ~/.cache/dataset/kaggle_code_it_data\n","root_dir: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip\n","yolo_path ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label\n","yaml_path: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml\n","get_path_data: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label\n"]}],"source":["# google drive root에 keggle.json 파일 필요합니다.\n","\n","#kaggle_code_it_data = \"~/.cache/kaggle_code_it_data\" if helper.is_colab else os.path.join(Path.cwd(),'dataset', 'kaggle_code_it_data')\n","kaggle_config_dir = \"/content/drive/MyDrive/\" if helper.is_colab else os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive')\n","print(\"kaggle_config_dir:\", kaggle_config_dir)\n","kaggle_code_it_data = os.path.join( '~/.cache/' if helper.is_colab else Path.cwd().drive + '\\\\','dataset', 'kaggle_code_it_data')\n","print(\"kaggle_code_it_data:\", kaggle_code_it_data)\n","\n","kaggle_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip')\n","kaggle_unzip_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip.unzip')\n","kaggle_unzip_path_test_images = os.path.join(kaggle_unzip_path, 'test_images')\n","kaggle_unzip_path_train_images = os.path.join(kaggle_unzip_path, 'train_images')\n","root_dir = os.path.join(kaggle_unzip_path)\n","#yolo_path  = os.path.join(root_dir, \"yolo_resize\")\n","yolo_path  = os.path.join(root_dir, \"yolo_no_label\")\n","yaml_path = os.path.join(yolo_path, \"dataset.yaml\")\n","\n","def get_path_data():\n","    path = yolo_path\n","    return path\n","\n","print(\"root_dir:\", root_dir)\n","print(\"yolo_path\",yolo_path)\n","print(\"yaml_path:\", yaml_path)\n","print(\"get_path_data:\", get_path_data())"]},{"cell_type":"markdown","metadata":{"id":"ZRk0o5CUMlGq"},"source":["## YOLO 모델링"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTZrT8TLMlGq","executionInfo":{"status":"ok","timestamp":1757605358844,"user_tz":-540,"elapsed":437,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"8958aee4-3c88-49bf-a6af-97056bbd210e"},"outputs":[{"output_type":"stream","name":"stdout","text":["사용 디바이스: cuda\n","CUDA 버전: 12.6\n","~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label\n","|-- images\n","   |-- val\n","      [데이터파일: 435개]\n","   |-- train\n","      [데이터파일: 1054개]\n","   |-- test\n","      [데이터파일: 843개]\n","|-- dataset.yaml\n","|-- labels\n","   |-- train.cache\n","   |-- val\n","      [데이터파일: 435개]\n","   |-- val.cache\n","   |-- train\n","      [데이터파일: 1054개]\n","데이터셋 설정:\n","클래스 수: 73\n","클래스 이름: ['K-001900', 'K-002483', 'K-003351', 'K-003483', 'K-003544', 'K-003743', 'K-003832', 'K-004378', 'K-004543', 'K-005094', 'K-005886', 'K-006192', 'K-006563', 'K-010221', 'K-012081', 'K-012247', 'K-012420', 'K-012778', 'K-013395', 'K-013900', 'K-016232', 'K-016262', 'K-016548', 'K-016551', 'K-016688', 'K-018110', 'K-018147', 'K-018357', 'K-019232', 'K-019552', 'K-019607', 'K-019861', 'K-020014', 'K-020238', 'K-020877', 'K-021026', 'K-021325', 'K-021771', 'K-022074', 'K-022347', 'K-022362', 'K-022627', 'K-023203', 'K-023223', 'K-024850', 'K-025367', 'K-025438', 'K-025469', 'K-027653', 'K-027733', 'K-027777', 'K-027926', 'K-027993', 'K-028763', 'K-029345', 'K-029451', 'K-029667', 'K-029871', 'K-030308', 'K-031705', 'K-031863', 'K-031885', 'K-032310', 'K-033009', 'K-033208', 'K-033878', 'K-033880', 'K-034597', 'K-035206', 'K-036637', 'K-038162', 'K-041768', 'K-044199']\n","훈련 경로: images/train\n","검증 경로: images/val\n","테스트 경로: images/test\n","\n","=== 데이터셋 정보 ===\n","훈련 이미지: 0개 (라벨: 1054개)\n","검증 이미지: 0개 (라벨: 435개)\n","테스트 이미지: 0개\n"]}],"source":["# YOLO 개고양이 분류 모델 테스트 (Google Colab)\n","# 데이터: 2564 train, 1100 valid, 3659 test (총 37개 품종 → 2개 클래스)\n","\n","# ============================================================================\n","# 1. 환경 설정 및 라이브러리 설치\n","# ============================================================================\n","from pathlib import Path\n","from ultralytics import YOLO\n","\n","\n","# GPU 확인\n","device = __device\n","print(f\"사용 디바이스: {device}\")\n","print(f\"CUDA 버전: {torch.version.cuda}\")\n","\n","# ============================================================================\n","# 2. 데이터셋 설정 및 확인\n","# ============================================================================\n","\n","# 데이터셋 경로 설정 (실제 경로에 맞게 수정)\n","#dataset_root = \"/root/.cache/yolo_dataset\"\n","\n","print(yolo_path)\n","print_dir_tree(root=yolo_path, max_depth=3,list_count=3)\n","#print_dir_tree(yaml_path, max_depth=3)\n","\n","# YAML 파일 내용 확인\n","with open(yaml_path, 'r') as f:\n","    dataset_config = yaml.safe_load(f)\n","\n","print(\"데이터셋 설정:\")\n","print(f\"클래스 수: {dataset_config['nc']}\")\n","print(f\"클래스 이름: {dataset_config['names']}\")\n","print(f\"훈련 경로: {dataset_config['train']}\")\n","print(f\"검증 경로: {dataset_config['val']}\")\n","print(f\"테스트 경로: {dataset_config.get('test', 'None')}\")\n","\n","# 데이터 분포 확인\n","def print_dataset_info():\n","    train_images = len(list(Path(f\"{yolo_path}/images/train\").glob(\"*.jpg\")))\n","    val_images = len(list(Path(f\"{yolo_path}/images/val\").glob(\"*.jpg\")))\n","    test_images = len(list(Path(f\"{yolo_path}/images/test\").glob(\"*.jpg\")))\n","\n","    train_labels = len(list(Path(f\"{yolo_path}/labels/train\").glob(\"*.txt\")))\n","    val_labels = len(list(Path(f\"{yolo_path}/labels/val\").glob(\"*.txt\")))\n","\n","    print(f\"\\n=== 데이터셋 정보 ===\")\n","    print(f\"훈련 이미지: {train_images}개 (라벨: {train_labels}개)\")\n","    print(f\"검증 이미지: {val_images}개 (라벨: {val_labels}개)\")\n","    print(f\"테스트 이미지: {test_images}개\")\n","\n","print_dataset_info()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYiHmKJIMlGq"},"outputs":[],"source":["raise ValueError(\"stop here\")"]},{"cell_type":"markdown","metadata":{"id":"d_ZyKQe7MlGu"},"source":["### 3.3 모델링 엔진"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udSHefYQMlGu","executionInfo":{"status":"ok","timestamp":1757607134333,"user_tz":-540,"elapsed":1742830,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"4ba84b8c-840a-4d70-d82a-16e6df518fb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["yaml_path= ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml\n","\n","=== YOLO 모델 훈련 시작 ===\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt': 100% ━━━━━━━━━━━━ 130.5MB 114.5MB/s 1.1s\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8x.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_20250912_0043, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/modeling_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/modeling_yolo/yolo_20250912_0043, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=73\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n","  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n","  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n"," 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n"," 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 22        [15, 18, 21]  1   8788267  ultralytics.nn.modules.head.Detect           [73, [320, 640, 640]]         \n","Model summary: 209 layers, 68,222,907 parameters, 68,222,891 gradients, 258.5 GFLOPs\n","\n","Transferred 589/595 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1904.9±530.2 MB/s, size: 114.0 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/labels/train.cache... 1054 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1054/1054 2.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 412.6±158.0 MB/s, size: 65.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/labels/val.cache... 435 images, 0 backgrounds, 2 corrupt: 100% ━━━━━━━━━━━━ 435/435 475.1Kit/s 0.0s\n","\u001b[34m\u001b[1mval: \u001b[0m/content/~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/images/val/K-003351-016262-018357_0_2_0_2_75_000_200.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.3707]\n","\u001b[34m\u001b[1mval: \u001b[0m/content/~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/images/val/K-003544-004543-012247-016551_0_2_0_2_70_000_200.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     7.0293]\n","Plotting labels to /content/drive/MyDrive/modeling_yolo/yolo_20250912_0043/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00013, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/modeling_yolo/yolo_20250912_0043\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/30      12.5G      0.237      3.006     0.8432         54        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 47.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.715      0.484      0.553      0.552\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/30      12.8G     0.1454      1.152     0.8051         58        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 47.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.9s\n","                   all        433       1323      0.869      0.749      0.901      0.899\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/30      12.5G     0.1552     0.7957     0.8064         77        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 47.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.9s\n","                   all        433       1323        0.8      0.866      0.933       0.93\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/30      12.8G     0.1527     0.6678     0.8031         71        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.892      0.904      0.955      0.951\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/30      12.7G     0.1435     0.5526     0.8056         73        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.913      0.898      0.965      0.964\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/30      12.7G     0.1339     0.4838     0.8022         65        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.906       0.92      0.963       0.96\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/30      12.7G     0.1263     0.4358     0.8007         55        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.906       0.96      0.975      0.974\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/30      12.7G     0.1241     0.4359     0.7986         59        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.953      0.953      0.983      0.981\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/30      12.8G     0.1201     0.3946     0.8019         58        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.9s\n","                   all        433       1323      0.949      0.984       0.99       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/30      12.8G     0.1201      0.352     0.7968         69        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323       0.95      0.968       0.99      0.988\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/30      12.7G     0.1165     0.3466     0.8011         66        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.964      0.968       0.99       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/30      12.8G     0.1121     0.3412     0.8003         67        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.939      0.987      0.987      0.986\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/30      12.7G      0.103     0.3054     0.8001         56        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.953      0.966       0.99      0.989\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/30      12.8G      0.102     0.2799     0.7966         66        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.968      0.984      0.991       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/30      12.8G     0.1019     0.2779     0.7947         57        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.971      0.972      0.991       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/30      12.7G    0.09924     0.2736     0.7938         54        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323       0.98      0.972      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/30      12.7G    0.09572     0.2442     0.7968         54        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.981      0.992      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/30      12.4G    0.08994     0.2272     0.7943         61        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323       0.97      0.994      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/30      12.7G    0.08777     0.2253      0.796         86        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.981      0.989      0.991       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/30      12.8G     0.0863     0.2208     0.7951         61        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.988      0.995      0.991      0.991\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/30      12.7G     0.0781     0.1459     0.7721         41        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 47.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.988      0.993      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/30      12.7G    0.07853     0.1391     0.7733         42        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.987      0.995      0.991       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/30      12.7G    0.07631     0.1342     0.7734         38        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.986      0.995      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/30      12.7G    0.07172     0.1295     0.7676         48        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.9s\n","                   all        433       1323       0.99      0.995      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/30      12.7G    0.07107     0.1169     0.7653         43        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.986      0.993      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/30      12.8G     0.0683     0.1154     0.7704         48        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.9s\n","                   all        433       1323      0.992      0.995      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/30      12.7G    0.06375     0.1054     0.7682         45        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.9s\n","                   all        433       1323       0.99      0.995      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/30      12.7G    0.05987     0.1033     0.7713         36        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.992      0.995      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/30      12.7G     0.0584    0.09531     0.7709         45        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.992      0.995      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/30      12.8G    0.05445    0.09301     0.7652         44        640: 100% ━━━━━━━━━━━━ 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.992      0.995      0.992      0.991\n","\n","30 epochs completed in 0.477 hours.\n","Optimizer stripped from /content/drive/MyDrive/modeling_yolo/yolo_20250912_0043/weights/last.pt, 136.9MB\n","Optimizer stripped from /content/drive/MyDrive/modeling_yolo/yolo_20250912_0043/weights/best.pt, 136.9MB\n","\n","Validating /content/drive/MyDrive/modeling_yolo/yolo_20250912_0043/weights/best.pt...\n","Ultralytics 8.3.198 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 112 layers, 68,193,867 parameters, 0 gradients, 257.8 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 1.8it/s 7.7s\n","                   all        433       1323      0.992      0.995      0.992      0.991\n","              K-001900         61         61      0.999          1      0.995      0.995\n","              K-002483         52         52      0.999          1      0.995      0.995\n","              K-003351         65         65      0.999      0.985       0.99       0.99\n","              K-003483        152        152          1          1      0.995      0.995\n","              K-003544         21         21      0.997          1      0.995      0.995\n","              K-003743         16         16      0.995          1      0.995      0.975\n","              K-003832         10         10      0.992        0.9      0.911      0.911\n","              K-004378         13         13      0.994          1      0.995      0.995\n","              K-004543          8          8      0.991          1      0.995      0.995\n","              K-005094         21         21      0.996          1      0.995      0.995\n","              K-005886         10         10      0.993          1      0.995      0.995\n","              K-006192         14         14      0.997          1      0.995      0.995\n","              K-006563          8          8      0.991          1      0.995      0.995\n","              K-010221          9          9      0.992          1      0.995      0.995\n","              K-012081         12         12      0.993      0.917      0.928      0.928\n","              K-012247          4          4      0.983          1      0.995      0.995\n","              K-012420          3          3      0.978          1      0.995      0.995\n","              K-012778         10         10      0.992          1      0.995      0.995\n","              K-013395         11         11      0.997          1      0.995      0.995\n","              K-013900          6          6      0.988          1      0.995      0.995\n","              K-016232         29         29      0.997          1      0.995      0.995\n","              K-016262         24         24      0.997          1      0.995      0.995\n","              K-016548         43         43      0.998      0.977      0.984      0.984\n","              K-016551         38         38      0.998          1      0.995      0.995\n","              K-016688          3          3       0.98          1      0.995      0.995\n","              K-018110          7          7      0.989          1      0.995      0.995\n","              K-018147          5          5       0.99          1      0.995      0.995\n","              K-018357          5          5      0.987          1      0.995      0.995\n","              K-019232         10         10      0.992          1      0.995      0.995\n","              K-019552         15         15      0.995          1      0.995      0.995\n","              K-019607         14         14      0.995          1      0.995      0.995\n","              K-019861         19         19      0.996          1      0.995      0.995\n","              K-020014          3          3          1          1      0.995      0.995\n","              K-020238         30         30      0.997          1      0.995      0.995\n","              K-020877         22         22      0.997          1      0.995      0.995\n","              K-021026         11         11          1          1      0.995      0.995\n","              K-021325          6          6      0.988          1      0.995      0.995\n","              K-021771          8          8      0.991          1      0.995      0.995\n","              K-022074         12         12      0.994          1      0.995      0.995\n","              K-022347         26         26      0.997          1      0.995      0.995\n","              K-022362         11         11      0.995          1      0.995      0.995\n","              K-022627          9          9      0.993          1      0.995      0.995\n","              K-023203          1          1          1          1      0.995      0.995\n","              K-023223         10         10      0.993          1      0.995      0.995\n","              K-024850         12         12      0.995          1      0.995      0.995\n","              K-025367         26         26      0.997          1      0.995      0.995\n","              K-025438         18         18      0.996          1      0.995      0.995\n","              K-025469         27         27      0.997          1      0.995      0.995\n","              K-027653         16         16      0.995          1      0.995      0.995\n","              K-027733         34         34      0.967      0.941      0.948      0.948\n","              K-027777         31         31      0.998          1      0.995      0.995\n","              K-027926         11         11      0.994          1      0.995      0.995\n","              K-027993          3          3      0.979          1      0.995      0.995\n","              K-028763         22         22      0.997          1      0.995      0.995\n","              K-029345         12         12      0.994          1      0.995      0.995\n","              K-029451          8          8      0.991          1      0.995      0.995\n","              K-029667         30         30      0.998          1      0.995      0.995\n","              K-029871          1          1      0.958          1      0.995      0.995\n","              K-030308         26         26      0.997          1      0.995      0.987\n","              K-031705         10         10      0.992          1      0.995      0.995\n","              K-031863          6          6          1          1      0.995      0.995\n","              K-031885         25         25          1      0.962      0.995      0.995\n","              K-032310          3          3      0.984          1      0.995      0.995\n","              K-033009         11         11      0.993          1      0.995      0.995\n","              K-033208          7          7          1          1      0.995      0.995\n","              K-033878          1          1      0.955          1      0.995      0.995\n","              K-033880          8          8      0.991          1      0.995      0.995\n","              K-034597         29         29      0.965          1      0.995      0.995\n","              K-035206         30         30      0.964      0.967      0.954      0.954\n","              K-036637         30         30      0.998          1      0.995      0.995\n","              K-038162          6          6      0.991          1      0.995      0.995\n","              K-041768          6          6      0.988          1      0.995      0.995\n","              K-044199          7          7       0.99          1      0.995      0.995\n","Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/modeling_yolo/yolo_20250912_0043\u001b[0m\n"]}],"source":["# ============================================================================\n","# 3. YOLO 모델 학습\n","# ============================================================================\n","\n","print(\"yaml_path=\",yaml_path)\n","\n","def train_yolo_model(yaml_path=yaml_path):\n","    \"\"\"YOLO 모델 훈련\"\"\"\n","    # YOLOv8n 모델 로드 (가장 빠른 버전)\n","    model = YOLO('yolov8x.pt')\n","    #model = YOLO('yolov8n.pt')  # nano 버전으로 빠른 테스트\n","    #model = YOLO('yolov8s.pt')  # nano 버전으로 빠른 테스트\n","\n","    model_save_name = f\"yolo_{datetime.now(__kst).strftime('%Y%m%d_%H%M')}\"\n","    # 훈련 설정\n","    results = model.train(\n","        data=yaml_path,           # 데이터셋 설정 파일\n","        epochs=30,                # 에포크 수 (테스트용으로 50)\n","        imgsz=640,               # 이미지 크기\n","        batch=16,                # 배치 크기\n","        device=__device,           # GPU 사용\n","        project=get_path_modeling(),  # 프로젝트 이름\n","        name=model_save_name,       # 실험 이름\n","        save_period=10,          # 10 에포크마다 저장\n","        patience=10,             # 조기 종료 설정\n","        resume=False,            # 처음부터 시작\n","        verbose=True             # 자세한 로그 출력\n","    )\n","\n","    return model, results, model_save_name\n","\n","# 훈련 시작\n","print(\"\\n=== YOLO 모델 훈련 시작 ===\")\n","model, train_results, model_save_name = train_yolo_model(yaml_path=yaml_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahzyEaU1MlGv"},"outputs":[],"source":["model_save_name = f\"yolo_{datetime.now(__kst).strftime('%Y%m%d_%H%M')}\"\n","print(model_save_name)\n","yolo_best_model_path = os.path.join(get_path_modeling(), model_save_name, \"weights\", \"best.pt\")\n","print(f\"최적 모델 경로: {yolo_best_model_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezrx3HeeMlGv"},"outputs":[],"source":["# ============================================================================\n","# 4. 훈련 결과 분석\n","# ============================================================================\n","\n","def analyze_training_results():\n","    \"\"\"훈련 결과 분석 및 시각화\"\"\"\n","    # 결과 경로\n","    results_path = os.path.join(get_path_modeling(), 'yolo_20250906_205051')\n","\n","    # 훈련 곡선 표시\n","    if os.path.exists(f\"{results_path}/results.png\"):\n","        img = Image.open(f\"{results_path}/results.png\")\n","        plt.figure(figsize=(12, 8))\n","        plt.imshow(img)\n","        plt.axis('off')\n","        plt.title(\"YOLO 훈련 결과\")\n","        plt.show()\n","\n","    # 혼동 행렬 표시\n","    if os.path.exists(f\"{results_path}/confusion_matrix.png\"):\n","        img = Image.open(f\"{results_path}/confusion_matrix.png\")\n","        plt.figure(figsize=(8, 6))\n","        plt.imshow(img)\n","        plt.axis('off')\n","        plt.title(\"혼동 행렬 (Confusion Matrix)\")\n","        plt.show()\n","\n","    # F1 곡선 표시\n","    if os.path.exists(f\"{results_path}/F1_curve.png\"):\n","        img = Image.open(f\"{results_path}/F1_curve.png\")\n","        plt.figure(figsize=(8, 6))\n","        plt.imshow(img)\n","        plt.axis('off')\n","        plt.title(\"F1 점수 곡선\")\n","        plt.show()\n","\n","analyze_training_results()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_sdVcvaMlGv"},"outputs":[],"source":["# ============================================================================\n","# 5. 모델 검증 및 mAP 계산\n","# ============================================================================\n","\n","def validate_model():\n","    \"\"\"검증 데이터로 모델 성능 평가\"\"\"\n","    # 최고 성능 모델 로드\n","    best_model = YOLO(os.path.join(get_path_modeling_release(), 'yolo_20250906_205051','weights','best.pt'))\n","\n","    # 검증 수행\n","    val_results = best_model.val(\n","        data=yaml_path,\n","        imgsz=640,\n","        batch=16,\n","        device=device\n","    )\n","\n","    print(\"\\n=== 검증 결과 ===\")\n","    print(f\"mAP@0.5: {val_results.box.map50:.3f}\")\n","    print(f\"mAP@0.5:0.95: {val_results.box.map:.3f}\")\n","    print(f\"Precision: {val_results.box.mp:.3f}\")\n","    print(f\"Recall: {val_results.box.mr:.3f}\")\n","\n","    # 클래스별 성능\n","    if hasattr(val_results.box, 'maps'):\n","        class_names = ['cat', 'dog']  # 추정\n","        for i, class_name in enumerate(class_names):\n","            if i < len(val_results.box.maps):\n","                print(f\"{class_name} mAP@0.5: {val_results.box.maps[i]:.3f}\")\n","\n","    return best_model, val_results\n","\n","# 모델 검증\n","print(\"\\n=== 모델 검증 시작 ===\")\n","best_model, validation_results = validate_model()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ihx241b4MlGv"},"outputs":[],"source":["print_dir_tree(yolo_dataset_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgv2dIlAMlGv"},"outputs":[],"source":["from pathlib import Path\n","\n","def test_on_samples(best_model):\n","    \"\"\"테스트 이미지에서 샘플 예측\"\"\"\n","    test_dir = os.path.join(yolo_dataset_path, 'images', 'test')\n","    test_images = list(Path(test_dir).glob(\"*.jpg\"))[:12]  # 처음 12개만\n","\n","    if not test_images:\n","        print(\"테스트 이미지를 찾을 수 없습니다.\")\n","        return\n","\n","    print(f\"\\n=== {len(test_images)}개 테스트 이미지 예측 ===\")\n","\n","    # 예측 수행\n","    results = best_model(test_images)\n","\n","    # 결과 시각화\n","    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n","    axes = axes.flatten()\n","\n","    class_names = ['cat', 'dog']\n","\n","    for idx, (result, ax) in enumerate(zip(results, axes)):\n","        img = result.orig_img\n","        annotated = result.plot()\n","        ax.imshow(annotated)\n","        ax.axis('off')\n","        if len(result.boxes) > 0:\n","            conf = result.boxes.conf[0].item()\n","            cls = int(result.boxes.cls[0].item())\n","            pred_class = class_names[cls] if cls < len(class_names) else 'unknown'\n","            ax.set_title(f'{pred_class} ({conf:.2f})')\n","        else:\n","            ax.set_title('No Detection')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 테스트 샘플 예측\n","test_on_samples(best_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJW2px3eMlGv"},"outputs":[],"source":["\n","# ============================================================================\n","# 7. 성능 요약 및 개선 방안\n","# ============================================================================\n","\n","def performance_summary():\n","    \"\"\"성능 요약 및 분석\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"                    성능 요약\")\n","    print(\"=\"*60)\n","\n","    # 데이터셋 정보\n","    print(f\"📊 데이터셋 규모:\")\n","    print(f\"   - 훈련: 2,564개\")\n","    print(f\"   - 검증: 1,100개\")\n","    print(f\"   - 테스트: 3,659개\")\n","    print(f\"   - 총 클래스: 2개 (고양이/강아지)\")\n","    print(f\"   - 품종 수: 37개 (고양이 12개, 강아지 25개)\")\n","\n","    print(f\"\\n🎯 모델 성능:\")\n","    if 'validation_results' in globals():\n","        print(f\"   - mAP@0.5: {validation_results.box.map50:.1%}\")\n","        print(f\"   - mAP@0.5:0.95: {validation_results.box.map:.1%}\")\n","        print(f\"   - Precision: {validation_results.box.mp:.1%}\")\n","        print(f\"   - Recall: {validation_results.box.mr:.1%}\")\n","\n","    print(f\"\\n💡 개선 방안:\")\n","    print(\"   1. 에포크 수 증가 (100-200 epochs)\")\n","    print(\"   2. 더 큰 모델 사용 (YOLOv8s, YOLOv8m)\")\n","    print(\"   3. 데이터 증강 기법 적용\")\n","    print(\"   4. 하이퍼파라미터 튜닝\")\n","    print(\"   5. 앙상블 모델 적용\")\n","\n","performance_summary()\n","\n","# ============================================================================\n","# 8. 추가 분석 함수들\n","# ============================================================================\n","\n","from pathlib import Path\n","def analyze_class_distribution():\n","    \"\"\"클래스별 데이터 분포 분석\"\"\"\n","    train_label_dir = Path(os.path.join(yolo_dataset_path, 'labels', 'train'))\n","\n","    cat_count = 0\n","    dog_count = 0\n","\n","    for label_file in train_label_dir.glob(\"*.txt\"):\n","        with open(label_file, 'r') as f:\n","            lines = f.readlines()\n","            for line in lines:\n","                class_id = int(line.split()[0])\n","                if class_id == 0:  # 고양이 (추정)\n","                    cat_count += 1\n","                elif class_id == 1:  # 강아지 (추정)\n","                    dog_count += 1\n","\n","    print(f\"\\n=== 훈련 데이터 클래스 분포 ===\")\n","    print(f\"고양이 객체 수: {cat_count}개\")\n","    print(f\"강아지 객체 수: {dog_count}개\")\n","    print(f\"총 객체 수: {cat_count + dog_count}개\")\n","\n","    # 분포 시각화\n","    plt.figure(figsize=(8, 6))\n","    plt.bar(['Cat', 'Dog'], [cat_count, dog_count],\n","            color=['orange', 'skyblue'], alpha=0.7)\n","    plt.title('훈련 데이터 클래스 분포')\n","    plt.ylabel('객체 수')\n","    plt.show()\n","\n","# 클래스 분포 분석 실행\n","analyze_class_distribution()\n","\n","print(\"\\n🎉 YOLO 테스트 완료!\")\n","print(\"더 자세한 결과는 'yolo_pet_detection/cat_dog_v1' 폴더를 확인하세요.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2TagaMdpMlGv"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n","ret, frame = cap.read()\n","cap.release()\n","\n","if ret and frame is not None:\n","    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","    plt.axis('off')\n","    plt.show()\n","else:\n","    print(\"카메라 프레임을 읽을 수 없습니다.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1R4i4XDuMlGv"},"outputs":[],"source":["def yolo_live_cam_counter(yolo_best_model_path=yolo_best_model_path):\n","    model = YOLO(yolo_best_model_path)\n","    class_names = ['cat', 'dog']\n","\n","    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n","    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n","    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n","\n","    detection_counts = {'cat': 0, 'dog': 0, 'none': 0}\n","    frame_count = 0\n","\n","    print(\"탐지 카운터 모드 (ESC로 종료)\")\n","    print(\"10초마다 결과를 요약해서 출력합니다.\")\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        results = model(frame, verbose=False, conf=0.6)\n","        annotated_frame = results[0].plot()\n","\n","        # 탐지 결과 카운트\n","        if len(results[0].boxes) > 0:\n","            cls = int(results[0].boxes.cls[0].item())\n","            detected_class = class_names[cls]\n","            detection_counts[detected_class] += 1\n","        else:\n","            detection_counts['none'] += 1\n","\n","        frame_count += 1\n","\n","        # 10초마다 (300프레임) 요약 출력\n","        if frame_count % 300 == 0:\n","            total = sum(detection_counts.values())\n","            print(f\"\\n=== {frame_count//30}초 경과 ===\")\n","            print(f\"고양이: {detection_counts['cat']}회 ({detection_counts['cat']/total*100:.1f}%)\")\n","            print(f\"강아지: {detection_counts['dog']}회 ({detection_counts['dog']/total*100:.1f}%)\")\n","            print(f\"미탐지: {detection_counts['none']}회 ({detection_counts['none']/total*100:.1f}%)\")\n","\n","        cv2.imshow('YOLO 카운터', annotated_frame)\n","\n","        if cv2.waitKey(1) & 0xFF == 27:\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","    # 최종 결과\n","    print(\"\\n=== 최종 결과 ===\")\n","    total = sum(detection_counts.values())\n","    for class_name, count in detection_counts.items():\n","        print(f\"{class_name}: {count}회 ({count/total*100:.1f}%)\")\n","\n","# 카운터 버전 실행\n","yolo_live_cam_counter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XS-XquGMlGv"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","from IPython.display import display, clear_output, HTML\n","import time\n","from ultralytics import YOLO\n","import threading\n","import base64\n","from io import BytesIO\n","\n","# 방법 1: 주기적 업데이트 방식\n","def yolo_live_cam_notebook(yolo_best_model_path=yolo_best_model_path, duration=30):\n","    \"\"\"\n","    노트북에서 실시간 YOLO 탐지 (주기적 화면 갱신)\n","    duration: 실행 시간(초)\n","    \"\"\"\n","    model = YOLO(yolo_best_model_path)\n","    class_names = ['cat', 'dog']\n","\n","    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n","    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n","    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n","\n","    detection_counts = {'cat': 0, 'dog': 0, 'none': 0}\n","    start_time = time.time()\n","    frame_count = 0\n","\n","    print(f\"YOLO 실시간 탐지 시작 ({duration}초간 실행)\")\n","\n","    try:\n","        results = None\n","        while time.time() - start_time < duration:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","\n","            # YOLO 탐지 (매 5프레임마다)\n","            if frame_count % 10 == 0:\n","                results = model(frame, verbose=False, conf=0.6)\n","                annotated_frame = results[0].plot()\n","\n","                # 탐지 결과 카운트\n","                if len(results[0].boxes) > 0:\n","                    cls = int(results[0].boxes.cls[0].item())\n","                    detected_class = class_names[cls]\n","                    detection_counts[detected_class] += 1\n","                    conf = results[0].boxes.conf[0].item()\n","                    current_detection = f\"{detected_class} ({conf:.2f})\"\n","                else:\n","                    detection_counts['none'] += 1\n","                    current_detection = \"미탐지\"\n","\n","                # 2초마다 화면 업데이트 (60프레임마다)\n","            if results is not None:\n","                if frame_count % 2 == 0:\n","                    clear_output(wait=True)\n","\n","                    # 현재 프레임 표시\n","                    plt.figure(figsize=(12, 8))\n","\n","                    plt.subplot(2, 2, 1)\n","                    plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n","                    plt.title(f'현재 탐지: {current_detection}')\n","                    plt.axis('off')\n","\n","                    # 통계 그래프\n","                    plt.subplot(2, 2, 2)\n","                    total = sum(detection_counts.values())\n","                    if total > 0:\n","                        labels = list(detection_counts.keys())\n","                        values = [detection_counts[k] for k in labels]\n","                        colors = ['orange', 'skyblue', 'lightgray']\n","\n","                        plt.pie(values, labels=labels, colors=colors, autopct='%1.1f%%')\n","                        plt.title(f'탐지 분포 (총 {total}프레임)')\n","\n","                    # 시간별 통계\n","                    plt.subplot(2, 1, 2)\n","                    elapsed = time.time() - start_time\n","                    remaining = duration - elapsed\n","\n","                    bars = plt.bar(labels, [detection_counts[k] for k in labels], color=colors)\n","                    plt.title(f'탐지 횟수 (경과: {elapsed:.1f}s, 남음: {remaining:.1f}s)')\n","                    plt.ylabel('횟수')\n","\n","                    # 값 표시\n","                    for bar, value in zip(bars, [detection_counts[k] for k in labels]):\n","                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n","                               str(value), ha='center', va='bottom')\n","\n","                    plt.tight_layout()\n","                    plt.show()\n","\n","\n","            frame_count += 1\n","            # ESC 또는 q 키 입력 시 중단\n","            key = cv2.waitKey(1) & 0xFF\n","            if key == 27 or key == ord('q'):\n","                print(\"사용자 입력(q 또는 ESC)으로 중단합니다.\")\n","                break\n","            # duration 초 경과 시 자동 중단\n","            if time.time() - start_time > duration:\n","                print(\"설정된 시간이 경과하여 자동 중단합니다.\")\n","                break\n","            time.sleep(0.03)  # 약 30 FPS\n","\n","    except KeyboardInterrupt:\n","        print(\"\\n사용자에 의해 중단되었습니다.\")\n","    finally:\n","        cap.release()\n","\n","        # 최종 결과\n","        print(f\"\\n=== 최종 결과 ===\")\n","        total = sum(detection_counts.values())\n","        for class_name, count in detection_counts.items():\n","            if total > 0:\n","                percentage = count/total*100\n","                print(f\"{class_name}: {count}회 ({percentage:.1f}%)\")\n","\n","# 실행\n","yolo_live_cam_notebook(duration=20)  # 30초간 실행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LUpx28KtMlGv"},"outputs":[],"source":["yolo_live_cam_notebook(duration=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fs1KSs1KMlGw"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","from IPython.display import display, clear_output\n","import time\n","from ultralytics import YOLO\n","\n","def yolo_mp4_notebook(mp4_path, yolo_best_model_path=yolo_best_model_path, max_frames=500):\n","    \"\"\"\n","    mp4 동영상에서 YOLO 탐지 결과를 노트북에서 시각화\n","    mp4_path: 동영상 파일 경로\n","    max_frames: 최대 처리 프레임 수 (None이면 전체)\n","    \"\"\"\n","    model = YOLO(yolo_best_model_path)\n","    class_names = ['cat', 'dog']\n","\n","    cap = cv2.VideoCapture(mp4_path)\n","    if not cap.isOpened():\n","        print(f\"동영상 파일을 열 수 없습니다: {mp4_path}\")\n","        return\n","\n","    detection_counts = {'cat': 0, 'dog': 0, 'none': 0}\n","    frame_count = 0\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print(f\"YOLO mp4 탐지 시작 (총 {total_frames}프레임, 최대 {max_frames if max_frames else total_frames}프레임)\")\n","\n","    try:\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                print(\"동영상 프레임을 더 이상 읽을 수 없습니다.\")\n","                break\n","\n","            results = model(frame, verbose=False, conf=0.6)\n","            annotated_frame = results[0].plot()\n","\n","            # 탐지 결과 카운트\n","            if len(results[0].boxes) > 0:\n","                for box in results[0].boxes:\n","                    cls = int(box.cls.item())\n","                    detected_class = class_names[cls]\n","                    detection_counts[detected_class] += 1\n","                conf = results[0].boxes.conf[0].item()\n","                current_detection = f\"{detected_class} ({conf:.2f})\"\n","            else:\n","                detection_counts['none'] += 1\n","                current_detection = \"미탐지\"\n","\n","            # 10프레임마다 화면 업데이트\n","            if frame_count % 10 == 0:\n","                clear_output(wait=True)\n","                plt.figure(figsize=(12, 8))\n","                plt.subplot(2, 2, 1)\n","                plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n","                plt.title(f'현재 탐지: {current_detection} (프레임 {frame_count}/{total_frames})')\n","                plt.axis('off')\n","\n","                # 통계 그래프\n","                plt.subplot(2, 2, 2)\n","                total = sum(detection_counts.values())\n","                labels = list(detection_counts.keys())\n","                values = [detection_counts[k] for k in labels]\n","                colors = ['orange', 'skyblue', 'lightgray']\n","                if total > 0:\n","                    plt.pie(values, labels=labels, colors=colors, autopct='%1.1f%%')\n","                    plt.title(f'탐지 분포 (총 {total}프레임)')\n","\n","                # 시간별 통계\n","                plt.subplot(2, 1, 2)\n","                bars = plt.bar(labels, values, color=colors)\n","                plt.title(f'탐지 횟수 (프레임: {frame_count})')\n","                plt.ylabel('횟수')\n","                for bar, value in zip(bars, values):\n","                    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n","                             str(value), ha='center', va='bottom')\n","                plt.tight_layout()\n","                plt.show()\n","\n","            frame_count += 1\n","            if max_frames and frame_count >= max_frames:\n","                print(\"최대 프레임 수에 도달하여 중단합니다.\")\n","                break\n","\n","            time.sleep(0.01)  # 너무 빠른 처리 방지\n","\n","    except KeyboardInterrupt:\n","        print(\"\\n사용자에 의해 중단되었습니다.\")\n","    finally:\n","        cap.release()\n","        print(f\"\\n=== 최종 결과 ===\")\n","        total = sum(detection_counts.values())\n","        for class_name, count in detection_counts.items():\n","            if total > 0:\n","                percentage = count/total*100\n","                print(f\"{class_name}: {count}회 ({percentage:.1f}%)\")\n","\n","# 사용 예시\n","mp4_path = r\"dog.mp4\"\n","yolo_mp4_notebook(mp4_path, max_frames=300)"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"24816e0122cf4c058127b5a4e2cee908":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5676358062d41e39a3734d658d52a37","IPY_MODEL_e0a75d1cd56e44788b3b4eb575d2ae2c","IPY_MODEL_b098f041193a4882b2f8dad7815deb7d"],"layout":"IPY_MODEL_d2a93d522b3f44c1a5bfaaab6b0e29ef"}},"d5676358062d41e39a3734d658d52a37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71d5cc6214c243d9ba22fd2982b157bf","placeholder":"​","style":"IPY_MODEL_d60d3d229d1f43de9808f6cf19d61d97","value":"Creating YOLO dataset: 100%"}},"e0a75d1cd56e44788b3b4eb575d2ae2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_761c6eaa6d8b440a9225f6d6ed61117c","max":5369,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a9be69c35014cbe85c96d4392265fc9","value":5369}},"b098f041193a4882b2f8dad7815deb7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e7961a59b744823b460a16a4d59193a","placeholder":"​","style":"IPY_MODEL_fd638b147d944be69005e5897720d3f4","value":" 5369/5369 [00:01&lt;00:00, 2988.47it/s, K-003544-010221-016551-021026_0_2_0_2_90_000_200.png]"}},"d2a93d522b3f44c1a5bfaaab6b0e29ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71d5cc6214c243d9ba22fd2982b157bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d60d3d229d1f43de9808f6cf19d61d97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"761c6eaa6d8b440a9225f6d6ed61117c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a9be69c35014cbe85c96d4392265fc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e7961a59b744823b460a16a4d59193a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd638b147d944be69005e5897720d3f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe8aeea207ed441d9aa2773db23c97d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c419bc980fec415a944c6e6e2dd8ad98","IPY_MODEL_d5086a914578434fb4a31403b5792a03","IPY_MODEL_a8ebacd7e8e040328ff249ff891a601d"],"layout":"IPY_MODEL_a42111a1c71c4cd28ec4394699586313"}},"c419bc980fec415a944c6e6e2dd8ad98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f83dd9a5bdd443f5b518d386a69eb075","placeholder":"​","style":"IPY_MODEL_e7e1efdc57684c219d9caf7b3f13c375","value":"Creating label-only YOLO dataset: 100%"}},"d5086a914578434fb4a31403b5792a03":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e71aa091bc7647c79b74ce754f3ad404","max":2332,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27add70b337647dca61c36c66fa8a943","value":2332}},"a8ebacd7e8e040328ff249ff891a601d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1549aadb94ce422ebddabfde483ec2b4","placeholder":"​","style":"IPY_MODEL_fe60a5cc55d84ea0b86b03cf43e21caa","value":" 2332/2332 [04:45&lt;00:00,  6.13it/s, K-003544-010221-016548-029451_0_2_0_2_75_000_200.png]"}},"a42111a1c71c4cd28ec4394699586313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f83dd9a5bdd443f5b518d386a69eb075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7e1efdc57684c219d9caf7b3f13c375":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e71aa091bc7647c79b74ce754f3ad404":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27add70b337647dca61c36c66fa8a943":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1549aadb94ce422ebddabfde483ec2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe60a5cc55d84ea0b86b03cf43e21caa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}