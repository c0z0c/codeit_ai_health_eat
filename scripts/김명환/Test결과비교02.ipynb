{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3tb146HKUGS"
   },
   "source": [
    "# [ì´ˆê¸‰ í”„ë¡œì íŠ¸] 4íŒ€_ê¹€ëª…í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaVeBaGKUGW"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzN8SzLMKgH1"
   },
   "source": [
    "# í”„ë¡œê·¸ë˜ë°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15401,
     "status": "ok",
     "timestamp": 1758003837717,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "47-Qf8TYKUGW",
    "outputId": "d4e1308d-dcde-4a6d-8c70-8f0b72fd4a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜: cpu\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì¤‘ë³µ ì œê±° ë° ì •ë¦¬)\n",
    "\n",
    "# --- Scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸, í‰ê°€ ---\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import (\n",
    "    fetch_california_housing, load_iris, make_moons, make_circles,\n",
    "    load_breast_cancer, load_wine\n",
    ")\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, average_precision_score\n",
    "\n",
    "# --- ì´ë¯¸ì§€ ì²˜ë¦¬ ---\n",
    "import cv2\n",
    "from PIL import Image, ImageFilter, ImageDraw\n",
    "import albumentations as A\n",
    "\n",
    "# --- PyTorch: ë”¥ëŸ¬ë‹ ê´€ë ¨ ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "# ë¬¸ì œ ìˆëŠ” v2 import ì œê±°í•˜ê³  í•„ìš”ì‹œì—ë§Œ ê°œë³„ì ìœ¼ë¡œ import\n",
    "# from torchvision.transforms import v2, functional as TF\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from collections import OrderedDict\n",
    "\n",
    "# --- COCO ë°ì´í„°ì…‹ ê´€ë ¨ ---\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as coco_mask\n",
    "\n",
    "# --- ë”¥ëŸ¬ë‹ ëª¨ë¸ ---\n",
    "import timm\n",
    "\n",
    "# --- ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import yaml\n",
    "import shutil\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# --- ì‹œê°„ ê´€ë ¨ ---\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pytz\n",
    "\n",
    "# --- ì§„í–‰ë¥  í‘œì‹œ ---\n",
    "import IPython.display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- ì‹œê°„ëŒ€ ì„¤ì • ---\n",
    "__kst = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# --- GPU ì„¤ì • ---\n",
    "__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "__device_cpu = torch.device('cpu')\n",
    "\n",
    "# --- ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì • ---\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if __device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜: {__device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40594,
     "status": "ok",
     "timestamp": 1758003878373,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "gDTmqQCCrBWm",
    "outputId": "43842ad0-e489-4c9e-ee19-d41621ecc966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "â„¹ï¸ NumPy 2.1.3 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\n",
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "â„¹ï¸ NumPy 2.1.3 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'helper_c0z0c_dev' from 'd:\\\\GoogleDrive\\\\codeit_ai_health_eat\\\\scripts\\\\ê¹€ëª…í™˜\\\\helper_c0z0c_dev.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n",
    "import importlib\n",
    "import helper_c0z0c_dev as helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14187,
     "status": "ok",
     "timestamp": 1758003892629,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "WE6336hF11C5",
    "outputId": "7968d02e-0563-4ab8-c563-8ed514e4f8b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils_dir: d:\\GoogleDrive\\codeit_ai_health_eat\\src\\python_modules\\utils\n",
      "sys.path: ['c:\\\\Users\\\\sw1\\\\anaconda3\\\\envs\\\\env_colab_250827\\\\python310.zip', 'c:\\\\Users\\\\sw1\\\\anaconda3\\\\envs\\\\env_colab_250827\\\\DLLs', 'c:\\\\Users\\\\sw1\\\\anaconda3\\\\envs\\\\env_colab_250827\\\\lib', 'c:\\\\Users\\\\sw1\\\\anaconda3\\\\envs\\\\env_colab_250827', '', 'C:\\\\Users\\\\sw1\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages', 'c:\\\\Users\\\\sw1\\\\anaconda3\\\\envs\\\\env_colab_250827\\\\lib\\\\site-packages', 'c:\\\\Users\\\\sw1\\\\anaconda3\\\\envs\\\\env_colab_250827\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\sw1\\\\anaconda3\\\\envs\\\\env_colab_250827\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\sw1\\\\anaconda3\\\\envs\\\\env_colab_250827\\\\lib\\\\site-packages\\\\Pythonwin', 'd:\\\\GoogleDrive\\\\codeit_ai_health_eat\\\\src\\\\python_modules\\\\utils']\n",
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "â„¹ï¸ NumPy 2.1.3 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\n",
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "â„¹ï¸ NumPy 2.1.3 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\n",
      "helper.__file__: d:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\helper_c0z0c_dev.py\n",
      "health_ea_utils.__file__: d:\\GoogleDrive\\codeit_ai_health_eat\\src\\python_modules\\utils\\health_ea_utils.py\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "utils_dir = None\n",
    "if helper.is_colab:\n",
    "    utils_dir = \"/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\"\n",
    "else:\n",
    "    utils_dir = os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive', \"codeit_ai_health_eat\", \"src\", \"python_modules\", \"utils\")\n",
    "\n",
    "print(\"utils_dir:\", utils_dir)\n",
    "\n",
    "sys.path.append(str(utils_dir))\n",
    "print(\"sys.path:\", sys.path)\n",
    "import importlib\n",
    "import health_ea_utils as heu\n",
    "importlib.reload(heu)\n",
    "from health_ea_utils import *\n",
    "\n",
    "print(\"helper.__file__:\", helper.__file__)\n",
    "print(\"health_ea_utils.__file__:\", heu.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1758003892713,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "A3JHrVMkzK9_",
    "outputId": "2530e187-3dfb-4661-8521-cd90adf254c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def get_tqdm_kwargs():\n",
    "    \"\"\"Widget ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ tqdm ì„¤ì •\"\"\"\n",
    "    return {\n",
    "        'disable': False,\n",
    "        'leave': True,\n",
    "        'file': sys.stdout,\n",
    "        'ascii': True,  # ASCII ë¬¸ìë§Œ ì‚¬ìš©\n",
    "        'dynamic_ncols': False,\n",
    "#        'ncols': 80  # ê³ ì • í­\n",
    "    }\n",
    "\n",
    "def drive_root():\n",
    "    root_path = os.path.join(\"D:\\\\\", \"GoogleDrive\")\n",
    "    if helper.is_colab:\n",
    "        root_path = os.path.join(\"/content/drive/MyDrive\")\n",
    "    return root_path\n",
    "\n",
    "def get_path_modeling(add_path = None):\n",
    "    modeling_path = \"modeling_yolo\"\n",
    "    path = os.path.join(drive_root(),modeling_path)\n",
    "    if add_path is not None:\n",
    "        path = os.path.join(path,add_path)\n",
    "    return path\n",
    "\n",
    "def get_path_modeling_release(add_path = None):\n",
    "    modeling_path = \"modeling_yolo\"\n",
    "    path = os.path.join(drive_root(),modeling_path)\n",
    "    if add_path is not None:\n",
    "        path = os.path.join(path,add_path)\n",
    "    return path\n",
    "\n",
    "def print_dir_tree(root, max_depth=2, list_count=3, indent=\"\"):\n",
    "    import os\n",
    "    if max_depth < 0:\n",
    "        return\n",
    "    try:\n",
    "        items = os.listdir(root)\n",
    "    except Exception as e:\n",
    "        print(indent + f\"[Error] {e}\")\n",
    "        return\n",
    "\n",
    "    img_count = len([f for f in os.listdir(root) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n",
    "    for item in items:\n",
    "        path = os.path.join(root, item)\n",
    "        if os.path.isdir(path):\n",
    "            print(indent + \"|-- \"+ item)\n",
    "            # ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜ë§Œ ì¶œë ¥\n",
    "            img_count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n",
    "            if img_count > list_count:\n",
    "                print(indent + \"   \"+ f\"[ë°ì´í„°íŒŒì¼: {img_count}ê°œ]\")\n",
    "            print_dir_tree(root=path, max_depth=max_depth-1, list_count=list_count, indent=indent + \"   \")\n",
    "        else:\n",
    "            if list_count < img_count and item.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt')):\n",
    "                continue\n",
    "            print(indent + \"|-- \"+ item)\n",
    "\n",
    "def save_model_dict(model, path, pth_name, kwargs=None):\n",
    "    \"\"\"ëª¨ë¸ state_dictì™€ ì¶”ê°€ ì •ë³´ë¥¼ ì €ì¥\"\"\"\n",
    "    def safe_makedirs(path):\n",
    "        \"\"\"ì•ˆì „í•œ ë””ë ‰í† ë¦¬ ìƒì„±\"\"\"\n",
    "        if os.path.exists(path) and not os.path.isdir(path):\n",
    "            os.remove(path)  # íŒŒì¼ì´ë©´ ì‚­ì œ\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    safe_makedirs(path)\n",
    "\n",
    "    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ\n",
    "    model_info = {\n",
    "        'class_name': model.__class__.__name__,\n",
    "        'init_args': {},\n",
    "        'str': str(model),\n",
    "        'repr': repr(model),\n",
    "        'modules': [m.__class__.__name__ for m in model.modules()],\n",
    "    }\n",
    "\n",
    "    # ìƒì„±ì ì¸ì ìë™ ì¶”ì¶œ(ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "    if hasattr(model, '__dict__'):\n",
    "        for key in ['in_ch', 'base_ch', 'num_classes', 'out_ch']:\n",
    "            if hasattr(model, key):\n",
    "                model_info['init_args'][key] = getattr(model, key)\n",
    "\n",
    "    # kwargs ì²˜ë¦¬\n",
    "    extra_info = {}\n",
    "    if kwargs is not None:\n",
    "        if isinstance(kwargs, str):\n",
    "            extra_info = json.loads(kwargs)\n",
    "        elif isinstance(kwargs, dict):\n",
    "            extra_info = kwargs\n",
    "\n",
    "    model_info.update(extra_info)\n",
    "\n",
    "    # ì €ì¥í•  dict êµ¬ì„±\n",
    "    save_dict = {\n",
    "        'model_state': model.state_dict(),\n",
    "        'class_name': model.__class__.__name__,\n",
    "        'model_info': model_info,\n",
    "    }\n",
    "\n",
    "    save_path = os.path.join(path, f\"{pth_name}.pth\")\n",
    "    torch.save(save_dict, save_path)\n",
    "    return save_path\n",
    "\n",
    "def load_model_dict(path, pth_name=None):\n",
    "    \"\"\"\n",
    "    save_model_dictë¡œ ì €ì¥í•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\n",
    "    ë°˜í™˜ê°’: (model_state, model_info)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    load_path = path\n",
    "    if pth_name is not None:\n",
    "        load_path = os.path.join(path, f\"{pth_name}.pth\")\n",
    "    checkpoint = torch.load(load_path, map_location='cpu', weights_only=False)  # <-- ì—¬ê¸° ì¶”ê°€\n",
    "    model_state = checkpoint.get('model_state')\n",
    "    model_info = checkpoint.get('model_info')\n",
    "    model_info['file_name'] = os.path.basename(load_path)\n",
    "    return model_state, model_info\n",
    "\n",
    "\n",
    "def search_pth_files(base_path):\n",
    "    \"\"\"\n",
    "    ì…ë ¥ëœ ê²½ë¡œì˜ í•˜ìœ„ í´ë”ë“¤ì—ì„œ pth íŒŒì¼ë“¤ì„ ê²€ìƒ‰\n",
    "    \"\"\"\n",
    "    pth_files = []\n",
    "\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_path}\")\n",
    "        return pth_files\n",
    "\n",
    "    print(f\"pth íŒŒì¼ ê²€ìƒ‰ ì‹œì‘: {base_path}\")\n",
    "\n",
    "    # í•˜ìœ„ í´ë”ë“¤ì„ ìˆœíšŒí•˜ë©° pth íŒŒì¼ ê²€ìƒ‰\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.pth'):\n",
    "                pth_path = os.path.join(root, file)\n",
    "                pth_files.append(pth_path)\n",
    "\n",
    "    # ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥\n",
    "    if pth_files:\n",
    "        print(f\"\\në°œê²¬ëœ pth íŒŒì¼ë“¤ ({len(pth_files)}ê°œ):\")\n",
    "        for i, pth_file in enumerate(pth_files, 1):\n",
    "            # ìƒëŒ€ ê²½ë¡œë¡œ í‘œì‹œ (base_path ê¸°ì¤€)\n",
    "            rel_path = os.path.relpath(pth_file, base_path)\n",
    "            print(f\" {i:2d}. {rel_path}\")\n",
    "    else:\n",
    "        print(\"pth íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    return pth_files\n",
    "\n",
    "def print_json_tree(data, indent=\"\", max_depth=4, _depth=0, list_count=2, print_value=True):\n",
    "    \"\"\"\n",
    "    JSON ê°ì²´ë¥¼ ì§€ì •í•œ ë‹¨ê³„(max_depth)ê¹Œì§€ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥\n",
    "    - list íƒ€ì…ì€ 3ê°œ ì´ìƒì¼ ë•Œ ê°œìˆ˜ë§Œ ì¶œë ¥\n",
    "    - í•˜ìœ„ ë…¸ë“œê°€ ê°’ì¼ ê²½ìš° key(type) í˜•íƒœë¡œ ì¶œë ¥\n",
    "    - print_value=Trueì¼ ë•Œ key(type): ê°’ í˜•íƒœë¡œ ì¶œë ¥\n",
    "    \"\"\"\n",
    "    if _depth > max_depth:\n",
    "        return\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, (dict, list)):\n",
    "                print(f\"{indent}|-- {key}\")\n",
    "                print_json_tree(value, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n",
    "            else:\n",
    "                if print_value:\n",
    "                    print(f\"{indent}|-- {key}({type(value).__name__}): {value if len(str(value)) < 100 else f'{str(value)[:30]}...'}\")\n",
    "                else:\n",
    "                    print(f\"{indent}|-- {key}({type(value).__name__})\")\n",
    "    elif isinstance(data, list):\n",
    "        if len(data) > list_count:\n",
    "            print(f\"{indent}|-- [list] ({len(data)} items)\")\n",
    "        else:\n",
    "            for i, item in enumerate(data):\n",
    "                if isinstance(item, (dict, list)):\n",
    "                    print(f\"{indent}|-- [{i}]\")\n",
    "                    print_json_tree(item, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n",
    "                else:\n",
    "                    if print_value:\n",
    "                        print(f\"{indent}|-- [{i}]({type(item).__name__}): {item if len(str(item)) < 100 else f'{str(item)[:30]}...'}\")\n",
    "                    else:\n",
    "                        print(f\"{indent}|-- [{i}]({type(item).__name__})\")\n",
    "    else:\n",
    "        if print_value:\n",
    "            print(f\"{indent}{type(data).__name__}: {data if len(str(data)) < 100 else f'{str(data)[:30]}...'}\")\n",
    "        else:\n",
    "            print(f\"{indent}{type(data).__name__}\")\n",
    "\n",
    "def print_git_tree(data, indent=\"\", max_depth=3, _depth=0):\n",
    "    \"\"\"\n",
    "    PyTorch tensor/ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ë¥¼ git tree ìŠ¤íƒ€ì¼ë¡œ ì¶œë ¥\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import numpy as np\n",
    "\n",
    "    if _depth > max_depth:\n",
    "        return\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            print(f\"{indent}â”œâ”€ {key} [{type(value).__name__}]\")\n",
    "            print_git_tree(value, indent + \"â”‚  \", max_depth, _depth + 1)\n",
    "    elif isinstance(data, (list, tuple)):\n",
    "        for i, item in enumerate(data):\n",
    "            print(f\"{indent}â”œâ”€ [{i}] [{type(item).__name__}]\")\n",
    "            print_git_tree(item, indent + \"â”‚  \", max_depth, _depth + 1)\n",
    "    elif torch.is_tensor(data):\n",
    "        shape = tuple(data.shape)\n",
    "        dtype = str(data.dtype)\n",
    "        preview = str(data)\n",
    "        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n",
    "        print(f\"{indent}â””â”€ Tensor shape={shape} dtype={dtype} preview={preview_str}\")\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        shape = data.shape\n",
    "        dtype = data.dtype\n",
    "        preview = str(data)\n",
    "        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n",
    "        print(f\"{indent}â””â”€ ndarray shape={shape} dtype={dtype} preview={preview_str}\")\n",
    "    else:\n",
    "        val_str = str(data)\n",
    "        print(f\"{indent}â””â”€ {type(data).__name__}: {val_str[:80]}{'...' if len(val_str)>80 else ''}\")\n",
    "\n",
    "\n",
    "print(\"ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_result_sample(self, result_json):\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    from PIL import Image\n",
    "    import base64\n",
    "    from io import BytesIO\n",
    "\n",
    "    # JSON ë¬¸ìì—´ íŒŒì‹±\n",
    "    result = json.loads(result_json)\n",
    "    bboxs = result['bboxs']\n",
    "    img_path = result.get('img_path', None)\n",
    "\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    if img_path is not None:\n",
    "        org_img = Image.open(img_path).convert(\"RGB\")\n",
    "    else:\n",
    "        org_img = None\n",
    "\n",
    "    n = len(bboxs)\n",
    "    fig = plt.figure(figsize=(4, 8))\n",
    "    gs = fig.add_gridspec(2, 1, height_ratios=[2, 1])\n",
    "\n",
    "    # 1í–‰: ì›ë³¸ ì´ë¯¸ì§€ + ë°•ìŠ¤\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    if org_img is not None:\n",
    "        ax1.imshow(org_img)\n",
    "        for box in bboxs:\n",
    "            xyxy = box['xyxy']\n",
    "            class_name = box['class_name']\n",
    "            class_score = box['class_score']\n",
    "            drug_N = box['drug_info']['drug_N']\n",
    "            dl_name = box['drug_info']['dl_name']\n",
    "            x1, y1, x2, y2 = xyxy\n",
    "            w, h = x2-x1, y2-y1\n",
    "            rect = mpatches.Rectangle((int(x1), int(y1)), int(w), int(h),\n",
    "                                    linewidth=2, edgecolor='red', facecolor='none')\n",
    "            ax1.add_patch(rect)\n",
    "            label = f\"{class_name} {class_score:.2f}\\n{drug_N}\\n{dl_name}\"\n",
    "            ax1.text(x1, y1-5, label, color='red', fontsize=10, backgroundcolor='white', alpha=0.8)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title('ì´ë¯¸ì§€ + ë°•ìŠ¤', pad=5)\n",
    "    else:\n",
    "        ax1.set_title('ì›ë³¸ ì´ë¯¸ì§€ ì—†ìŒ')\n",
    "        ax1.axis('off')\n",
    "\n",
    "    # 2í–‰: ê° ë°•ìŠ¤ Crop ì´ë¯¸ì§€ í•œ í–‰ì— ë‚˜ë€íˆ\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    crop_imgs = []\n",
    "    for box in bboxs:\n",
    "        # base64 ì´ë¯¸ì§€ë¥¼ PILë¡œ ë³€í™˜\n",
    "        img_b64 = box['img']\n",
    "        img_bytes = base64.b64decode(img_b64)\n",
    "        crop_img = Image.open(BytesIO(img_bytes)).convert(\"RGB\")\n",
    "        crop_imgs.append(np.array(crop_img))\n",
    "\n",
    "    if n > 0:\n",
    "        heights = [img.shape[0] for img in crop_imgs]\n",
    "        max_h = max(heights)\n",
    "        resized_imgs = []\n",
    "        crop_positions = []\n",
    "        x_offset = 0\n",
    "        for i, img in enumerate(crop_imgs):\n",
    "            if img.shape[0] != max_h:\n",
    "                pil_img = Image.fromarray(img)\n",
    "                ratio = max_h / img.shape[0]\n",
    "                new_w = int(img.shape[1] * ratio)\n",
    "                pil_img = pil_img.resize((new_w, max_h))\n",
    "                img = np.array(pil_img)\n",
    "            resized_imgs.append(img)\n",
    "            crop_positions.append((x_offset, img.shape[1]))\n",
    "            x_offset += img.shape[1]\n",
    "        concat_img = np.concatenate(resized_imgs, axis=1)\n",
    "        ax2.imshow(concat_img)\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title('ì•Œì•½ ì´ë¯¸ì§€ë“¤', pad=5)\n",
    "        # ê° crop ì´ë¯¸ì§€ ìœ„ì— ë¼ë²¨ ì¶œë ¥\n",
    "        for i, (start_x, width) in enumerate(crop_positions):\n",
    "            class_name = bboxs[i]['class_name']\n",
    "            class_score = bboxs[i]['class_score']\n",
    "            label = f\"{class_name}\\n{class_score:.2f}\"\n",
    "            ax2.text(start_x + width // 2, 10, label, color='red', fontsize=10,\n",
    "                    backgroundcolor='white', ha='center', va='top', alpha=0.8)\n",
    "    else:\n",
    "        ax2.set_title('ì•Œì•½ ì—†ìŒ')\n",
    "        ax2.axis('off')\n",
    "\n",
    "    # ì—¬ë°± ìµœì†Œí™”\n",
    "    plt.subplots_adjust(hspace=0, top=1, bottom=0)\n",
    "    plt.tight_layout(pad=0)\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    pil_img = Image.open(buf)\n",
    "    return pil_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_result(test_images_path, result_a_csv_path, result_b_csv_path, output_folder)\n",
    "# annotation_id,image_id,category_id,bbox_x,bbox_y,bbox_w,bbox_h,score\n",
    "# 1,1,16550,558.0531616210938,75.6333999633789,398.298583984375,396.9631881713867,0.9944773316383361\n",
    "# test_images_pathì— image_id ì´ë¦„ìœ¼ë¡œ ì›ë³¸íŒŒì¼ì´ ìˆë‹¤.\n",
    "# image_id ìœ„ì—  bbox_x, bbox_y, bbox_w, bbox_h ë¥¼ê·¸ë¦¬ê³  category_id, scoreë¥¼ í‘œì‹œí•œë‹¤\n",
    "# result_aëŠ” íŒŒë€ìƒ‰ result_bëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œí•œë‹¤\n",
    "# image_result_sampleë¥¼ ì°¸ê³ í•˜ì—¬ image_resultë¥¼ ë§Œë“ ë‹¤ ì›ë³¸ì´ë¯¸ì§€ìœ„ì— ë°•ìŠ¤ì™€ì •ë³´, ê·¸ë°‘ì— cropì´ë¯¸ì§€ë“¤ì„ ë‚˜ë€íˆ\n",
    "# diff_resultì—ì„œ ì´ìš©í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_result(img_path, boxes_a, boxes_b, title=\"ë¹„êµ ê²°ê³¼\"):\n",
    "    \"\"\"\n",
    "    image_result_sampleì„ ì°¸ê³ í•˜ì—¬ ë§Œë“  ë¹„êµìš© ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        img_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "        boxes_a: result_aì˜ ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ (íŒŒë€ìƒ‰)\n",
    "        boxes_b: result_bì˜ ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ë¹¨ê°„ìƒ‰)\n",
    "        title: ì´ë¯¸ì§€ ì œëª©\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image: ë¹„êµ ê²°ê³¼ ì´ë¯¸ì§€\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    from PIL import Image\n",
    "    from io import BytesIO\n",
    "    \n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    if os.path.exists(img_path):\n",
    "        org_img = Image.open(img_path).convert(\"RGB\")\n",
    "    else:\n",
    "        print(f\"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}\")\n",
    "        return None\n",
    "    \n",
    "    # ëª¨ë“  ë°•ìŠ¤ë“¤ í•©ì¹˜ê¸° (êµ¬ë¶„ì„ ìœ„í•´ ìƒ‰ìƒ ì •ë³´ ì¶”ê°€)\n",
    "    all_boxes = []\n",
    "    for box in boxes_a:\n",
    "        box_info = box.copy()\n",
    "        box_info['color'] = 'blue'\n",
    "        box_info['label_prefix'] = 'A:'\n",
    "        all_boxes.append(box_info)\n",
    "    \n",
    "    for box in boxes_b:\n",
    "        box_info = box.copy()\n",
    "        box_info['color'] = 'red' \n",
    "        box_info['label_prefix'] = 'B:'\n",
    "        all_boxes.append(box_info)\n",
    "    \n",
    "    n_total = len(all_boxes)\n",
    "    \n",
    "    if n_total == 0:\n",
    "        # ë°•ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° ì›ë³¸ ì´ë¯¸ì§€ë§Œ ë°˜í™˜\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        ax.imshow(org_img)\n",
    "        ax.set_title(f'{title} - ê²€ì¶œ ê²°ê³¼ ì—†ìŒ')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        buf.seek(0)\n",
    "        result_img = Image.open(buf).copy()\n",
    "        buf.close()\n",
    "        return result_img\n",
    "    \n",
    "    # ë ˆì´ì•„ì›ƒ ì„¤ì • (ìƒë‹¨: ì›ë³¸+ë°•ìŠ¤, í•˜ë‹¨: crop ì´ë¯¸ì§€ë“¤)\n",
    "    fig = plt.figure(figsize=(max(12, n_total * 2), 10))\n",
    "    gs = fig.add_gridspec(2, 1, height_ratios=[3, 1], hspace=0.1)\n",
    "    \n",
    "    # 1í–‰: ì›ë³¸ ì´ë¯¸ì§€ + ë°•ìŠ¤ë“¤\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax1.imshow(org_img)\n",
    "    \n",
    "    # ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "    for box in all_boxes:\n",
    "        x, y, w, h = box['bbox_x'], box['bbox_y'], box['bbox_w'], box['bbox_h']\n",
    "        category_id = box['category_id']\n",
    "        score = box['score']\n",
    "        color = box['color']\n",
    "        prefix = box['label_prefix']\n",
    "        \n",
    "        # ìƒ‰ìƒ ì„¤ì •\n",
    "        edge_color = 'blue' if color == 'blue' else 'red'\n",
    "        \n",
    "        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "        rect = mpatches.Rectangle((x, y), w, h,\n",
    "                                linewidth=2, edgecolor=edge_color, \n",
    "                                facecolor='none', alpha=0.8)\n",
    "        ax1.add_patch(rect)\n",
    "        \n",
    "        # ë¼ë²¨ í…ìŠ¤íŠ¸\n",
    "        label = f\"{prefix}{category_id}\\n{score:.3f}\"\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ë°°ê²½ìƒ‰ ì„¤ì •\n",
    "        bg_color = 'lightblue' if color == 'blue' else 'lightcoral'\n",
    "        text_color = 'darkblue' if color == 'blue' else 'darkred'\n",
    "        \n",
    "        # ë¼ë²¨ ìœ„ì¹˜ ì„¤ì •: íŒŒë€ìƒ‰ì€ ì˜¤ë¥¸ìª½ ì•„ë˜, ë¹¨ê°„ìƒ‰ì€ ì™¼ìª½ ìœ„\n",
    "        if color == 'blue':\n",
    "            # íŒŒë€ìƒ‰: ë°•ìŠ¤ ì˜¤ë¥¸ìª½ ì•„ë˜\n",
    "            label_x, label_y = x + w, y + h + 5\n",
    "            va = 'top'\n",
    "            ha = 'right'\n",
    "        else:\n",
    "            # ë¹¨ê°„ìƒ‰: ë°•ìŠ¤ ì™¼ìª½ ìœ„ (ê¸°ì¡´ ìœ„ì¹˜)\n",
    "            label_x, label_y = x, y - 5\n",
    "            va = 'bottom'\n",
    "            ha = 'left'\n",
    "        \n",
    "        ax1.text(label_x, label_y, label, color=text_color, fontsize=9, \n",
    "                backgroundcolor=bg_color, alpha=0.9, \n",
    "                verticalalignment=va, horizontalalignment=ha)\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(f'{title} - A(íŒŒë€ìƒ‰) vs B(ë¹¨ê°„ìƒ‰)', pad=10, fontsize=14)\n",
    "    \n",
    "    # 2í–‰: Crop ì´ë¯¸ì§€ë“¤\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    \n",
    "    if n_total > 0:\n",
    "        crop_imgs = []\n",
    "        crop_labels = []\n",
    "        \n",
    "        # ê° ë°•ìŠ¤ë³„ë¡œ crop ì´ë¯¸ì§€ ìƒì„±\n",
    "        for box in all_boxes:\n",
    "            x, y, w, h = box['bbox_x'], box['bbox_y'], box['bbox_w'], box['bbox_h']\n",
    "            \n",
    "            # ì¢Œí‘œ ì •ìˆ˜ ë³€í™˜ ë° ì´ë¯¸ì§€ ë²”ìœ„ í´ë¦¬í•‘\n",
    "            x1, y1 = max(0, int(x)), max(0, int(y))\n",
    "            x2, y2 = min(org_img.width, int(x + w)), min(org_img.height, int(y + h))\n",
    "            \n",
    "            if x2 > x1 and y2 > y1:\n",
    "                crop_img = org_img.crop((x1, y1, x2, y2))\n",
    "                crop_imgs.append(np.array(crop_img))\n",
    "                \n",
    "                # ë¼ë²¨ ìƒì„± - A/B êµ¬ë¶„ì— ë”°ë¥¸ ìƒ‰ìƒ ì„¤ì •\n",
    "                prefix = box['label_prefix']\n",
    "                category_id = box['category_id']\n",
    "                score = box['score']\n",
    "                color = box['color']\n",
    "                \n",
    "                # A/Bì— ë”°ë¥¸ ìƒ‰ìƒ ë° ë°°ê²½ìƒ‰ ì„¤ì •\n",
    "                if color == 'blue':  # A ê²°ê³¼\n",
    "                    text_color = 'white'\n",
    "                    bg_color = 'blue'\n",
    "                else:  # B ê²°ê³¼\n",
    "                    text_color = 'white'\n",
    "                    bg_color = 'red'\n",
    "                \n",
    "                crop_labels.append({\n",
    "                    'text': f\"{prefix}{category_id}\\n{score:.3f}\",\n",
    "                    'text_color': text_color,\n",
    "                    'bg_color': bg_color,\n",
    "                    'label_type': 'A' if color == 'blue' else 'B'\n",
    "                })\n",
    "        \n",
    "        if crop_imgs:\n",
    "            # ë†’ì´ë¥¼ í†µì¼í•˜ì—¬ ê°€ë¡œë¡œ ì—°ê²°\n",
    "            heights = [img.shape[0] for img in crop_imgs]\n",
    "            max_h = max(heights)\n",
    "            \n",
    "            resized_imgs = []\n",
    "            crop_positions = []\n",
    "            x_offset = 0\n",
    "            \n",
    "            for i, img in enumerate(crop_imgs):\n",
    "                if img.shape[0] != max_h:\n",
    "                    # ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ\n",
    "                    pil_img = Image.fromarray(img)\n",
    "                    ratio = max_h / img.shape[0]\n",
    "                    new_w = int(img.shape[1] * ratio)\n",
    "                    pil_img = pil_img.resize((new_w, max_h), Image.Resampling.LANCZOS)\n",
    "                    img = np.array(pil_img)\n",
    "                \n",
    "                resized_imgs.append(img)\n",
    "                crop_positions.append((x_offset, img.shape[1]))\n",
    "                x_offset += img.shape[1]\n",
    "            \n",
    "            # ê°€ë¡œë¡œ ì—°ê²°\n",
    "            concat_img = np.concatenate(resized_imgs, axis=1)\n",
    "            ax2.imshow(concat_img)\n",
    "            \n",
    "            # ê° crop ì´ë¯¸ì§€ ìœ„ì— ë¼ë²¨ í‘œì‹œ - ìƒ‰ìƒ êµ¬ë¶„ ê°•í™”\n",
    "            for i, (start_x, width) in enumerate(crop_positions):\n",
    "                if i < len(crop_labels):\n",
    "                    label_info = crop_labels[i]\n",
    "                    \n",
    "                    # ë¼ë²¨ í…ìŠ¤íŠ¸ í‘œì‹œ (ìƒë‹¨ ì¤‘ì•™)\n",
    "                    ax2.text(start_x + width // 2, 10, label_info['text'], \n",
    "                            color=label_info['text_color'], fontsize=9, weight='bold',\n",
    "                            backgroundcolor=label_info['bg_color'], ha='center', va='top', \n",
    "                            alpha=0.9, bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                                                facecolor=label_info['bg_color'], \n",
    "                                                alpha=0.9))\n",
    "                    \n",
    "                    # ì¶”ê°€: ì´ë¯¸ì§€ í•˜ë‹¨ì— A/B êµ¬ë¶„ í‘œì‹œ\n",
    "                    label_type = label_info['label_type']\n",
    "                    ax2.text(start_x + width // 2, max_h - 5, f\"[{label_type}]\", \n",
    "                            color=label_info['text_color'], fontsize=10, weight='bold',\n",
    "                            backgroundcolor=label_info['bg_color'], ha='center', va='bottom', \n",
    "                            alpha=0.9, bbox=dict(boxstyle=\"round,pad=0.2\", \n",
    "                                                facecolor=label_info['bg_color'], \n",
    "                                                alpha=0.9))\n",
    "            \n",
    "            ax2.set_title('ê²€ì¶œëœ ê°ì²´ë“¤ - A(íŒŒë€ìƒ‰) vs B(ë¹¨ê°„ìƒ‰)', pad=5, fontsize=12)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'ìœ íš¨í•œ crop ì´ë¯¸ì§€ ì—†ìŒ', \n",
    "                    ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'ê²€ì¶œ ê²°ê³¼ ì—†ìŒ', \n",
    "                ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "    \n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # ì—¬ë°± ìµœì†Œí™”\n",
    "    plt.tight_layout(pad=1.0)\n",
    "    \n",
    "    # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0.1, dpi=150)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    result_img = Image.open(buf).copy()\n",
    "    buf.close()\n",
    "    \n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_result(test_images_path, result_a_csv_path, result_b_csv_path, output_folder):\n",
    "    \"\"\"\n",
    "    ë‘ CSV ê²°ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        test_images_path: ì›ë³¸ ì´ë¯¸ì§€ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ\n",
    "        result_a_csv_path: ì²« ë²ˆì§¸ ê²°ê³¼ CSV íŒŒì¼ (íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œ)\n",
    "        result_b_csv_path: ë‘ ë²ˆì§¸ ê²°ê³¼ CSV íŒŒì¼ (ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ)\n",
    "        output_folder: ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë”\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # ì¶œë ¥ í´ë” ìƒì„±\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # CSV íŒŒì¼ ì½ê¸°\n",
    "    try:\n",
    "        df_a = pd.read_csv(result_a_csv_path)\n",
    "        print(f\"Result A loaded: {len(df_a)} detections\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading result A: {e}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df_b = pd.read_csv(result_b_csv_path)\n",
    "        print(f\"Result B loaded: {len(df_b)} detections\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading result B: {e}\")\n",
    "        return\n",
    "    \n",
    "    # image_idë³„ë¡œ ê·¸ë£¹í™”\n",
    "    grouped_a = df_a.groupby('image_id') if len(df_a) > 0 else {}\n",
    "    grouped_b = df_b.groupby('image_id') if len(df_b) > 0 else {}\n",
    "    \n",
    "    # ëª¨ë“  image_id ìˆ˜ì§‘\n",
    "    all_image_ids = set()\n",
    "    if len(df_a) > 0:\n",
    "        all_image_ids.update(df_a['image_id'].unique())\n",
    "    if len(df_b) > 0:\n",
    "        all_image_ids.update(df_b['image_id'].unique())\n",
    "    \n",
    "    print(f\"Processing {len(all_image_ids)} unique images...\")\n",
    "    \n",
    "    # ê° ì´ë¯¸ì§€ë³„ë¡œ ì²˜ë¦¬\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    all_image_ids = [615]\n",
    "    \n",
    "    # print(f\"df_aì—ì„œ image_id={all_image_ids}\")\n",
    "    # print(df_a[df_a['image_id'].isin(all_image_ids)])\n",
    "\n",
    "    # print(\"df_bì—ì„œ image_id=={all_image_ids}\")\n",
    "    # print(df_b[df_b['image_id'].isin(all_image_ids)])\n",
    "    \n",
    "    for image_id in tqdm(sorted(all_image_ids), desc=\"Processing images\", **get_tqdm_kwargs()):\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
    "        img_path = None\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:\n",
    "            potential_path = os.path.join(test_images_path, f\"{image_id}{ext}\")\n",
    "            if os.path.exists(potential_path):\n",
    "                img_path = potential_path\n",
    "                break\n",
    "        \n",
    "        if img_path is None:\n",
    "            print(f\"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_id}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "        # í•´ë‹¹ ì´ë¯¸ì§€ì˜ ë°•ìŠ¤ë“¤ ì¶”ì¶œ\n",
    "        boxes_a = []\n",
    "        boxes_b = []\n",
    "        \n",
    "        if hasattr(grouped_a, 'get_group'):\n",
    "            try:\n",
    "                group_a = grouped_a.get_group(image_id)\n",
    "                boxes_a = group_a.to_dict('records')\n",
    "            except KeyError:\n",
    "                pass  # í•´ë‹¹ ì´ë¯¸ì§€ì— ëŒ€í•œ ê²°ê³¼ê°€ ì—†ìŒ\n",
    "        \n",
    "        if hasattr(grouped_b, 'get_group'):\n",
    "            try:\n",
    "                group_b = grouped_b.get_group(image_id)\n",
    "                boxes_b = group_b.to_dict('records')\n",
    "            except KeyError:\n",
    "                pass  # í•´ë‹¹ ì´ë¯¸ì§€ì— ëŒ€í•œ ê²°ê³¼ê°€ ì—†ìŒ\n",
    "        \n",
    "        # ë¹„êµ ì´ë¯¸ì§€ ìƒì„±\n",
    "        title = f\"Image {image_id}\"\n",
    "        result_img = image_result(img_path, boxes_a, boxes_b, title)\n",
    "        \n",
    "        if result_img is not None:\n",
    "            # ê²°ê³¼ ì €ì¥ (PNG -> JPGë¡œ ë³€ê²½)\n",
    "            output_path = os.path.join(output_folder, f\"{image_id}_comparison.jpg\")\n",
    "            # JPG ì €ì¥ ì‹œ RGB ëª¨ë“œ í™•ì¸ ë° í’ˆì§ˆ ì„¤ì •\n",
    "            if result_img.mode == 'RGBA':\n",
    "                result_img = result_img.convert('RGB')\n",
    "            result_img.save(output_path, 'JPEG', quality=95)\n",
    "            success_count += 1\n",
    "        else:\n",
    "            error_count += 1\n",
    "            \n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨\")\n",
    "    print(f\"ê²°ê³¼ ì €ì¥ í´ë”: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result A loaded: 3233 detections\n",
      "Result B loaded: 3235 detections\n",
      "Processing 843 unique images...\n",
      "df_aì—ì„œ image_id=[615]\n",
      "      annotation_id  image_id  category_id  bbox_x  bbox_y  bbox_w  bbox_h  \\\n",
      "2590           2591       615        19231     208     754     239     350   \n",
      "2591           2592       615        22073     673     821     184     186   \n",
      "2592           2593       615         3350     393     215     176     174   \n",
      "\n",
      "       score  \n",
      "2590  1.0000  \n",
      "2591  0.9998  \n",
      "2592  0.9305  \n",
      "df_bì—ì„œ image_id=={all_image_ids}\n",
      "      annotation_id  image_id  category_id      bbox_x      bbox_y  \\\n",
      "2332           2333       615         3350  388.059998  211.250320   \n",
      "2333           2334       615        22073  672.931152  819.715942   \n",
      "2334           2335       615        19231  209.280411  742.179016   \n",
      "2335           2336       615        18356  209.666931  749.831543   \n",
      "\n",
      "          bbox_w      bbox_h     score  \n",
      "2332  185.193604  182.417740  0.988077  \n",
      "2333  188.193909  188.500061  0.907362  \n",
      "2334  247.081131  378.053772  0.739136  \n",
      "2335  224.261688  367.570923  0.516201  \n",
      "Processing images: 100%|##########| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\n",
      "ì™„ë£Œ: 1ê°œ ì„±ê³µ, 0ê°œ ì‹¤íŒ¨\n",
      "ê²°ê³¼ ì €ì¥ í´ë”: D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\2stage_result_20250918_130256_411_diff\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ìš© ê²½ë¡œ (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)\n",
    "test_images_path = r\"D:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\test_images\"  # ì›ë³¸ ì´ë¯¸ì§€ í´ë”\n",
    "result_a_csv = r\"D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\2stage_result_20250918_130256\\result_2way_20250918_130256.csv\"  # ì²« ë²ˆì§¸ ê²°ê³¼\n",
    "result_b_csv = r\"D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\output_data_resnet101.csv\"  # ë‘ ë²ˆì§¸ ê²°ê³¼\n",
    "#output_folder = r\"D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\2stage_result_20250918_130256_diff\"  # ì¶œë ¥ í´ë”\n",
    "output_folder = r\"D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\2stage_result_20250918_130256_411_diff\"  # ì¶œë ¥ í´ë”\n",
    "\n",
    "diff_result(test_images_path, result_a_csv, result_b_csv, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result A loaded: 3233 detections\n",
      "Result B loaded: 3235 detections\n",
      "category_idê°€ ë‹¤ë¥´ê²Œ ì¡´ì¬í•˜ëŠ” image_id ê°œìˆ˜: 11\n",
      "image_id: 277\n",
      "  df_a category_id: [3482, 19860, 34596, 36636]\n",
      "  df_b category_id: [3482, 19860, 30307, 36636]\n",
      "  only_in_a: [34596]\n",
      "  only_in_b: [30307]\n",
      "----------------------------------------\n",
      "image_id: 409\n",
      "  df_a category_id: [1899, 16550, 25366, 33008]\n",
      "  df_b category_id: [1899, 10223, 16550, 33008]\n",
      "  only_in_a: [25366]\n",
      "  only_in_b: [10223]\n",
      "----------------------------------------\n",
      "image_id: 411\n",
      "  df_a category_id: [1899, 16550, 25366, 33008]\n",
      "  df_b category_id: [1899, 10223, 16550, 33008]\n",
      "  only_in_a: [25366]\n",
      "  only_in_b: [10223]\n",
      "----------------------------------------\n",
      "image_id: 615\n",
      "  df_a category_id: [3350, 19231, 22073]\n",
      "  df_b category_id: [3350, 18356, 19231, 22073]\n",
      "  only_in_a: []\n",
      "  only_in_b: [18356]\n",
      "----------------------------------------\n",
      "image_id: 697\n",
      "  df_a category_id: [3350, 18356, 38161]\n",
      "  df_b category_id: [3350, 18356, 19231, 38161]\n",
      "  only_in_a: []\n",
      "  only_in_b: [19231]\n",
      "----------------------------------------\n",
      "image_id: 701\n",
      "  df_a category_id: [3482, 16231, 19860, 34596]\n",
      "  df_b category_id: [3482, 16231, 19860, 30307]\n",
      "  only_in_a: [34596]\n",
      "  only_in_b: [30307]\n",
      "----------------------------------------\n",
      "image_id: 879\n",
      "  df_a category_id: [3482, 27652, 31884, 36636]\n",
      "  df_b category_id: [3482, 27652, 34596, 36636]\n",
      "  only_in_a: [31884]\n",
      "  only_in_b: [34596]\n",
      "----------------------------------------\n",
      "image_id: 979\n",
      "  df_a category_id: [3350, 18356, 22073]\n",
      "  df_b category_id: [3350, 4999, 18356]\n",
      "  only_in_a: [22073]\n",
      "  only_in_b: [4999]\n",
      "----------------------------------------\n",
      "image_id: 980\n",
      "  df_a category_id: [3350, 18356, 22073]\n",
      "  df_b category_id: [3350, 4999, 18356, 19231]\n",
      "  only_in_a: [22073]\n",
      "  only_in_b: [4999, 19231]\n",
      "----------------------------------------\n",
      "image_id: 1418\n",
      "  df_a category_id: [1899, 16550, 31704, 33877]\n",
      "  df_b category_id: [1899, 10223, 16550, 31704]\n",
      "  only_in_a: [33877]\n",
      "  only_in_b: [10223]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def diff_result_df(test_images_path, result_a_csv_path, result_b_csv_path, output_folder):\n",
    "    \"\"\"\n",
    "    ë‘ CSV ê²°ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        test_images_path: ì›ë³¸ ì´ë¯¸ì§€ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ\n",
    "        result_a_csv_path: ì²« ë²ˆì§¸ ê²°ê³¼ CSV íŒŒì¼ (íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œ)\n",
    "        result_b_csv_path: ë‘ ë²ˆì§¸ ê²°ê³¼ CSV íŒŒì¼ (ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ)\n",
    "        output_folder: ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë”\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # ì¶œë ¥ í´ë” ìƒì„±\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # CSV íŒŒì¼ ì½ê¸°\n",
    "    try:\n",
    "        df_a = pd.read_csv(result_a_csv_path)\n",
    "        print(f\"Result A loaded: {len(df_a)} detections\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading result A: {e}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df_b = pd.read_csv(result_b_csv_path)\n",
    "        print(f\"Result B loaded: {len(df_b)} detections\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading result B: {e}\")\n",
    "        return\n",
    "    \n",
    "    # df_a, df_bëŠ” ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆë‹¤ê³  ê°€ì •\n",
    "\n",
    "    # 1. image_idë³„ë¡œ df_aì™€ df_bì˜ category_id ì§‘í•© ë¹„êµ\n",
    "    diff_image_ids = []\n",
    "    diff_summary = []\n",
    "\n",
    "    for image_id in sorted(set(df_a['image_id']).union(df_b['image_id'])):\n",
    "        cats_a = set(df_a[df_a['image_id'] == image_id]['category_id'])\n",
    "        cats_b = set(df_b[df_b['image_id'] == image_id]['category_id'])\n",
    "        if cats_a != cats_b:\n",
    "            diff_image_ids.append(image_id)\n",
    "            diff_summary.append({\n",
    "                'image_id': image_id,\n",
    "                'category_id_a': sorted(list(cats_a)),\n",
    "                'category_id_b': sorted(list(cats_b)),\n",
    "                'only_in_a': sorted(list(cats_a - cats_b)),\n",
    "                'only_in_b': sorted(list(cats_b - cats_a)),\n",
    "            })\n",
    "\n",
    "    print(f\"category_idê°€ ë‹¤ë¥´ê²Œ ì¡´ì¬í•˜ëŠ” image_id ê°œìˆ˜: {len(diff_image_ids)}\")\n",
    "    for item in diff_summary[:10]:  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥\n",
    "        print(f\"image_id: {item['image_id']}\")\n",
    "        print(f\"  df_a category_id: {item['category_id_a']}\")\n",
    "        print(f\"  df_b category_id: {item['category_id_b']}\")\n",
    "        print(f\"  only_in_a: {item['only_in_a']}\")\n",
    "        print(f\"  only_in_b: {item['only_in_b']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš© ê²½ë¡œ (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)\n",
    "test_images_path = r\"D:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\test_images\"  # ì›ë³¸ ì´ë¯¸ì§€ í´ë”\n",
    "result_a_csv = r\"D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\2stage_result_20250918_130256\\result_2way_20250918_130256.csv\"  # ì²« ë²ˆì§¸ ê²°ê³¼\n",
    "result_b_csv = r\"D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\output_data_resnet101.csv\"  # ë‘ ë²ˆì§¸ ê²°ê³¼\n",
    "#output_folder = r\"D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\2stage_result_20250918_130256_diff\"  # ì¶œë ¥ í´ë”\n",
    "output_folder = r\"D:\\GoogleDrive\\codeit_ai_health_eat\\scripts\\ê¹€ëª…í™˜\\2stage_result_20250918_130256_411_diff\"  # ì¶œë ¥ í´ë”\n",
    "\n",
    "diff_result_df(test_images_path, result_a_csv, result_b_csv, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_colab_250827",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0fed5fa4ef0c438abdca95570161d4cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c161d2b6ee0a4b4da504dfcc9b2814e4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e1e0b3df68004360a09dc4d8d2ea434b",
      "value": "â€‡49.3M/49.3Mâ€‡[00:00&lt;00:00,â€‡200MB/s]"
     }
    },
    "2b7e56c2359f4941a59ccc77858b12de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "336973c948724d95ad32489e7951aa84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fbd52d9887541fca10a3996f5c48a1b",
      "max": 49335454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b7e56c2359f4941a59ccc77858b12de",
      "value": 49335454
     }
    },
    "5449dc81135b4472908c94acd9f2641f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60ef28f19359454189e5e96661567d9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80cbe3479a1a409ea5473b666afdacb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4fcd1847d884743bb1a9c59cdc9eff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_60ef28f19359454189e5e96661567d9a",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "8fbd52d9887541fca10a3996f5c48a1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4fcd1847d884743bb1a9c59cdc9eff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c161d2b6ee0a4b4da504dfcc9b2814e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1a46fba4b4f4931856112d55bdf4dea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80cbe3479a1a409ea5473b666afdacb8",
       "IPY_MODEL_336973c948724d95ad32489e7951aa84",
       "IPY_MODEL_0fed5fa4ef0c438abdca95570161d4cd"
      ],
      "layout": "IPY_MODEL_5449dc81135b4472908c94acd9f2641f"
     }
    },
    "e1e0b3df68004360a09dc4d8d2ea434b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
