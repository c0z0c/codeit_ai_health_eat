{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3tb146HKUGS"
   },
   "source": [
    "# [초급 프로젝트] 4팀_김명환 - 알약객체 증강"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmaVeBaGKUGW"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzN8SzLMKgH1"
   },
   "source": [
    "# 환경설정\n",
    "    - 라이브러리 설치 및 로딩\n",
    "    - 사용자 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54696,
     "status": "ok",
     "timestamp": 1758107103955,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "ECzUDN-OzK99",
    "outputId": "6357e211-02d6-426a-fcc5-46f08f5f5429"
   },
   "outputs": [],
   "source": [
    "!pip install -q gdown\n",
    "!pip install -q albumentations\n",
    "!pip install -q ultralytics\n",
    "!pip install -q -U ultralytics\n",
    "!pip install -q nbformat\n",
    "!pip install -q roboflow\n",
    "!pip install -q opencv-python\n",
    "!pip install -q opencv-python-headless\n",
    "!pip install -q wandb\n",
    "!pip install -q timm\n",
    "!pip install -q torchvision\n",
    "#!pip install -q torch torchvision tqdm pillow matplotlib\n",
    "\n",
    "print(\"로딩완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15470,
     "status": "ok",
     "timestamp": 1758107122263,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "47-Qf8TYKUGW",
    "outputId": "84bbaee1-8d35-4273-fee2-9d14bdbc5784"
   },
   "outputs": [],
   "source": [
    "# 기본 라이브러리 (중복 제거 및 정리)\n",
    "\n",
    "# --- Scikit-learn: 데이터 전처리, 모델, 평가 ---\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import (\n",
    "    fetch_california_housing, load_iris, make_moons, make_circles,\n",
    "    load_breast_cancer, load_wine\n",
    ")\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, average_precision_score\n",
    "\n",
    "# --- 이미지 처리 ---\n",
    "import cv2\n",
    "from PIL import Image, ImageFilter, ImageDraw\n",
    "import albumentations as A\n",
    "\n",
    "# --- PyTorch: 딥러닝 관련 ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "# 문제 있는 v2 import 제거하고 필요시에만 개별적으로 import\n",
    "# from torchvision.transforms import v2, functional as TF\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from collections import OrderedDict\n",
    "\n",
    "# --- COCO 데이터셋 관련 ---\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as coco_mask\n",
    "\n",
    "# --- 딥러닝 모델 ---\n",
    "import timm\n",
    "\n",
    "# --- 기본 라이브러리 ---\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import yaml\n",
    "import shutil\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 데이터 분석 및 시각화 ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# --- 시간 관련 ---\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pytz\n",
    "\n",
    "# --- 진행률 표시 ---\n",
    "import IPython.display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- 시간대 설정 ---\n",
    "__kst = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# --- GPU 설정 ---\n",
    "__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "__device_cpu = torch.device('cpu')\n",
    "\n",
    "# --- 재현 가능한 결과를 위한 시드 설정 ---\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if __device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(f\"라이브러리 로드 완료 사용장치: {__device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15052,
     "status": "ok",
     "timestamp": 1758107178459,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "WE6336hF11C5",
    "outputId": "65e4bc24-5f9e-4077-beb0-97cd7734140f"
   },
   "outputs": [],
   "source": [
    "# OS 및 경로 관련 라이브러리 임포트\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    COLAB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    COLAB_AVAILABLE = False\n",
    "\n",
    "# 유틸리티 함수 디렉토리 경로 설정 (Colab 환경 여부에 따라 다르게 지정)\n",
    "utils_dir = None\n",
    "if COLAB_AVAILABLE:\n",
    "    # Colab 환경일 경우 Google Drive 경로 사용\n",
    "    utils_dir = \"/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\"\n",
    "else:\n",
    "    # 로컬 환경일 경우 현재 드라이브 기준 경로 사용\n",
    "    utils_dir = os.path.join(Path.cwd().drive + '\\\\\\\\', 'GoogleDrive', \"codeit_ai_health_eat\", \"src\", \"python_modules\", \"utils\")\n",
    "\n",
    "print(\"utils_dir:\", utils_dir)\n",
    "\n",
    "# 유틸리티 함수 경로를 파이썬 모듈 검색 경로에 추가\n",
    "sys.path.append(str(utils_dir))\n",
    "print(\"sys.path:\", sys.path)\n",
    "\n",
    "# health_ea_utils 모듈 임포트 및 최신화(reload)\n",
    "import importlib\n",
    "import health_ea_utils as heu\n",
    "importlib.reload(heu)\n",
    "from health_ea_utils import *\n",
    "\n",
    "# helper 및 health_ea_utils 파일 경로 출력 (디버깅용)\n",
    "print(\"helper.__file__:\", helper.__file__)\n",
    "print(\"health_ea_utils.__file__:\", heu.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1758107178466,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "A3JHrVMkzK9_",
    "outputId": "40eb0a1b-057c-4356-e7f7-07851b18b6e5"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import helper_utils as hutils\n",
    "importlib.reload(hutils)\n",
    "from helper_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B4qELHp5E9D"
   },
   "source": [
    "# 데이타 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1758107178597,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "0o9rB50tzK-A"
   },
   "outputs": [],
   "source": [
    "# download_files 변수 예시 (Google Drive 및 Naver MyBox 링크)\n",
    "# 여러 버전의 데이터셋 다운로드 링크를 주석으로 관리\n",
    "\n",
    "# download_files={\n",
    "#     'yolo_label_one_class' : r'https://drive.google.com/file/d/177_86k4BuT6JnFnq7ZHJtEjp7jaRbCl2/view?usp=sharing',\n",
    "#     'yolo_label' : r'https://drive.google.com/file/d/1nc-WFcw7lCS7s7VGzN9Kxh80PiBBggez/view?usp=sharing',\n",
    "#     'yolo_resize_one_class' : r'https://drive.google.com/file/d/1Ak0EvkMnuwvcAFvTO-zovIgVcNlROjsS/view?usp=sharing',\n",
    "#     'yolo_resize' : r'https://drive.google.com/file/d/1kpo57qOJhEhrkuzUCEh57ILB5xSPVoFv/view?usp=sharing',\n",
    "# }\n",
    "\n",
    "# download_files={\n",
    "#     'yolo_label' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODU5OTkzNTMyOHxGfDA&svcType=MYBOX-WEB&time=1757776010785',\n",
    "#     'yolo_label_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODYzOTg5NDExMnxGfDA&svcType=MYBOX-WEB&time=1757776673721',\n",
    "#     'yolo_resize_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODgwNjk2NDMyMHxGfDA&svcType=MYBOX-WEB&time=1757780142635',\n",
    "#     'yolo_resize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODY4MDc2MjQ2NHxGfDA&svcType=MYBOX-WEB&time=1757780177672',\n",
    "# }\n",
    "\n",
    "# 실제로 사용할 데이터셋 다운로드 링크만 활성화\n",
    "download_files={\n",
    "    # 'yolo_label' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODU5OTkzNTMyOHxGfDA&svcType=MYBOX-WEB&time=1757776010785',\n",
    "    # 'yolo_label_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODYzOTg5NDExMnxGfDA&svcType=MYBOX-WEB&time=1757776673721',\n",
    "    # 'yolo_resize_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODgwNjk2NDMyMHxGfDA&svcType=MYBOX-WEB&time=1757780142635',\n",
    "    # 'yolo_resize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODY4MDc2MjQ2NHxGfDA&svcType=MYBOX-WEB&time=1757780177672',\n",
    "    'yolo_noresize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDA0ODY2ODI1NnxGfDA&svcType=MYBOX-WEB&time=1757851996107',\n",
    "    #'yolo_noresize_one_class':r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDgwMDcxODk0NHxGfDA&svcType=MYBOX-WEB&time=1757893856220',\n",
    "}\n",
    "\n",
    "# 참고용: 각 데이터셋의 직접 다운로드 링크\n",
    "# yolo_noresize = https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDA0ODY2ODI1NnxGfDA&svcType=MYBOX-WEB&time=1757851996107\n",
    "# yolo_noresize_one_class = https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDgwMDcxODk0NHxGfDA&svcType=MYBOX-WEB&time=1757893856220\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19663,
     "status": "ok",
     "timestamp": 1758107198263,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "pdLVsfpwzK-A",
    "outputId": "c4c669d3-ae3b-4c50-df5a-c049fad718bd"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "def download_gdrive_file(url, output_path, ignore=True):\n",
    "    \"\"\"Google Drive 파일 다운로드 함수\n",
    "\n",
    "    Args:\n",
    "        url (str): Google Drive 공유 링크\n",
    "        output_path (str): 다운로드할 파일 경로\n",
    "        ignore (bool, optional): True면 기존 파일 삭제 후 다운로드, False면 파일 있으면 건너뜀. Defaults to True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Google Drive 파일 ID를 찾을 수 없습니다.\n",
    "    \"\"\"\n",
    "    # 공유 링크에서 파일 ID 추출\n",
    "    if os.path.exists(output_path):\n",
    "        if ignore:\n",
    "            os.remove(output_path)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    file_id_match = re.search(r'/d/([a-zA-Z0-9_-]+)', url)\n",
    "    if not file_id_match:\n",
    "        raise ValueError(\"Google Drive 파일 ID를 찾을 수 없습니다.\")\n",
    "    file_id = file_id_match.group(1)\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n",
    "\n",
    "def download_http(url, target, ignore=True):\n",
    "    \"\"\"\n",
    "    HTTP 파일 다운로드 함수 (진행률 표시)\n",
    "    url: 다운로드할 파일 URL\n",
    "    target: 저장할 파일 경로\n",
    "    ignore: True면 기존 파일 삭제 후 다운로드, False면 파일 있으면 건너뜀\n",
    "    \"\"\"\n",
    "    if os.path.exists(target):\n",
    "        if ignore:\n",
    "            os.remove(target)\n",
    "        else:\n",
    "            print(f\"이미 파일이 존재합니다: {target}\")\n",
    "            return target\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    total = int(response.headers.get('content-length', 0))\n",
    "    with open(target, 'wb') as file, tqdm(\n",
    "        desc=f\"Downloading {os.path.basename(target)}\",\n",
    "        total=total,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "        ascii=True\n",
    "    ) as bar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "    print(f\"다운로드 완료: {target}\")\n",
    "    return target\n",
    "\n",
    "# local_code_it_ai04 = os.path.join( '~/.cache/' if helper.is_colab else Path.cwd().drive + '\\\\'\n",
    "#                                   ,'temp'\n",
    "#                                   , 'code_it_ai04')\n",
    "\n",
    "# 데이터 다운로드 및 압축 해제 코드에 상세 주석 추가\n",
    "\n",
    "# 다운로드 경로 설정 (Colab/로컬 환경에 따라 다름)\n",
    "if COLAB_AVAILABLE:\n",
    "    local_code_it_ai04 = os.path.join( '/content/', 'code_it_ai04')\n",
    "else:\n",
    "    local_code_it_ai04 = os.path.join( Path.cwd().drive + '\\\\\\\\', 'temp', 'code_it_ai04')\n",
    "\n",
    "print(\"local_code_it_ai04:\", local_code_it_ai04)\n",
    "\n",
    "os.makedirs(local_code_it_ai04, exist_ok=True)  # 폴더 생성 코드 추가\n",
    "\n",
    "unzip_paths = []\n",
    "for key, url in download_files.items():\n",
    "    print(f\"{key}: {url}\")\n",
    "    zipfile = os.path.join(local_code_it_ai04, f'{key}.zip')\n",
    "    unzip_path = os.path.join(local_code_it_ai04, f'{key}.zip.unzip')\n",
    "    # 이미 압축해제된 폴더가 있으면 재다운로드/압축해제하지 않음\n",
    "    if os.path.exists(unzip_path):\n",
    "        print(f\"이미 압축해제된 폴더가 존재합니다: {unzip_path}\")\n",
    "        print('unzipfile:', unzip_path)\n",
    "        unzip_paths.append(unzip_path)\n",
    "        continue\n",
    "    # Google Drive 파일 다운로드 함수 (주석처리, 필요시 사용)\n",
    "    #download_gdrive_file(url, os.path.join(local_code_it_ai04, f'{key}.zip'), ignore=False)\n",
    "    # 일반 HTTP 다운로드 함수 사용\n",
    "    download_http(url, zipfile, ignore=False)\n",
    "    # 압축 해제 (health_ea_utils의 unzip 함수 사용)\n",
    "    unzip_path_list = heu.unzip([os.path.join(local_code_it_ai04, f'{key}.zip')])\n",
    "    # 압축 해제된 경로 리스트 출력 및 저장\n",
    "    print('unzip_path_list:', unzip_path_list)\n",
    "    unzip_paths.extend(unzip_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1758107198273,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "PjxsUVjUMlGq",
    "outputId": "b9afff51-38e3-499f-a4ba-25dde4cb1895"
   },
   "outputs": [],
   "source": [
    "# google drive root에 keggle.json 파일 필요합니다.\n",
    "for path in unzip_paths:\n",
    "    print(\"압축해제된 폴더:\", path)\n",
    "\n",
    "#yolo_dataset_path = os.path.join(local_code_it_ai04, f'yolo_label_one_class.zip.unzip')\n",
    "yolo_dataset_path =unzip_paths[0]\n",
    "yaml_path = os.path.join(yolo_dataset_path, \"dataset.yaml\")\n",
    "\n",
    "def get_path_data():\n",
    "    path = yolo_dataset_path\n",
    "    return path\n",
    "\n",
    "print(\"yaml_path:\", yaml_path)\n",
    "print(\"get_path_data:\", get_path_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1758107198456,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "5Z6vnx9ANq4u"
   },
   "outputs": [],
   "source": [
    "class YOLOToClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    YOLO 형식의 객체 감지 데이터셋을 이미지 분류용 데이터셋으로 변환하는 클래스입니다.\n",
    "\n",
    "    - yaml_path: YOLO 데이터셋의 dataset.yaml 파일 경로\n",
    "    - split: 'train', 'val', 'test' 중 하나로 데이터 분할 선택\n",
    "    - transform: 이미지 전처리(transform) 함수 (torchvision.transforms 등)\n",
    "    - crop_objects: True일 경우, 바운딩 박스(bbox) 영역만 crop하여 분류 이미지로 사용\n",
    "\n",
    "    주요 동작:\n",
    "    1. yaml 파일에서 이미지/라벨 폴더 경로, 클래스 정보 등을 읽어옴\n",
    "    2. 각 라벨(txt) 파일을 읽어, 이미지 경로와 클래스, bbox 정보를 self.data에 저장\n",
    "    3. __getitem__에서 bbox 영역 crop 후 transform 적용, (이미지, 클래스ID) 반환\n",
    "    4. get_item은 추가로 원본 이미지 경로와 bbox 좌표도 반환 (샘플 저장 등에 활용)\n",
    "\n",
    "    예시 사용법:\n",
    "        dataset = YOLOToClassificationDataset(yaml_path, split='train', transform=...)\n",
    "        image, label = dataset[0]\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, yaml_path, split='train', transform=None, crop_objects=True):\n",
    "        \"\"\"YOLOToClassificationDataset 초기화\n",
    "\n",
    "        Args:\n",
    "            yaml_path (str): YOLO 데이터셋의 dataset.yaml 파일 경로\n",
    "            split (str, optional): 'train', 'val', 'test' 중 하나로 데이터 분할 선택. Defaults to 'train'.\n",
    "            transform (callable, optional): 이미지 전처리(transform) 함수 (torchvision.transforms 등). Defaults to None.\n",
    "            crop_objects (bool, optional): True일 경우, 바운딩 박스(bbox) 영역만 crop하여 분류 이미지로 사용. Defaults to True.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: 잘못된 split 값이 주어진 경우\n",
    "        \"\"\"\n",
    "        # yaml 파일 읽기\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            yaml_data = yaml.safe_load(f)\n",
    "\n",
    "        self.yaml_data_path = yaml_data['path']\n",
    "        self.nc = yaml_data['nc']\n",
    "        self.names = yaml_data['names']\n",
    "        self.yaml_data_train = os.path.join(yaml_data['path'], yaml_data['train'])\n",
    "        self.yaml_data_val = os.path.join(yaml_data['path'], yaml_data['val'])\n",
    "        self.yaml_data_test = os.path.join(yaml_data['path'], yaml_data['test'])\n",
    "\n",
    "        print(\"yaml_data_path:\", self.yaml_data_path)\n",
    "\n",
    "        # split에 따라 경로 선택\n",
    "        if split == 'train':\n",
    "            image_dir = self.yaml_data_train\n",
    "        elif split == 'val':\n",
    "            image_dir = self.yaml_data_val\n",
    "        elif split == 'test':\n",
    "            image_dir = self.yaml_data_test\n",
    "        else:\n",
    "            raise ValueError(f\"split 값이 잘못되었습니다: {split}\")\n",
    "\n",
    "        label_dir = image_dir.replace('images', 'labels')\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.class_names = self.names\n",
    "        self.transform = transform\n",
    "        self.crop_objects = crop_objects\n",
    "        self.data = []\n",
    "\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        데이터셋을 로드하는 함수\n",
    "\n",
    "        - 라벨 디렉토리(self.label_dir) 내의 모든 .txt 파일(객체 감지 라벨)을 순회합니다.\n",
    "        - 각 라벨 파일의 한 줄(line)은 하나의 객체(알약)에 대한 정보입니다.\n",
    "        - 각 줄에서 class_id, bbox(x_center, y_center, width, height)를 읽어옵니다.\n",
    "        - 해당 라벨 파일에 대응하는 이미지 파일(.jpg)을 찾고, 존재하면\n",
    "        이미지 경로, 클래스ID, 바운딩박스 정보를 self.data 리스트에 저장합니다.\n",
    "        - 즉, 한 알약(객체)마다 하나의 데이터 샘플이 만들어집니다.\n",
    "        - 이후 __getitem__에서 bbox 영역만 crop(클리핑)하여 분류용 이미지로 반환합니다.\n",
    "\n",
    "        반환값: 없음 (self.data에 샘플 정보가 누적됨)\n",
    "        \"\"\"\n",
    "\n",
    "        if not os.path.exists(self.label_dir):\n",
    "            #print(f\"라벨 폴더가 존재하지 않습니다: {self.label_dir}\")\n",
    "            return  # 라벨 폴더 없으면 빈 데이터셋\n",
    "        for label_file in os.listdir(self.label_dir):\n",
    "            if not label_file.endswith('.txt'):\n",
    "                continue\n",
    "            image_file = label_file.replace('.txt', '.jpg')\n",
    "            image_path = os.path.join(self.image_dir, image_file)\n",
    "            label_path = os.path.join(self.label_dir, label_file)\n",
    "            if not os.path.exists(image_path):\n",
    "                continue\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                    self.data.append({\n",
    "                        'image_path': image_path,\n",
    "                        'class_id': class_id,\n",
    "                        'bbox': (x_center, y_center, width, height)\n",
    "                    })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        데이터셋에서 특정 인덱스의 샘플을 가져오는 함수\n",
    "\n",
    "        - self.data에서 idx번째 샘플 정보를 가져옵니다.\n",
    "        - 해당 이미지 파일을 열고, crop_objects=True일 경우 바운딩 박스(bbox) 영역만 crop(클리핑)합니다.\n",
    "        - 이미지 전처리(transform)가 지정되어 있으면 적용합니다.\n",
    "        - 최종적으로 (이미지, 클래스ID)를 반환합니다.\n",
    "\n",
    "        즉, 한 알약 객체의 crop된 이미지와 클래스 라벨을 반환합니다.\n",
    "        \"\"\"\n",
    "\n",
    "        item = self.data[idx]\n",
    "        image = Image.open(item['image_path']).convert('RGB')\n",
    "        if self.crop_objects and 'bbox' in item:\n",
    "            img_w, img_h = image.size\n",
    "            x_center, y_center, width, height = item['bbox']\n",
    "            x1 = int((x_center - width/2) * img_w)\n",
    "            y1 = int((y_center - height/2) * img_h)\n",
    "            x2 = int((x_center + width/2) * img_w)\n",
    "            y2 = int((y_center + height/2) * img_h)\n",
    "            # 좌표가 올바른지 체크\n",
    "            if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0 and x2 <= img_w and y2 <= img_h:\n",
    "                image = image.crop((x1, y1, x2, y2))\n",
    "            # else: 잘못된 bbox는 crop하지 않음\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, item['class_id']\n",
    "\n",
    "    def get_item(self, idx):\n",
    "        \"\"\"\n",
    "        데이터셋에서 특정 인덱스의 샘플을 가져오는 함수\n",
    "\n",
    "        - self.data에서 idx번째 샘플 정보를 가져옵니다.\n",
    "        - 해당 이미지 파일을 열고, crop_objects=True일 경우 바운딩 박스(bbox) 영역만 crop(클리핑)합니다.\n",
    "        - 이미지, 클래스ID, 원본 이미지 경로, bbox 좌표([x1, y1, x2, y2])를 반환합니다.\n",
    "        - 샘플 이미지 저장, 시각화 등에 활용할 수 있습니다.\n",
    "\n",
    "        즉, 한 알약 객체의 crop된 이미지와 클래스 라벨, 원본 경로, bbox 좌표를 반환합니다.\n",
    "        \"\"\"\n",
    "\n",
    "        item = self.data[idx]\n",
    "        image = Image.open(item['image_path']).convert('RGB')\n",
    "        if self.crop_objects and 'bbox' in item:\n",
    "            img_w, img_h = image.size\n",
    "            x_center, y_center, width, height = item['bbox']\n",
    "            x1 = int((x_center - width/2) * img_w)\n",
    "            y1 = int((y_center - height/2) * img_h)\n",
    "            x2 = int((x_center + width/2) * img_w)\n",
    "            y2 = int((y_center + height/2) * img_h)\n",
    "            # 좌표가 올바른지 체크\n",
    "            if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0 and x2 <= img_w and y2 <= img_h:\n",
    "                image = image.crop((x1, y1, x2, y2))\n",
    "            # else: 잘못된 bbox는 crop하지 않음\n",
    "        return image, item['class_id'], item['image_path'], [x1, y1, x2, y2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1758107198549,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "h0UX5QuCUPiM",
    "outputId": "bd3a64ad-455b-45d7-efa2-ca926d17403e"
   },
   "outputs": [],
   "source": [
    "def update_yaml_paths_to_absolute(yaml_path):\n",
    "    \"\"\"\n",
    "    dataset.yaml 파일의 상대 경로(path)를 절대 경로로 변환하여 저장하는 함수\n",
    "\n",
    "    Args:\n",
    "        yaml_path (str): dataset.yaml 파일의 경로\n",
    "\n",
    "    Returns:\n",
    "        dict: 절대 경로로 수정된 yaml 데이터 딕셔너리\n",
    "    \"\"\"\n",
    "\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "\n",
    "    yaml_dir = os.path.dirname(yaml_path)\n",
    "    data['path'] = os.path.normpath(os.path.join(yaml_dir, data['path']))\n",
    "    # for key in ['train', 'val', 'test']:\n",
    "    #     if key in data and not os.path.isabs(data[key]):\n",
    "    #         data[key] = os.path.normpath(os.path.join(yaml_dir, data[key]))\n",
    "\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(data, f, allow_unicode=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "yaml_data = update_yaml_paths_to_absolute(yaml_path)\n",
    "print(yaml_data.keys())\n",
    "yaml_data_path = yaml_data['path']\n",
    "nc = yaml_data['nc']\n",
    "names = yaml_data['names']\n",
    "yaml_data_train = os.path.join(yaml_data['path'], yaml_data['train'])\n",
    "yaml_data_val = os.path.join(yaml_data['path'], yaml_data['val'])\n",
    "yaml_data_test = os.path.join(yaml_data['path'], yaml_data['test'])\n",
    "\n",
    "print(\"nc:\", nc)\n",
    "print(\"names:\", names)\n",
    "print(\"yaml_data_path:\", yaml_data_path)\n",
    "print(\"yaml_data_train:\", yaml_data_train)\n",
    "print(\"yaml_data_val:\", yaml_data_val)\n",
    "print(\"yaml_data_test:\", yaml_data_test)\n",
    "\n",
    "coco_data_root = f\"{yaml_data_path}_coco\"\n",
    "print(\"coco_data_root:\", coco_data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_dataset = YOLOToClassificationDataset(\n",
    "    yaml_path=yaml_path,\n",
    "    split='train',\n",
    "    transform=None\n",
    ")\n",
    "original_val_dataset = YOLOToClassificationDataset(\n",
    "    yaml_path=yaml_path,\n",
    "    split='val',\n",
    "    transform=None\n",
    ")\n",
    "print(len(original_train_dataset), len(original_val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_yolo_to_coco_format(train_dataset, val_dataset, test_dataset, output_dir, image_format='jpg'):\n",
    "    \"\"\"\n",
    "    YOLO 데이터셋을 COCO 형식으로 변환하여 저장하는 함수\n",
    "    \n",
    "    Args:\n",
    "        train_dataset: YOLOToClassificationDataset (train)\n",
    "        val_dataset: YOLOToClassificationDataset (val) \n",
    "        test_dataset: YOLOToClassificationDataset (test)\n",
    "        output_dir: 출력 폴더 경로\n",
    "        image_format: 저장할 이미지 형식 ('jpg' 또는 'png')\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # 출력 디렉토리 구조 생성\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # COCO 형식 기본 구조\n",
    "    def create_coco_structure(description, split_name):\n",
    "        return {\n",
    "            \"info\": {\n",
    "                \"description\": description,\n",
    "                \"url\": \"\",\n",
    "                \"version\": \"1.0\",\n",
    "                \"year\": datetime.now().year,\n",
    "                \"contributor\": \"YOLO to COCO Converter\",\n",
    "                \"date_created\": datetime.now().isoformat()\n",
    "            },\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"id\": 1,\n",
    "                    \"name\": \"Unknown License\",\n",
    "                    \"url\": \"\"\n",
    "                }\n",
    "            ],\n",
    "            \"images\": [],\n",
    "            \"annotations\": [],\n",
    "            \"categories\": []\n",
    "        }\n",
    "    \n",
    "    # 각 분할별로 처리\n",
    "    datasets_info = [\n",
    "        (train_dataset, 'train', 'Training dataset'),\n",
    "        (val_dataset, 'val', 'Validation dataset'), \n",
    "        (test_dataset, 'test', 'Test dataset')\n",
    "    ]\n",
    "    \n",
    "    for dataset, split_name, description in datasets_info:\n",
    "        if dataset is None or len(dataset) == 0:\n",
    "            print(f\"{split_name} 데이터셋이 비어있거나 None입니다. 건너뜁니다.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"{split_name} 데이터셋 변환 중... ({len(dataset)} samples)\")\n",
    "        \n",
    "        # COCO 구조 초기화\n",
    "        coco_data = create_coco_structure(description, split_name)\n",
    "        \n",
    "        # 이미지 및 주석 디렉토리 생성\n",
    "        images_dir = os.path.join(output_dir, f'{split_name}2017')\n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        \n",
    "        # 카테고리 정보 추가 (한 번만)\n",
    "        if hasattr(dataset, 'class_names'):\n",
    "            class_names = dataset.class_names\n",
    "        elif hasattr(dataset, 'dataset') and hasattr(dataset.dataset, 'class_names'):\n",
    "            # ConcatDataset의 경우\n",
    "            for ds in dataset.datasets:\n",
    "                if hasattr(ds, 'class_names'):\n",
    "                    class_names = ds.class_names\n",
    "                    break\n",
    "                elif hasattr(ds, 'dataset') and hasattr(ds.dataset, 'class_names'):\n",
    "                    class_names = ds.dataset.class_names\n",
    "                    break\n",
    "        else:\n",
    "            class_names = [f\"class_{i}\" for i in range(10)]  # 기본값\n",
    "            \n",
    "        for i, class_name in enumerate(class_names):\n",
    "            coco_data[\"categories\"].append({\n",
    "                \"id\": i,\n",
    "                \"name\": class_name,\n",
    "                \"supercategory\": \"pill\"\n",
    "            })\n",
    "        \n",
    "        # 이미지별 그룹핑을 위한 딕셔너리\n",
    "        image_groups = {}\n",
    "        annotation_id = 1\n",
    "        \n",
    "        # 모든 샘플을 순회하며 이미지별로 그룹핑\n",
    "        print(f\"{split_name} 샘플들을 이미지별로 그룹핑 중...\")\n",
    "        pbar = tqdm(range(len(dataset)), desc=f\"Processing {split_name}\")\n",
    "        \n",
    "        for idx in pbar:\n",
    "            # 데이터셋 타입에 따른 처리\n",
    "            if hasattr(dataset, 'get_item'):\n",
    "                # 원본 YOLOToClassificationDataset\n",
    "                crop_image, class_id, original_image_path, bbox = dataset.get_item(idx)\n",
    "            elif hasattr(dataset, 'dataset') and hasattr(dataset.dataset, 'get_item'):\n",
    "                # ConcatDataset 내부의 원본 데이터셋 접근\n",
    "                # 복잡하므로 원본 이미지 정보 추출\n",
    "                crop_image, class_id = dataset[idx]\n",
    "                # 원본 경로는 별도로 처리 필요\n",
    "                original_image_path = f\"unknown_{idx}.jpg\"\n",
    "                bbox = [0, 0, 224, 224]  # 기본값\n",
    "            else:\n",
    "                crop_image, class_id = dataset[idx]\n",
    "                original_image_path = f\"sample_{idx}.jpg\"\n",
    "                bbox = [0, 0, 224, 224]\n",
    "                \n",
    "            # 이미지 파일명 생성\n",
    "            base_filename = os.path.basename(original_image_path).replace('.jpg', '').replace('.png', '')\n",
    "            image_filename = f\"{base_filename}_{class_id:03d}_{idx:06d}.{image_format}\"\n",
    "            image_path = os.path.join(images_dir, image_filename)\n",
    "            \n",
    "            # crop된 이미지 저장\n",
    "            if isinstance(crop_image, torch.Tensor):\n",
    "                # 정규화 해제\n",
    "                if crop_image.shape[0] == 3:  # (C, H, W)\n",
    "                    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "                    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "                    crop_image = crop_image * std + mean\n",
    "                    crop_image = torch.clamp(crop_image, 0, 1)\n",
    "                crop_image = TF.to_pil_image(crop_image)\n",
    "            \n",
    "            # 이미지 저장\n",
    "            crop_image.save(image_path)\n",
    "            crop_width, crop_height = crop_image.size\n",
    "            \n",
    "            # COCO 이미지 정보 추가\n",
    "            image_info = {\n",
    "                \"id\": idx + 1,\n",
    "                \"width\": crop_width,\n",
    "                \"height\": crop_height,\n",
    "                \"file_name\": image_filename,\n",
    "                \"license\": 1,\n",
    "                \"flickr_url\": \"\",\n",
    "                \"coco_url\": \"\",\n",
    "                \"date_captured\": datetime.now().isoformat()\n",
    "            }\n",
    "            coco_data[\"images\"].append(image_info)\n",
    "            \n",
    "            # COCO 주석 정보 추가 (전체 이미지가 해당 클래스)\n",
    "            annotation_info = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": idx + 1,\n",
    "                \"category_id\": int(class_names[class_id]),\n",
    "                \"segmentation\": [],\n",
    "                \"area\": crop_width * crop_height,\n",
    "                \"bbox\": [0, 0, crop_width, crop_height],  # 전체 이미지\n",
    "                \"iscrowd\": 0\n",
    "            }\n",
    "            coco_data[\"annotations\"].append(annotation_info)\n",
    "            annotation_id += 1\n",
    "            \n",
    "            pbar.set_postfix_str(f'{class_names[class_id]} ({image_filename})')\n",
    "                \n",
    "        \n",
    "        # JSON 파일 저장\n",
    "        json_filename = f\"instances_{split_name}2017.json\"\n",
    "        json_path = os.path.join(output_dir, json_filename)\n",
    "        \n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(coco_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"{split_name} 변환 완료:\")\n",
    "        print(f\"이미지: {len(coco_data['images'])}개 → {images_dir}\")\n",
    "        print(f\"주석: {json_path}\")\n",
    "        print(f\"카테고리: {len(coco_data['categories'])}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data_org_root = f\"{coco_data_root}_org\"\n",
    "print(\"coco_data_org_root:\", coco_data_org_root)\n",
    "\n",
    "# 기존 폴더가 있으면 삭제 후 다시 생성\n",
    "if os.path.exists(coco_data_org_root):\n",
    "    import shutil\n",
    "    shutil.rmtree(coco_data_org_root)\n",
    "    \n",
    "if not os.path.exists(coco_data_org_root):\n",
    "    os.makedirs(coco_data_org_root)\n",
    "    # COCO 형식으로 변환\n",
    "    convert_yolo_to_coco_format(\n",
    "        train_dataset=original_train_dataset,\n",
    "        val_dataset=original_val_dataset,\n",
    "        test_dataset=None,  # test 데이터셋이 없는 경우 None으로 설정\n",
    "        output_dir=coco_data_org_root,\n",
    "        image_format='jpg')\n",
    "else :\n",
    "    print(f\"{coco_data_org_root} 폴더가 이미 존재합니다. COCO 변환을 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cocco 데이타 셋 load\n",
    "coco_data_org_root = f\"{coco_data_root}_org\"\n",
    "print(\"coco_data_org_root:\", coco_data_org_root)\n",
    "\n",
    "train_coco_original = CocoDetection(\n",
    "    root=f'{coco_data_org_root}/train2017',\n",
    "    annFile=f'{coco_data_org_root}/instances_train2017.json'\n",
    ")\n",
    "\n",
    "val_coco_original = CocoDetection(\n",
    "    root=f'{coco_data_org_root}/val2017',\n",
    "    annFile=f'{coco_data_org_root}/instances_val2017.json'\n",
    ")\n",
    "\n",
    "print(len(train_coco_original), len(val_coco_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coco_class_distribution_df(coco_dataset, class_names=None, title=\"COCO 데이터셋 클래스 분포\"):\n",
    "    \"\"\"\n",
    "    COCO Detection 데이터셋의 클래스 분포를 DataFrame으로 출력 (가로 형태)\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "\n",
    "    class_counts = Counter()\n",
    "    for _, targets in tqdm(coco_dataset, desc=\"클래스 분포 집계\"):\n",
    "        for ann in targets:\n",
    "            class_id = ann.get('category_id', None)\n",
    "            if class_id is not None:\n",
    "                class_counts[class_id] += 1\n",
    "\n",
    "    # 클래스명 매핑\n",
    "    if class_names is None:\n",
    "        # category_id가 0부터 시작한다고 가정\n",
    "        class_names = [f\"class_{i}\" for i in range(max(class_counts.keys())+1)]\n",
    "\n",
    "    # DataFrame 생성\n",
    "    df = pd.DataFrame({\n",
    "        '클래스명': [class_names[cid] for cid in sorted(class_counts.keys())],\n",
    "        '샘플수': [class_counts[cid] for cid in sorted(class_counts.keys())],\n",
    "        '비율(%)': [class_counts[cid] / sum(class_counts.values()) * 100 for cid in sorted(class_counts.keys())]\n",
    "    })\n",
    "    df = df.set_index('클래스명').T  # 전치하여 가로 형태로\n",
    "\n",
    "    print(\"=\"*40)\n",
    "    print(title)\n",
    "    print(\"=\"*40)\n",
    "    df.head_att(10)\n",
    "    print(f\"\\n전체 샘플 수(객체 수): {sum(class_counts.values())}\")\n",
    "    print(\"=\"*40)\n",
    "    return df\n",
    "\n",
    "# 사용 예시\n",
    "df_train_org = print_coco_class_distribution_df(train_coco_original, title=\"train_coco_original 클래스 분포\")\n",
    "df_val_org = print_coco_class_distribution_df(val_coco_original, title=\"val_coco_original 클래스 분포\")\n",
    "\n",
    "category_id_list=[]\n",
    "class_names = list(df_train_org.columns)  # 또는 yaml에서 가져온 names\n",
    "for class_id, class_name in enumerate(class_names):\n",
    "    category_id = class_name.split('_')[1]\n",
    "    category_id_list.append(category_id)\n",
    "    print(f\"category_id: {class_id}, class_name: {category_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pill_optimized_augmentation():\n",
    "    \"\"\"\n",
    "    알약 특성에 최적화된 증강 변환\n",
    "    - 180도 회전 (알약이 굴러다니는 특성 반영)\n",
    "    - ImageNet 평균값으로 배경 채움\n",
    "    - 의료 이미지에 적합한 증강\n",
    "    \"\"\"\n",
    "    \n",
    "    # ImageNet 평균값을 0-255 범위로 변환\n",
    "    imagenet_mean_rgb = [int(0.485 * 255), int(0.456 * 255), int(0.406 * 255)]  # [123, 116, 103]\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomRotation(180, fill=imagenet_mean_rgb),  # 180도 회전 + ImageNet 평균값\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.3,\n",
    "            contrast=0.3,\n",
    "            saturation=0.2,\n",
    "            hue=0.1\n",
    "        ),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.1, 0.1),\n",
    "            scale=(0.9, 1.1),\n",
    "            fill=imagenet_mean_rgb  # ImageNet 평균값으로 채움\n",
    "        ),\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_augmented_dataset(dataset, augmentation_fn, verbose=True, class_names=None):\n",
    "    \"\"\"\n",
    "    클래스 분포의 최대값에 맞춰 증강하여 균일화된 데이터셋 생성\n",
    "    Args:\n",
    "        dataset: YOLOToClassificationDataset 또는 분류용 Dataset\n",
    "        augmentation_fn: 증강 transform 함수 (예: get_pill_optimized_augmentation())\n",
    "        verbose: 진행상황 출력 여부\n",
    "    Returns:\n",
    "        images: 증강된 이미지 리스트\n",
    "        labels: 증강된 라벨 리스트\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    class_indices = defaultdict(list)\n",
    "    pbar = tqdm(range(len(dataset)), desc=\"클래스별 인덱스 그룹핑\", **get_tqdm_kwargs())\n",
    "    for idx in pbar:\n",
    "        _, category_id = dataset[idx]  # label이 category_id임\n",
    "        class_indices[category_id].append(idx)\n",
    "    class_counts = {cid: len(idxs) for cid, idxs in class_indices.items()}\n",
    "    max_count = max(class_counts.values())\n",
    "    if verbose:\n",
    "        print(\"클래스별 샘플 수:\", class_counts)\n",
    "        print(\"최대 샘플 수:\", max_count)\n",
    "\n",
    "    images, labels = [], []\n",
    "    pbar = tqdm(class_indices.items(), desc=\"클래스별\", **get_tqdm_kwargs())\n",
    "    for category_id, idxs in pbar:\n",
    "        for idx in idxs:\n",
    "            img, label = dataset[idx]\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        n_to_add = max_count - len(idxs)\n",
    "        if n_to_add > 0:\n",
    "            for i in range(n_to_add):\n",
    "                src_idx = idxs[i % len(idxs)]\n",
    "                img, label = dataset[src_idx]\n",
    "                aug_img = augmentation_fn(img)\n",
    "                images.append(aug_img)\n",
    "                labels.append(label)\n",
    "        if verbose:\n",
    "            name = class_names[category_id] if class_names is not None and category_id < len(class_names) else str(category_id)\n",
    "            print(f\"카테고리 {name}({category_id}): 증강 {n_to_add}개 추가\")\n",
    "    return images, labels\n",
    "\n",
    "# 사용 예시\n",
    "pill_aug_transform = get_pill_optimized_augmentation()\n",
    "train_aug_images, train_aug_labels = create_balanced_augmented_dataset(\n",
    "    original_train_dataset,\n",
    "    augmentation_fn=pill_aug_transform,\n",
    "    verbose=True,\n",
    "    class_names=category_id_list  # names는 yaml에서 가져온 클래스명 리스트\n",
    ")\n",
    "\n",
    "val_aug_images, val_aug_labels = create_balanced_augmented_dataset(\n",
    "    original_val_dataset,\n",
    "    augmentation_fn=pill_aug_transform,\n",
    "    verbose=True,\n",
    "    class_names=category_id_list  # names는 yaml에서 가져온 클래스명 리스트\n",
    ")\n",
    "\n",
    "print(f\"train 균일화된 증강 데이터셋 크기: {len(train_aug_images)}\")\n",
    "print(f\"val 균일화된 증강 데이터셋 크기: {len(val_aug_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data_aug_root = f\"{coco_data_root}_aug\"\n",
    "print(\"coco_data_aug_root:\", coco_data_aug_root)\n",
    "\n",
    "# 기존 폴더가 있으면 삭제 후 다시 생성\n",
    "if os.path.exists(coco_data_aug_root):\n",
    "    import shutil\n",
    "    shutil.rmtree(coco_data_aug_root)\n",
    "\n",
    "if not os.path.exists(coco_data_aug_root):\n",
    "    os.makedirs(coco_data_aug_root)\n",
    "    # COCO 형식으로 변환\n",
    "    convert_yolo_to_coco_format(\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=train_dataset,\n",
    "        test_dataset=None,  # test 데이터셋이 없는 경우 None으로 설정\n",
    "        output_dir=coco_data_aug_root,\n",
    "        image_format='jpg')\n",
    "else :\n",
    "    print(f\"{coco_data_aug_root} 폴더가 이미 존재합니다. COCO 변환을 건너뜁니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_colab_250827",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "323211db356043ba882de45afca67656": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9c13127ccec4e9289a0fd5914e7f139",
      "max": 49335454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_944c5af927f44f85ad76ebbf5773f74e",
      "value": 49335454
     }
    },
    "609e7c83990c46c6aff3ef811e7b407e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "652ac9056f6746bcb2ce1ffdae392287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c32d540f631f4a58b1bc55bc00a9ec46",
      "placeholder": "​",
      "style": "IPY_MODEL_84d4fa7530814708b269d4b7f3a9ad86",
      "value": "model.safetensors: 100%"
     }
    },
    "6be00c22f33e439a956ae069aca91ae3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e98aa92b76b49e981021505a44716ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84d4fa7530814708b269d4b7f3a9ad86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "944c5af927f44f85ad76ebbf5773f74e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b4c4d8b0df8746ddae665d0afe8848b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_652ac9056f6746bcb2ce1ffdae392287",
       "IPY_MODEL_323211db356043ba882de45afca67656",
       "IPY_MODEL_d43d7e46e8024cd5b2d9f267d7d9a735"
      ],
      "layout": "IPY_MODEL_7e98aa92b76b49e981021505a44716ae"
     }
    },
    "c32d540f631f4a58b1bc55bc00a9ec46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9c13127ccec4e9289a0fd5914e7f139": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d43d7e46e8024cd5b2d9f267d7d9a735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6be00c22f33e439a956ae069aca91ae3",
      "placeholder": "​",
      "style": "IPY_MODEL_609e7c83990c46c6aff3ef811e7b407e",
      "value": " 49.3M/49.3M [00:00&lt;00:00, 183MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
